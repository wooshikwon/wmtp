# Weighted-MTP 연구제안서

---

### **연구 제안서: Critic Function을 활용한 Weighted Multi-Token Prediction (WMTP) 방법론 연구**

### **1. 연구 개요**

본 연구는 Multi-Token Prediction (MTP) 방식으로 사전 학습된 대규모 언어 모델(LLM)의 지도 미세 조정(Supervised Fine-Tuning, SFT) 단계에서 '토큰의 중요도'를 동적으로 반영하는 새로운 손실 함수인 **Weighted-MTP (WMTP)**를 제안하고자 합니다. 1 기존 MTP 모델은 N개의 미래 토큰을 예측할 때 모든 토큰에 동일한 가중치를 부여하여 병렬적으로 학습합니다. 2222 이로 인해 수렴 속도는 빠르지만, 학습 규모가 커질수록 성능 효율이 저하되는 문제가 보고된 바 있습니다. 3

본 연구는 이러한 비효율이 '중요하지 않은' 미래 토큰 정보까지 동등하게 학습하기 때문에 발생한다고 가정합니다. 4 이를 해결하기 위해 강화학습의 Critic 개념을 도입하여 각 미래 토큰의 가치(중요도)를 평가하고, 이를 MTP의 병렬 Cross-Entropy 손실에 가중치로 적용하는 방식을 제안합니다. 이 SFT 프레임워크는 강화학습과 지도 미세 조정을 통합하여, 모델이 단순히 여러 미래를 예측하는 것을 넘어 **'중요한 미래'에 더 집중하여 은닉 상태 벡터(hidden state vector)를 형성하도록 유도**하는 것을 목표로 합니다.

### **2. 연구 배경 및 문제 정의**

### **2.1. 대규모 언어 모델의 학습 방식: NTP에서 MTP로**

현대의 LLM은 대부분 자기회귀(auto-regressive) 방식으로, 주어진 컨텍스트(xt:1)를 바탕으로 다음 토큰(xt+1)을 예측하는 **Next-Token Prediction (NTP)** 손실 함수(L1)를 통해 학습됩니다. 5555 이 방식은 매우 효과적이지만, 방대한 데이터를 요구하며 학습 과정이 비효율적이라는 지적이 있습니다.

최근 Meta AI의 연구(Fabian Glöckle et al., 2024)에서는 NTP의 대안으로 **Multi-Token Prediction (MTP)**을 제안했습니다. 7 MTP는 다음 한 개의 토큰이 아닌, 미래의 N개 토큰(xt+n:t+1)을 동시에 예측하는 방식입니다. 8888 모델의 공유된 몸통(Shared Trunk)에서 나온 은닉 상태를 복사(Copy)하여 N개의 병렬적인 디코더 층(Decoder Layers)에 전달하고, 각 헤드는 서로 다른 미래 시점의 토큰(Pθ(xt+k∣xt:1))을 예측합니다. 9999

### **2.2. MTP의 잠재적 비효율성**

Glöckle 등의 연구에 따르면, MTP는 적은 데이터(예: 200B 토큰)로 학습 시 NTP보다 높은 성능을 보이며 빠른 수렴 속도를 가집니다. 10 하지만 학습 데이터가 증가(예: 500B 토큰)하면 NTP와 성능이 비슷해지거나 소폭 하회하는 경향을 보입니다. 11 이는 MTP 방식이 특정 규모 이상에서는 비효율을 야기할 수 있음을 시사합니다.

본 연구는 이 문제의 원인을 다음과 같이 정의합니다.

1. **균등한 중요도 가정의 한계**: MTP는 N개의 미래 토큰이 모두 동등하게 중요하다고 가정합니다.  하지만 실제 언어 생성 과업에서 모든 미래 토큰의 정보 가치는 동일하지 않습니다.

2. **은닉 상태 표현의 제약**: 단일 은닉 상태 벡터가 N개의 서로 다른 미래 토큰 정보를 동시에, 그리고 효과적으로 표상하는 데에는 본질적인 한계가 있을 수 있습니다.

3. **불필요한 상호 정보량 학습**: 저자의 해석처럼, MTP는 미래 토큰들의 '상호 정보량'에 N배의 가중치를 부여하는 효과를 가집니다. 만약 예측 대상이 되는 N개의 토큰 묶음이 중요하지 않다면, 이는 불필요한 정보에 학습 자원을 낭비하는 결과를 초래할 수 있습니다.

따라서 MTP의 병렬 학습 구조는 유지하되, **'중요한' 미래 토큰을 선별적으로 학습**할 수 있는 메커니즘이 필요합니다. 14

### **3. 제안 방법론: Critic-Weighted MTP (WMTP)**

이러한 문제의식을 바탕으로, 본 연구는 토큰의 중요도를 평가하기 위한 Critic Function과 이를 SFT 손실에 반영하는 Weighted-Loss 방식을 결합한 WMTP 방법론을 제안합니다. 15

### **3.1. 아키텍처**

제안하는 모델은 사전 학습된 MTP 모델을 기반으로 하며, 공유된 몸통(Shared Trunk)의 마지막 은닉 상태 벡터를 입력으로 받는 **MLP (Value Head)**를 추가합니다. 16 이 Value Head가 바로 각 시점의 상태 가치(state-value) Vϕ(st)를 예측하는 Critic 역할을 수행합니다.

### **3.2. 학습 과정**

학습은 두 단계로 구성됩니다.

**1단계: Critic Head 학습**

- MTP 모델의 파라미터는 모두 동결(freeze)합니다.
- 보상 모델(Reward Model, RM)이 제공하는 보상 신호(Rt)를 바탕으로, Value Head가 각 토큰 시점의 상태 가치 Vϕ(st)를 정확히 예측하도록 학습시킵니다.


- 손실 함수로는 one-step TD error에 기반한 평균 제곱 오차(Mean Squared Error)를 사용합니다: LVF(ϕ)=Et[(Vϕ(st)−Rt)2].


- Critic Head의 손실이 충분히 수렴할 때까지 이 단계를 진행합니다.

**2단계: Weighted-MTP 기반 SFT**

- 학습된 Critic Head를 사용하여 MTP 모델 전체를 미세 조정합니다.
- **토큰 중요도 계산**: MTP 모델이 t시점에서 t+1부터 t+4까지 4개의 토큰을 예측할 때, Critic Head는 각 미래 상태의 가치를 예측합니다. 두 연속된 상태 가치의 차분(δt−1=Vϕ(st)−Vϕ(st−1))을 해당 토큰의 중요도 점수로 사용합니다.

- **가중치 변환**: 계산된 4개 미래 토큰의 중요도 점수(δ)에 소프트맥스(softmax) 함수를 적용하여 합이 1인 확률 가중치(wt+k)로 변환합니다: wt+k=∑i=03exp(δt+i)exp(δt+k).

- **가중 손실 적용**: MTP의 각 병렬 헤드에서 계산된 Cross-Entropy 손실(lCE)에 해당 시점의 가중치(wt+k)를 곱합니다.

- **최종 손실 함수**: 제안하는 최종 손실은 Weighted-MTP 손실과 Critic 손실의 가중 합으로 구성됩니다:
Ltotal=LWMTP+λ LVF=E(x,y)[k=0∑3wt+klCE(yt+k,y^t+k)]+λEt[(Vϕ(st)−Rt)2]

이 과정을 통해 모델은 Critic이 중요하다고 판단한 미래 토큰의 예측 오류에 더 큰 그래디언트를 부여받게 되며, 결과적으로 중요한 정보를 중심으로 은닉 상태를 재구성하게 됩니다.

### **4. 연구의 타당성 검토**

- **토큰 가중치 방식의 유효성**: Falko Helm 등 (2025)의 연구는 토큰 가중치 적용의 효과를 입증한 바 있습니다. 23 해당 연구에서는 긴 컨텍스트와 짧은 컨텍스트 모델의 예측 확률 차이(∣w~i∣=∣log(pθ′(n)(i))−log(pθ(N)(i))∣)를 이용해 '장기 의존성(Long-Range Dependency)' 점수를 계산하고, 이를 NTP 미세 조정 시 손실 가중치로 활용하여 성능 향상을 이끌어냈습니다. 24 특히, 80%의 토큰을 학습에서 제외하는 희소(Sparse) 가중치 방식이 검색 위주 과제(retrieval-heavy tasks)에서 뛰어난 성능을 보였습니다. 25252525 이는 학습 시 모든 토큰을 동등하게 취급하는 것보다 중요한 토큰에 집중하는 것이 효과적임을 강력히 시사하며, 본 연구가 제안하는 '미래 토큰'에 대한 가중치 부여 방식의 타당성을 뒷받침합니다.
- **강화학습 Critic의 역할**: 강화학습에서 Critic이 예측하는 상태 가치 V(st)는 현재 상태로부터 미래에 얻을 총 보상의 기댓값으로, 본질적으로 해당 상태(토큰)의 '중요도'를 나타냅니다. 따라서 이를 MTP 손실의 가중치로 사용하는 것은 논리적으로 타당합니다.

### **5. 세부 연구 계획**

1. **베이스 모델**: Meta AI에서 공개한 7B 파라미터, n=4 MTP 사전 학습 모델을 HuggingFace를 통해 확보하여 활용합니다.
2. **데이터셋 및 RM**: 베이스라인 비교를 위해 Glöckle 등 (2024)이 미세 조정에 사용한 CodeContests 데이터셋을 우선적으로 활용할 계획입니다.  해당 데이터셋 접근이 어려울 경우, 유사한 공개 SFT 데이터셋과 널리 사용되는 공개 RM을 채택할 것입니다.
3. **구현**: Critic Head는 MTP 헤드가 분기되기 직전의 은닉 상태 벡터에 연결된 간단한 MLP로 구현합니다.  학습 파이프라인은 상기한 2단계(Critic 학습 → WMTP-SFT)로 구성합니다.

### **6. 추가 고려사항**

- **학습 파이프라인의 복잡성**: RM, Critic Head, MTP Head를 모두 고려하는 현재의 파이프라인은 다소 복잡할 수 있습니다. 개별 토큰의 중요도를 계산하는 더 단순한 방법론을 모색할 수 있습니다. 예를 들어 Alex J. Chan 등 (2024)의 아이디어처럼, 별도의 Critic Head 학습 없이 RM이 최종 보상을 생성할 때 내부적으로 사용한 Attention score를 활용하여 이전 토큰들에게 보상을 분배하는 방식을 고려해볼 수 있습니다.
- **사전 학습 방식의 중요성**: Glöckle 등 (2024)은 NTP로 사전 학습된 모델을 MTP 방식으로 미세 조정하는 것은 유의미한 성능 향상을 보이지 않았다고 보고했습니다.  따라서 본 연구는 반드시 MTP로 사전 학습된 모델을 기반으로 진행되어야 하며, 이는 공개된 모델이 존재하여 실현 가능합니다. 그들의 실험에서 MTP(n=4) 사전학습 모델은 미세조정 시 n'=4 뿐만 아니라 n'=1(NTP)로 학습해도 NTP 베이스라인보다 좋은 성능을 보였는데, 이는 MTP 사전학습이 강건한 표상을 학습했음을 시사합니다.
