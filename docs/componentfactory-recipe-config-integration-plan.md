# ComponentFactory Recipe/Config í†µí•© ê°œì„  ê³„íš

## ğŸ¯ ëª©í‘œ
ComponentFactoryì˜ ëª¨ë“  create_* ë©”ì„œë“œê°€ recipeì™€ configë§Œì„ ì¸ìë¡œ ë°›ì•„ì„œ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ í†µí•©

## ğŸ“Š í˜„ì¬ ë¬¸ì œì  ë¶„ì„

### ë¶ˆì¼ì¹˜í•˜ëŠ” ì¸ì íŒ¨í„´
- âœ… `create_scorer(recipe)` - ì´ë¯¸ recipeë§Œ ì‚¬ìš©
- âœ… `create_evaluator(recipe, config)` - ì´ë¯¸ recipe/configë§Œ ì‚¬ìš©
- âœ… `create_pretrainer(recipe)` - ì´ë¯¸ recipeë§Œ ì‚¬ìš©
- âŒ `create_trainer(recipe, config, scorer)` - scorer ë³„ë„ ì˜ì¡´ì„±
- âŒ `create_optimizer(recipe, model_params)` - model_params ë³„ë„ í•„ìš”
- âŒ `create_data_loader(source, config)` - source ë³„ë„ ì¸ì
- âŒ `create_tokenizer(config, recipe, tokenizer_type)` - tokenizer_type ë³„ë„

### Pipelineì—ì„œì˜ ë³µì¡í•œ í˜¸ì¶œ íŒ¨í„´
```python
# í˜„ì¬: ë³µì¡í•œ ë³„ë„ ì¸ìë“¤ê³¼ ì˜ì¡´ì„± ê´€ë¦¬
scorer = ComponentFactory.create_scorer(recipe)
trainer = ComponentFactory.create_trainer(recipe, config, scorer)
train_source = recipe.data.train.sources[0]
train_loader = ComponentFactory.create_data_loader(train_source, config)
tokenizer = ComponentFactory.create_tokenizer(config, recipe, "hf")
optimizer = ComponentFactory.create_optimizer(recipe, base.parameters())
```

## ğŸš€ ì¢…í•© í•´ê²° ë°©ì•ˆ

### Phase 1: Recipe ìŠ¤í‚¤ë§ˆ í™•ì¥

#### 1.1 Model ìŠ¤í‚¤ë§ˆì— tokenizer_type í•„ë“œ ì¶”ê°€
```python
# src/settings/recipe_schema.py
class Model(BaseModel):
    """ëª¨ë¸ ì„¤ì •: WMTPì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ëª¨ë¸ ì •ì˜"""

    # ... ê¸°ì¡´ í•„ë“œë“¤
    base_id: str = Field(..., description="ê¸°ë³¸ MTP ëª¨ë¸ ì‹ë³„ì")
    rm_id: str | None = Field(default=None, description="ë³´ìƒ ëª¨ë¸ ì‹ë³„ì")
    ref_id: str = Field(..., description="ì°¸ì¡° ëª¨ë¸ ì‹ë³„ì")

    # ğŸ†• ìƒˆ í•„ë“œ: í† í¬ë‚˜ì´ì € íƒ€ì…
    tokenizer_type: Literal["hf", "raw"] = Field(
        default="hf",
        description="Tokenizer interface type: hf=HuggingFace compatible, raw=SentencePiece direct"
    )

    # ... ê¸°ì¡´ í•„ë“œë“¤ ê³„ì†
```

#### 1.2 ê¸°ì¡´ data.sources í•„ë“œ í™œìš©
Recipeì—ëŠ” ì´ë¯¸ `recipe.data.train.sources` í•„ë“œê°€ ì¡´ì¬í•˜ë¯€ë¡œ ì¶”ê°€ ìˆ˜ì • ë¶ˆí•„ìš”:
```python
class DataConfig(BaseModel):
    sources: list[str] = Field(..., description="Data sources")  # ì´ë¯¸ ì¡´ì¬
```

### Phase 2: ComponentFactory ë©”ì„œë“œ ë¦¬íŒ©í† ë§

#### 2.1 create_tokenizer í†µí•© (ì™„ì „ ë‹¬ì„±)
```python
@classmethod
def create_tokenizer(cls, recipe: Recipe, config: Config):
    """í† í¬ë‚˜ì´ì € ìƒì„± - recipe/configë§Œ ì‚¬ìš©í•˜ëŠ” í†µí•© íŒ¨í„´"""

    # 1. tokenizer_typeì„ recipeì—ì„œ ê°€ì ¸ì˜´ (ë” ì´ìƒ ë³„ë„ ì¸ì ë¶ˆí•„ìš”)
    tokenizer_type = recipe.model.tokenizer_type

    # 2. registry_key ê²°ì •
    if tokenizer_type in ["hf", "huggingface", "hf-sentencepiece"]:
        registry_key = "hf"
    elif tokenizer_type in ["raw", "sentencepiece", "default"]:
        registry_key = "default"
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” tokenizer_type: {tokenizer_type}")

    # 3. config ì§ì ‘ ì‚¬ìš©
    tokenizer_config = config.model_dump()

    # 4. registry ìƒì„± ë° ë°˜í™˜
    return tokenizer_registry.create(registry_key, tokenizer_config)
```

#### 2.2 create_data_loader í†µí•© (ì™„ì „ ë‹¬ì„±)
```python
@classmethod
def create_data_loader(cls, recipe: Recipe, config: Config) -> Loader:
    """ë°ì´í„° ë¡œë” ìƒì„± - recipe/configë§Œ ì‚¬ìš©í•˜ëŠ” í†µí•© íŒ¨í„´"""

    # 1. sourceë¥¼ recipeì—ì„œ ìë™ ì¶”ì¶œ (ë” ì´ìƒ ë³„ë„ ì¸ì ë¶ˆí•„ìš”)
    source = recipe.data.train.sources[0]  # ì²« ë²ˆì§¸ í›ˆë ¨ ì†ŒìŠ¤ ì‚¬ìš©

    # 2. ì†ŒìŠ¤ë³„ ë°ì´í„°ì…‹ ê²½ë¡œ ê²°ì • (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    dataset_path = None
    if source == "mbpp":
        dataset_path = str(config.paths.datasets.mbpp)
    elif source in ["contest", "codecontests"]:
        dataset_path = str(config.paths.datasets.contest)
    else:
        dataset_path = source

    # 3. í†µí•© ë°ì´í„° ë¡œë” ì„¤ì • (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    loader_config = {
        "storage": config.storage.model_dump(),
        "paths": config.paths.model_dump(),
        "split": "train",
        "dataset_type": source,
    }

    # 4. UnifiedDataLoader ìƒì„±
    return loader_registry.create("unified-data-loader", loader_config)
```

#### 2.3 create_trainer ì˜ì¡´ì„± ìë™ ê´€ë¦¬ (ì™„ì „ ë‹¬ì„±)
```python
@classmethod
def create_trainer(cls, recipe: Recipe, config: Config) -> Trainer:
    """íŠ¸ë ˆì´ë„ˆ ìƒì„± - recipe/configë§Œ ì‚¬ìš©, scorer ì˜ì¡´ì„± ìë™ ê´€ë¦¬"""

    # 1. scorerë¥¼ ë‚´ë¶€ì—ì„œ ìë™ ìƒì„± (ë” ì´ìƒ ë³„ë„ ì¸ì ë¶ˆí•„ìš”)
    if recipe.train.algo == "mtp-baseline":
        scorer = None  # Baseline: ê· ë“± ê°€ì¤‘ì¹˜
    else:
        scorer = cls.create_scorer(recipe)  # ìë™ìœ¼ë¡œ ì í•©í•œ scorer ìƒì„±

    # 2. trainer ì„¤ì • êµ¬ì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    trainer_config = {
        "n_heads": recipe.model.mtp.n_heads,
        "horizon": recipe.model.mtp.horizon,
        "loss_config": {
            "weight_norm": recipe.loss.weight_norm,
            "lambda": recipe.loss.lambda_weight,
            "temperature": recipe.loss.temperature,
            "epsilon": recipe.loss.epsilon,
            "max_weight": recipe.loss.max_weight,
        },
        "full_finetune": recipe.train.full_finetune,
        "lora_config": recipe.train.lora.model_dump() if recipe.train.lora.enabled else None,
        "mixed_precision": config.devices.mixed_precision,
        "fsdp_config": config.devices.fsdp.model_dump() if config.devices.fsdp.enabled else None,
        "scorer": scorer,  # ìë™ ìƒì„±ëœ scorer í¬í•¨
    }

    # 3. registry ìƒì„± ë° ë°˜í™˜
    return trainer_registry.create(recipe.train.algo, trainer_config)
```

#### 2.4 create_optimizer ë¶€ë¶„ ê°œì„  (ê¸°ìˆ ì  ì œì•½)
```python
@classmethod
def create_optimizer(cls, recipe: Recipe, model_params) -> Optimizer:
    """ìµœì í™”ê¸° ìƒì„± - model_paramsëŠ” ê¸°ìˆ ì  ì œì•½ìœ¼ë¡œ ìœ ì§€"""

    # model_paramsëŠ” ì‹¤ì œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì˜ .parameters() í•„ìš”
    # recipe/configë§Œìœ¼ë¡œëŠ” í•´ê²° ë¶ˆê°€ëŠ¥í•œ ê¸°ìˆ ì  ì œì•½

    # ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ config ì •ë³´ëŠ” recipeì—ì„œ ì¶”ì¶œ ê°€ëŠ¥
    optimizer_config = {
        "params": model_params,  # ì—¬ì „íˆ ë³„ë„ ì¸ì í•„ìš”
        "lr": recipe.optim.lr,
        "weight_decay": recipe.optim.weight_decay,
        "betas": recipe.optim.betas,
        "grad_clip": recipe.optim.grad_clip,
        "scheduler": recipe.optim.scheduler,
        "warmup_ratio": recipe.optim.warmup_ratio,
    }

    return optimizer_registry.create(recipe.optim.optimizer, optimizer_config)
```

### Phase 3: Pipeline ëŒ€í­ ë‹¨ìˆœí™”

#### 3.1 training_pipeline.py ê°œì„ 
```python
# Before: ë³µì¡í•œ ë³„ë„ ì¸ìë“¤ê³¼ ì˜ì¡´ì„± ê´€ë¦¬
scorer = ComponentFactory.create_scorer(recipe)
trainer = ComponentFactory.create_trainer(recipe, config, scorer)
train_source = recipe.data.train.sources[0]
train_loader = ComponentFactory.create_data_loader(train_source, config)
tokenizer_component = ComponentFactory.create_tokenizer(config, recipe, "hf")
optimizer = ComponentFactory.create_optimizer(recipe, base.parameters())

# After: recipe/config ì¤‘ì‹¬ì˜ ê¹”ë”í•œ í˜¸ì¶œ
trainer = ComponentFactory.create_trainer(recipe, config)  # scorer ìë™ ìƒì„±
train_loader = ComponentFactory.create_data_loader(recipe, config)  # source ìë™ ì¶”ì¶œ
tokenizer_component = ComponentFactory.create_tokenizer(recipe, config)  # typeì€ recipeì—ì„œ
optimizer = ComponentFactory.create_optimizer(recipe, base.parameters())  # ìœ ì¼í•œ ì˜ˆì™¸
```

#### 3.2 evaluation_pipeline.py ê°œì„ 
```python
# Before
for source in sources:
    data_loader = ComponentFactory.create_data_loader(source, self.config)

# After
for source in sources:
    # recipe.dataë¥¼ ë™ì ìœ¼ë¡œ ìˆ˜ì •í•˜ì—¬ í˜„ì¬ source ë°˜ì˜
    current_recipe = recipe.model_copy(deep=True)
    current_recipe.data.train.sources = [source]
    data_loader = ComponentFactory.create_data_loader(current_recipe, self.config)
```

### Phase 4: YAML ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸

#### 4.1 ê¸°ì¡´ recipe YAML íŒŒì¼ë“¤ì— tokenizer_type í•„ë“œ ì¶”ê°€
```yaml
# configs/recipe.mtp_baseline.yaml
model:
  base_id: "facebook/multi-token-prediction"
  ref_id: "codellama/CodeLlama-7b-Python-hf"
  tokenizer_type: "hf"  # ğŸ†• ìƒˆ í•„ë“œ ì¶”ê°€
  tokenizer_pad_side: "right"
  mtp:
    n_heads: 4
    horizon: 4

# configs/recipe.critic.yaml
model:
  base_id: "facebook/multi-token-prediction"
  rm_id: "models/Llama_3_8B_RM"
  ref_id: "codellama/CodeLlama-7b-Python-hf"
  tokenizer_type: "hf"  # ğŸ†• ìƒˆ í•„ë“œ ì¶”ê°€
  tokenizer_pad_side: "right"

# configs/recipe.rho1.yaml
model:
  base_id: "facebook/multi-token-prediction"
  ref_id: "codellama/CodeLlama-7b-Python-hf"
  tokenizer_type: "hf"  # ğŸ†• ìƒˆ í•„ë“œ ì¶”ê°€
  tokenizer_pad_side: "right"
```

### Phase 5: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

#### 5.1 ê¸°ë³¸ import í…ŒìŠ¤íŠ¸
```python
from src.factory.component_factory import ComponentFactory
from src.settings.loader import load_config, load_recipe

config = load_config("configs/config.yaml")
recipe = load_recipe("configs/recipe.mtp_baseline.yaml")
```

#### 5.2 ìƒˆ ì¸í„°í˜ì´ìŠ¤ ë™ì‘ í…ŒìŠ¤íŠ¸
```python
# ìƒˆë¡œìš´ í†µí•© ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
trainer = ComponentFactory.create_trainer(recipe, config)
data_loader = ComponentFactory.create_data_loader(recipe, config)
tokenizer = ComponentFactory.create_tokenizer(recipe, config)
```

#### 5.3 ê¸°ì¡´ pipelineê³¼ì˜ í˜¸í™˜ì„± ê²€ì¦
- training_pipeline.py ë™ì‘ í™•ì¸
- evaluation_pipeline.py ë™ì‘ í™•ì¸
- ë™ì¼í•œ ê²°ê³¼ ìƒì„±ë˜ëŠ”ì§€ ê²€ì¦

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### ğŸ‰ ê°œì„  ì§€í‘œ
- **ì¸í„°í˜ì´ìŠ¤ ì¼ê´€ì„±**: 75% ë©”ì„œë“œê°€ recipe/configë§Œ ì‚¬ìš© (3/4 ë©”ì„œë“œ ì™„ì „ í†µí•©)
- **ì½”ë“œ ë‹¨ìˆœí™”**: Pipeline í˜¸ì¶œ ì½”ë“œ 50% ì´ìƒ ë‹¨ìˆœí™”
- **ì˜ì¡´ì„± ê´€ë¦¬**: ComponentFactory ë‚´ë¶€ì—ì„œ ìë™ ì²˜ë¦¬
- **ì„¤ì • ì¤‘ì‹¬**: ì„ ì–¸ì  YAML ì„¤ì • íŒ¨í„´ ì™„ì„±

### ğŸ”§ ê¸°ìˆ ì  ê°œì„ 
1. **ì¼ê´€ì„±**: ëª¨ë“  ë©”ì„œë“œê°€ ìœ ì‚¬í•œ ì¸í„°í˜ì´ìŠ¤ íŒ¨í„´ ì‚¬ìš©
2. **ìº¡ìŠí™”**: ì»´í¬ë„ŒíŠ¸ ê°„ ì˜ì¡´ì„±ì„ Factory ë‚´ë¶€ì—ì„œ ê´€ë¦¬
3. **ì„ ì–¸ì **: YAML ì„¤ì •ë§Œìœ¼ë¡œ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ êµ¬ì„± ê°€ëŠ¥
4. **ìœ ì§€ë³´ìˆ˜ì„±**: Pipeline ì½”ë“œê°€ ì„¤ì • ì¤‘ì‹¬ìœ¼ë¡œ ë‹¨ìˆœí™”

### âš ï¸ ì œì•½ì‚¬í•­
- `create_optimizer`ì˜ model_paramsëŠ” ì‹¤ì œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ í•„ìš”ë¡œ ê¸°ìˆ ì  ì œì•½ ìœ ì§€
- í•˜ì§€ë§Œ ë‚˜ë¨¸ì§€ 75% ë©”ì„œë“œëŠ” ì™„ì „íˆ recipe/configë¡œ í†µí•© ê°€ëŠ¥

## ğŸš€ êµ¬í˜„ ìˆœì„œ

1. **Phase 1**: Recipe Model ìŠ¤í‚¤ë§ˆì— tokenizer_type í•„ë“œ ì¶”ê°€
2. **Phase 2.1**: create_tokenizer ë¦¬íŒ©í† ë§ (recipe/configë§Œ ì‚¬ìš©)
3. **Phase 2.2**: create_data_loader ë¦¬íŒ©í† ë§ (recipe/configë§Œ ì‚¬ìš©)
4. **Phase 2.3**: create_trainer ë¦¬íŒ©í† ë§ (scorer ìë™ ìƒì„±)
5. **Phase 3**: Pipeline í˜¸ì¶œ ë°©ì‹ ë‹¨ìˆœí™”
6. **Phase 4**: YAML ì„¤ì • íŒŒì¼ë“¤ì— tokenizer_type ì¶”ê°€
7. **Phase 5**: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

## ğŸ’¡ ê²°ë¡ 

ì´ ê³„íšì„ í†µí•´ ComponentFactoryê°€ recipe/config ì¤‘ì‹¬ì˜ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ê²Œ ë˜ë©°, Pipeline ì½”ë“œì˜ ë³µì¡ì„±ì´ ëŒ€í­ ê°ì†Œí•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì¸ "recipeì™€ configë§Œ ì¸ìë¡œ ë°›ì•„ì„œ ëª¨ë“ ê²ƒì„ ìƒì„±"í•˜ëŠ” ëª©í‘œë¥¼ 75% ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì´ê³  êµ¬ì²´ì ì¸ ë°©ì•ˆì…ë‹ˆë‹¤.

íŠ¹íˆ model_paramsì˜ ê¸°ìˆ ì  ì œì•½ì„ ì¸ì •í•˜ë©´ì„œë„, ë‚˜ë¨¸ì§€ ëŒ€ë¶€ë¶„ì˜ ë©”ì„œë“œë¥¼ í†µí•©í•˜ì—¬ ì „ì²´ì ì¸ ì¼ê´€ì„±ê³¼ ì‚¬ìš©ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.