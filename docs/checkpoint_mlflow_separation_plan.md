# Checkpoint-MLflow ì—­í•  ë¶„ë¦¬ êµ¬í˜„ ê³„íšì„œ

**ì‘ì„±ì¼**: 2025-10-02
**ëª©ì **: ì¤‘ë³µ ì €ì¥ ì œê±°ë¥¼ í†µí•œ ë¹„ìš© ì ˆê° ë° ì—­í•  ëª…í™•í™”
**ì „ëµ**: ì—­í•  ê¸°ë°˜ ë¶„ë¦¬ (í›ˆë ¨ ì¬ê°œ vs ì‹¤í—˜ ì¶”ì )
**ìŠ¹ì¸**: Option 3 - ìµœì†Œ ë³€ê²½, ì¦‰ì‹œ ì ìš©

---

## ğŸ“‹ Executive Summary

### í•µì‹¬ ë¬¸ì œ
- **í˜„ìƒ**: ë™ì¼ checkpointê°€ paths.checkpointsì™€ MLflowì— ì¤‘ë³µ ì €ì¥
- **ì›ì¸**: `distribute_manager.py` Line 412-416ì—ì„œ ë¬´ì¡°ê±´ MLflow ì—…ë¡œë“œ
- **ì˜í–¥**: ì €ì¥ ë¹„ìš© 2ë°° (Production ê¸°ì¤€ 490GB â†’ 70GB ê°€ëŠ¥)

### í•´ê²° ì „ëµ
**ì—­í•  ê¸°ë°˜ ëª…ì‹œì  ë¶„ë¦¬**:
- **paths.checkpoints**: í›ˆë ¨ ì¬ê°œ ì „ìš© (ì£¼ê¸°ì , keep_last ê´€ë¦¬)
- **MLflow artifacts**: ìµœì¢… ëª¨ë¸ ì „ìš© (ì˜êµ¬, ë²„ì „ ê´€ë¦¬)

### ë³€ê²½ ë²”ìœ„
- **2ê°œ íŒŒì¼ ìˆ˜ì •**: `distribute_manager.py`, `base_wmtp_trainer.py`
- **ë³€ê²½ ë¼ì¸**: ì•½ 30ì¤„ (ì‚­ì œ 15 + ì¶”ê°€ 15)
- **ì ìš© ì‹œê°„**: ì¦‰ì‹œ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)

### ê¸°ëŒ€ íš¨ê³¼
- âœ… ì €ì¥ ë¹„ìš© 86% ì ˆê° (420GB ì¤‘ë³µ ì œê±°)
- âœ… ì—­í•  ëª…í™•í™” (ì¬ê°œ vs ì¶”ì )
- âœ… ì„¤ì • ê°„ì†Œí™” (í…ŒìŠ¤íŠ¸ í™˜ê²½)

---

## ğŸ¯ ê°œë°œ ì›ì¹™ ì¤€ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì›ì¹™ 1: ì•/ë’¤ íë¦„ í™•ì¸ ë° í˜„ì¬ êµ¬ì¡° íŒŒì•…
- [x] **Phase 0 ì™„ë£Œ**: ì €ì¥ íë¦„ ì „ì²´ ë¶„ì„
  - base_wmtp_trainer.py â†’ _save_checkpoint â†’ distribute_manager.save_checkpoint
  - MLflow ì—…ë¡œë“œ ì§€ì  íŒŒì•… (distribute_manager.py Line 412-416)
  - ìµœì¢… ëª¨ë¸ ì €ì¥ íë¦„ íŒŒì•… (_save_final_checkpoint)

**ì ìš© ë°©ì•ˆ**:
- Phase 1 ì „: distribute_manager.py save_checkpoint ë©”ì„œë“œ ì „ì²´ ì½ê¸°
- Phase 2 ì „: base_wmtp_trainer.py _save_final_checkpoint ë©”ì„œë“œ ì „ì²´ ì½ê¸°
- ê° Phaseì—ì„œ ìˆ˜ì • ì „ í•´ë‹¹ ë©”ì„œë“œ í˜¸ì¶œ/í”¼í˜¸ì¶œ ê´€ê³„ í™•ì¸

### ì›ì¹™ 2: ê¸°ì¡´ êµ¬ì¡° ì¡´ì¤‘ ë° ì¤‘ë³µ ì œê±°
- [x] **êµ¬ì¡° ì¡´ì¤‘**: ê¸°ì¡´ checkpoint ì €ì¥ ë¡œì§ ìœ ì§€
- [x] **ì¤‘ë³µ ì œê±°**: MLflow ìë™ ì—…ë¡œë“œë§Œ ì œê±° (ì—­í•  ë¶„ë¦¬)

**ì ìš© ë°©ì•ˆ**:
- ê¸°ì¡´ save_checkpoint ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ (mlflow_manager íŒŒë¼ë¯¸í„° ìœ ì§€)
- ë¡œì»¬/S3 ì €ì¥ ë¡œì§ ë³€ê²½ ì—†ìŒ
- ìµœì¢… ëª¨ë¸ë§Œ MLflow ì²˜ë¦¬ (ëª…ì‹œì  ë¶„ë¦¬)

### ì›ì¹™ 3: ì‚­ì œ vs ìˆ˜ì • ê²€í†  ë° ìŠ¹ì¸
- [x] **ìŠ¹ì¸ ì™„ë£Œ**: Option 3 (ì—­í•  ë¶„ë¦¬) ì„ íƒ
- [x] **ì‚­ì œ ëŒ€ìƒ**: MLflow ìë™ ì—…ë¡œë“œ ì½”ë“œë§Œ (Line 412-416)
- [x] **ìˆ˜ì • ëŒ€ìƒ**: _save_final_checkpointì— ëª…ì‹œì  MLflow ì²˜ë¦¬ ì¶”ê°€

**ì ìš© ë°©ì•ˆ**:
- distribute_manager.py: ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ ì‚­ì œ
- base_wmtp_trainer.py: ìµœì¢… ëª¨ë¸ MLflow ë“±ë¡ ê°•í™”
- í•˜ìœ„ í˜¸í™˜: mlflow_manager íŒŒë¼ë¯¸í„° ìœ ì§€ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)

### ì›ì¹™ 4: ê¹¨ë—í•œ ì½”ë“œ ìƒì„±
- [x] **í•˜ìœ„ í˜¸í™˜ ë¬´ì‹œ**: ì¤‘ë³µ ì—…ë¡œë“œ ì™„ì „ ì œê±°
- [x] **í†µì¼ì„±**: ì£¼ì„ ë° ë³€ìˆ˜ëª… ì¼ê´€ì„± ìœ ì§€
- [x] **ë‹¨ìˆœì„±**: wrapper ë©”ì„œë“œ ì—†ì´ ì§ì ‘ êµ¬í˜„
- [x] **ì£¼ì„**: ë¶ˆí•„ìš”í•œ phase ë²ˆí˜¸ ì œê±°, ë™ì‘ ì„¤ëª…ë§Œ

**ì ìš© ë°©ì•ˆ** (ì›ì¹™ 4-1, 4-2, 4-3):
- ë³€ìˆ˜ëª…: checkpoint_path, final_path (ì¼ê´€ì„±)
- ì£¼ì„: "ì—­í•  ë¶„ë¦¬: í›ˆë ¨ ì¬ê°œ vs ì‹¤í—˜ ì¶”ì " (í•µì‹¬ë§Œ)
- Phase ë²ˆí˜¸ ì£¼ì„ ì œê±° (ex. "Phase 3:" â†’ ì‚­ì œ)
- wrapper ì—†ì´ ì§ì ‘ mlflow.log_model, log_artifact í˜¸ì¶œ

### ì›ì¹™ 5: ê³„íš ëŒ€ë¹„ ê²€í†  ë° ê°ê´€ì  ë³´ê³ 
- [ ] **Phase 1 ì™„ë£Œ í›„**: ê³„íšì„œ ëŒ€ë¹„ ê²€ì¦ ë° ë³´ê³ 
- [ ] **Phase 2 ì™„ë£Œ í›„**: ê³„íšì„œ ëŒ€ë¹„ ê²€ì¦ ë° ë³´ê³ 
- [ ] **Phase 4 ì™„ë£Œ í›„**: ìµœì¢… ì„±ê³¼ ê°ê´€ì  ê¸°ìˆ 

**ì ìš© ë°©ì•ˆ**:
- ê° Phase ì™„ë£Œ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦
- ê³„íšì„œì™€ ì‹¤ì œ ë³€ê²½ ì‚¬í•­ ë¹„êµ ë³´ê³ 
- ì˜ˆìƒ íš¨ê³¼ì™€ ì‹¤ì œ íš¨ê³¼ ë¹„êµ (ì €ì¥ ì‹œê°„, íŒŒì¼ í¬ê¸°)

### ì›ì¹™ 6: íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ë„êµ¬ í™œìš©
- [x] **uv í™˜ê²½ ì‚¬ìš©**: ëª¨ë“  í…ŒìŠ¤íŠ¸ì—ì„œ `uv run` í™œìš©
- [x] **ì˜ì¡´ì„± ë³€ê²½ ì—†ìŒ**: ê¸°ì¡´ íŒ¨í‚¤ì§€ë§Œ ì‚¬ìš© (torch, mlflow)

**ì ìš© ë°©ì•ˆ**:
- ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸: `uv run python -m src.cli.train ...`
- ì˜ì¡´ì„± ì¶”ê°€ ì—†ìŒ (ê¸°ì¡´ ì½”ë“œë§Œ ìˆ˜ì •)

---

## 1. ë¬¸ì œ ì •ì˜

### 1.1. ì¤‘ë³µ ì €ì¥ ì½”ë“œ ìœ„ì¹˜

**distribute_manager.py (Line 405-417)**:
```python
else:
    # ë¡œì»¬ ì €ì¥
    torch.save(checkpoint, checkpoint_path)
    console.print(
        f"[green]Checkpoint saved locally: {checkpoint_path}[/green]"
    )

    # MLflowì—ë„ ê¸°ë¡ (ìˆëŠ” ê²½ìš°)  â† ì¤‘ë³µ ë°œìƒ ì§€ì !
    if mlflow_manager:
        mlflow_manager.log_artifact(
            local_path=checkpoint_path, artifact_path="checkpoints"
        )
```

**ê²°ê³¼**: ë§¤ save_intervalë§ˆë‹¤ ë¡œì»¬ + MLflow 2ê³³ì— ì €ì¥

### 1.2. ì €ì¥ ë¹„ìš© ê³„ì‚°

**Production ì˜ˆì‹œ** (7B ëª¨ë¸, 30K steps, save_interval=1000):
```
Checkpoint ì €ì¥ íšŸìˆ˜: 30íšŒ

paths.checkpoints (keep_last=5):
- ì €ì¥ëŸ‰: 14GB Ã— 5 = 70GB

MLflow artifacts (ì˜êµ¬ ë³´ì¡´):
- ì €ì¥ëŸ‰: 14GB Ã— 30 = 420GB

ì´ ì €ì¥ëŸ‰: 490GB
ì¤‘ë³µ ì œê±° í›„: 70GB (86% ì ˆê°)
```

---

## 2. í•´ê²° ì „ëµ: ì—­í•  ê¸°ë°˜ ë¶„ë¦¬

### 2.1. ì„¤ê³„ ì›ì¹™

| ì‹œìŠ¤í…œ | ëª©ì  | ì €ì¥ ëŒ€ìƒ | ê´€ë¦¬ ì •ì±… | ìƒëª…ì£¼ê¸° |
|--------|------|-----------|-----------|----------|
| **paths.checkpoints** | í›ˆë ¨ ì¬ê°œ | ì£¼ê¸°ì  checkpoint | keep_last | Ephemeral |
| **MLflow artifacts** | ì‹¤í—˜ ì¶”ì  | ìµœì¢… ëª¨ë¸ë§Œ | ì˜êµ¬ ë³´ì¡´ | Persistent |

### 2.2. ë³€ê²½ ìµœì†Œí™”

**ë³€ê²½ íŒŒì¼**:
1. `src/utils/distribute_manager.py` (Line 405-417)
2. `src/components/trainer/base_wmtp_trainer.py` (Line 151-218)

**ë³€ê²½ ë‚´ìš©**:
- distribute_manager: MLflow ìë™ ì—…ë¡œë“œ ì œê±°
- base_wmtp_trainer: _save_final_checkpointì—ì„œ MLflow ëª…ì‹œì  ì²˜ë¦¬

---

## ğŸ“ Phase 0: ì‚¬ì „ ë¶„ì„ âœ…

**ëª©í‘œ**: ì½”ë“œ íë¦„ ì™„ì „ íŒŒì•… (ì›ì¹™ 1)

**ì™„ë£Œ ì‚¬í•­**:
- [x] ì €ì¥ íë¦„ ì „ì²´ ë¶„ì„
  - base_wmtp_trainer.py (Line 559-602): _save_checkpoint ë©”ì„œë“œ
  - distribute_manager.py (Line 310-417): save_checkpoint ë©”ì„œë“œ
  - base_wmtp_trainer.py (Line 151-218): _save_final_checkpoint ë©”ì„œë“œ

- [x] ì¤‘ë³µ ë°œìƒ ì§€ì  íŒŒì•…
  - distribute_manager.py Line 412-416: ë¬´ì¡°ê±´ MLflow ì—…ë¡œë“œ
  - S3 ê²½ë¡œì¸ ê²½ìš° Line 388ë„ MLflow ì—…ë¡œë“œ

- [x] ì˜í–¥ ë²”ìœ„ í™•ì •
  - 2ê°œ íŒŒì¼ ìˆ˜ì •
  - ê¸°ì¡´ API ë³€ê²½ ì—†ìŒ (í•˜ìœ„ í˜¸í™˜)
  - Config/Recipe ë³€ê²½ ì—†ìŒ

**ì›ì¹™ ì¤€ìˆ˜**:
- âœ… ì›ì¹™ 1: ì•/ë’¤ íë¦„ ì™„ì „ ë¶„ì„ ì™„ë£Œ
- âœ… ì›ì¹™ 2: ê¸°ì¡´ êµ¬ì¡° íŒŒì•… (ì¡´ì¤‘ ëŒ€ìƒ í™•ì¸)

---

## ğŸ“ Phase 1: distribute_manager.py ì¤‘ë³µ ì—…ë¡œë“œ ì œê±°

**ëª©í‘œ**: ì¤‘ê°„ checkpoint MLflow ìë™ ì—…ë¡œë“œ ì œê±°

### ì›ì¹™ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì›ì¹™ 1**: save_checkpoint ë©”ì„œë“œ ì „ì²´ ì½ê¸° (Line 310-419)
- [ ] **ì›ì¹™ 2**: ë¡œì»¬/S3 ì €ì¥ ë¡œì§ ìœ ì§€, MLflow ë¶€ë¶„ë§Œ ì œê±°
- [ ] **ì›ì¹™ 3**: ìŠ¹ì¸ëœ ì‚­ì œ ëŒ€ìƒ (Line 412-416, Line 388)
- [ ] **ì›ì¹™ 4-1**: íŒŒë¼ë¯¸í„°ëª… ìœ ì§€ (mlflow_manager), ì£¼ì„ ì •ë¦¬
- [ ] **ì›ì¹™ 4-2**: wrapper ì—†ì´ ì§ì ‘ ì‚­ì œ
- [ ] **ì›ì¹™ 4-3**: "Phase 3" ê°™ì€ ì£¼ì„ ì œê±°, ì—­í•  ì„¤ëª… ì¶”ê°€
- [ ] **ì›ì¹™ 5**: ë³€ê²½ í›„ ê³„íš ëŒ€ë¹„ ê²€ì¦
- [ ] **ì›ì¹™ 6**: uv runìœ¼ë¡œ í…ŒìŠ¤íŠ¸

### 1.1. ì½”ë“œ ë³€ê²½

**íŒŒì¼**: `src/utils/distribute_manager.py`

#### ë³€ê²½ 1: Docstring ì—…ë°ì´íŠ¸ (Line 320-340)

**Before**:
```python
"""
ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (FSDP/non-FSDP ëª¨ë¸ ëª¨ë‘ ì§€ì›).

WMTP ë§¥ë½:
í•™ìŠµ ì¤‘ê°„ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ ì¬ê°œ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
íŠ¹íˆ ì¥ì‹œê°„ í•™ìŠµì´ í•„ìš”í•œ ëŒ€ê·œëª¨ ëª¨ë¸ì—ì„œ ì¤‘ìš”í•©ë‹ˆë‹¤.
S3 ê²½ë¡œ ì§€ì› ë° MLflow ìë™ ì—…ë¡œë“œ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

ë§¤ê°œë³€ìˆ˜:
    model: FSDP ë˜í•‘ëœ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ torch.nn.Module
    optimizer: ì˜µí‹°ë§ˆì´ì €
    checkpoint_path: ì €ì¥ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” s3://)
    epoch: í˜„ì¬ ì—í­
    step: í˜„ì¬ ìŠ¤í…
    mlflow_manager: MLflow ë§¤ë‹ˆì € (ì„ íƒì )
    **kwargs: ì¶”ê°€ ì €ì¥ ë°ì´í„° (loss, metrics ë“±)

ì£¼ì˜ì‚¬í•­:
    - rank0_only=Trueë¡œ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ë§Œ ì €ì¥
    - offload_to_cpu=Trueë¡œ GPU ë©”ëª¨ë¦¬ ì ˆì•½
    - S3 ê²½ë¡œì‹œ ì§ì ‘ ì—…ë¡œë“œ, ë¡œì»¬ ê²½ë¡œì‹œ íŒŒì¼ ì €ì¥ í›„ MLflow ì—…ë¡œë“œ
"""
```

**After**:
```python
"""
ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (FSDP/non-FSDP ëª¨ë¸ ëª¨ë‘ ì§€ì›).

ì—­í•  ë¶„ë¦¬:
- ì£¼ê¸°ì  checkpoint: paths.checkpointsì—ë§Œ ì €ì¥ (í›ˆë ¨ ì¬ê°œìš©)
- ìµœì¢… ëª¨ë¸: base_wmtp_trainer._save_final_checkpointì—ì„œ MLflow ì²˜ë¦¬

ë§¤ê°œë³€ìˆ˜:
    model: FSDP ë˜í•‘ëœ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ torch.nn.Module
    optimizer: ì˜µí‹°ë§ˆì´ì €
    checkpoint_path: ì €ì¥ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” s3://)
    epoch: í˜„ì¬ ì—í­
    step: í˜„ì¬ ìŠ¤í…
    mlflow_manager: MLflow ë§¤ë‹ˆì € (ìµœì¢… ëª¨ë¸ìš©, ì¤‘ê°„ checkpointëŠ” ë¯¸ì‚¬ìš©)
    **kwargs: ì¶”ê°€ ì €ì¥ ë°ì´í„° (loss, metrics ë“±)

ì£¼ì˜ì‚¬í•­:
    - rank0_only=Trueë¡œ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ë§Œ ì €ì¥
    - offload_to_cpu=Trueë¡œ GPU ë©”ëª¨ë¦¬ ì ˆì•½
    - ì¤‘ê°„ checkpointëŠ” MLflowì— ì—…ë¡œë“œí•˜ì§€ ì•ŠìŒ (ë¹„ìš© ì ˆê°)
"""
```

#### ë³€ê²½ 2: S3 ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° (Line 372-404)

**Before**:
```python
# S3 ë˜ëŠ” ë¡œì»¬ ì €ì¥ ì²˜ë¦¬
if checkpoint_path.startswith("s3://"):
    # S3ì— ì§ì ‘ ì €ì¥
    import io
    import tempfile
    from pathlib import Path

    buffer = io.BytesIO()
    torch.save(checkpoint, buffer)
    buffer.seek(0)

    if mlflow_manager:
        # MLflowë¥¼ í†µí•´ ì•„í‹°íŒ©íŠ¸ë¡œ ì—…ë¡œë“œ (ì„ì‹œ íŒŒì¼ ê²½ìœ )
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp_path = Path(tmpdir) / f"checkpoint_step_{step}.pt"
            with open(tmp_path, "wb") as f:
                f.write(buffer.getvalue())
            mlflow_manager.log_artifact(
                local_path=str(tmp_path),
                artifact_path=f"checkpoints/step_{step}",
            )
        console.print(
            f"[green]Checkpoint uploaded to MLflow: step_{step}[/green]"
        )
    else:
        # S3Managerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì €ì¥
        from src.utils.s3 import S3Manager

        s3_manager = S3Manager()
        s3_key = checkpoint_path.replace("s3://wmtp/", "")
        s3_manager.upload_from_bytes(buffer.getvalue(), s3_key)
        console.print(
            f"[green]Checkpoint saved to S3: {checkpoint_path}[/green]"
        )
```

**After**:
```python
# S3 ì €ì¥ (MLflow ìš°íšŒ)
if checkpoint_path.startswith("s3://"):
    import io
    from src.utils.s3 import S3Manager

    buffer = io.BytesIO()
    torch.save(checkpoint, buffer)
    buffer.seek(0)

    s3_manager = S3Manager()
    s3_key = checkpoint_path.replace("s3://wmtp/", "")
    s3_manager.upload_from_bytes(buffer.getvalue(), s3_key)
    console.print(
        f"[green]Checkpoint saved to S3: {checkpoint_path}[/green]"
    )
```

**ë³€ê²½ ìš”ì•½**:
- ì‚­ì œ: MLflow ì—…ë¡œë“œ ë¡œì§ (tmpdir ìƒì„± ë° log_artifact)
- ì‚­ì œ: if mlflow_manager ì¡°ê±´ë¬¸
- ìœ ì§€: S3 ì§ì ‘ ì—…ë¡œë“œ ë¡œì§
- ê°„ì†Œí™”: import ì •ë¦¬ (tempfile, Path ì œê±°)

#### ë³€ê²½ 3: ë¡œì»¬ ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° (Line 405-417)

**Before**:
```python
else:
    # ë¡œì»¬ ì €ì¥
    torch.save(checkpoint, checkpoint_path)
    console.print(
        f"[green]Checkpoint saved locally: {checkpoint_path}[/green]"
    )

    # MLflowì—ë„ ê¸°ë¡ (ìˆëŠ” ê²½ìš°)
    if mlflow_manager:
        mlflow_manager.log_artifact(
            local_path=checkpoint_path, artifact_path="checkpoints"
        )
```

**After**:
```python
else:
    # ë¡œì»¬ ì €ì¥ (í›ˆë ¨ ì¬ê°œìš©)
    torch.save(checkpoint, checkpoint_path)
    console.print(
        f"[green]Checkpoint saved locally: {checkpoint_path}[/green]"
    )
```

**ë³€ê²½ ìš”ì•½**:
- ì‚­ì œ: MLflow ì—…ë¡œë“œ ì „ì²´ (Line 412-416)
- ì£¼ì„ ìˆ˜ì •: "ë¡œì»¬ ì €ì¥" â†’ "ë¡œì»¬ ì €ì¥ (í›ˆë ¨ ì¬ê°œìš©)"

### 1.2. ê²€ì¦ ë°©ë²•

#### 1.2.1. ì½”ë“œ ë¦¬ë·°
```bash
# ë³€ê²½ ì‚¬í•­ í™•ì¸
git diff src/utils/distribute_manager.py

# ê¸°ëŒ€:
# - Line 320-340: Docstring ì—…ë°ì´íŠ¸
# - Line 372-404: S3 ê²½ë¡œ MLflow ì½”ë“œ ì‚­ì œ
# - Line 405-417: ë¡œì»¬ ê²½ë¡œ MLflow ì½”ë“œ ì‚­ì œ
```

#### 1.2.2. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Dry-run)
```bash
# ì„¤ì • ê²€ì¦ë§Œ (ì‹¤ì œ í›ˆë ¨ X)
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config tests/configs/config.local_test.yaml \
    --recipe tests/configs/recipe.mtp_baseline.yaml \
    --run-name test_phase1_dryrun \
    --tags test,phase1 \
    --dry-run \
    --verbose
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ì„¤ì • ê²€ì¦ í†µê³¼
- âœ… ì—ëŸ¬ ì—†ìŒ

#### 1.2.3. ì‹¤ì œ í›ˆë ¨ (10 step)
```bash
# ì§§ì€ í›ˆë ¨ìœ¼ë¡œ checkpoint ì €ì¥ í™•ì¸
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config tests/configs/config.local_test.yaml \
    --recipe tests/configs/recipe.mtp_baseline.yaml \
    --run-name test_phase1_training \
    --tags test,phase1 \
    --verbose 2>&1 | tee /tmp/phase1_training.log
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… í›ˆë ¨ ì •ìƒ ì™„ë£Œ
- âœ… ë¡œì»¬ checkpoint ì €ì¥ í™•ì¸: `ls -lh ./test_checkpoints/*/checkpoint_*.pt`
- âœ… MLflow artifacts ì—†ìŒ í™•ì¸: `ls -lh /tmp/mlflow_m3/{run_id}/artifacts/checkpoints/` â†’ ì—†ì–´ì•¼ í•¨

### 1.3. ì™„ë£Œ ê¸°ì¤€

- [ ] Docstring ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] S3 ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° ì™„ë£Œ
- [ ] ë¡œì»¬ ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° ì™„ë£Œ
- [ ] Dry-run í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì‹¤ì œ í›ˆë ¨ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] MLflow artifacts/checkpoints ë””ë ‰í† ë¦¬ ì—†ìŒ í™•ì¸
- [ ] ë¡œì»¬ checkpoint ì •ìƒ ì €ì¥ í™•ì¸

### 1.4. ì›ì¹™ 5: ê³„íš ëŒ€ë¹„ ê²€ì¦ ë° ë³´ê³ 

**ê³„íš ëª©í‘œ**:
```
âœ… distribute_manager.py ì¤‘ë³µ ì—…ë¡œë“œ ì œê±°
âœ… Docstring ì—…ë°ì´íŠ¸
âœ… S3/ë¡œì»¬ ëª¨ë‘ MLflow ìš°íšŒ
```

**ì‹¤ì œ ë‹¬ì„± (ë³´ê³  í˜•ì‹)**:
```
[Phase 1 ì™„ë£Œ ë³´ê³ ]

ë³€ê²½ íŒŒì¼: src/utils/distribute_manager.py
ë³€ê²½ ë¼ì¸: 3ê°œ ì„¹ì…˜ (Docstring, S3 ë¡œì§, ë¡œì»¬ ë¡œì§)

ê³„íš ëŒ€ë¹„:
âœ… Docstring ì—…ë°ì´íŠ¸ (ì—­í•  ë¶„ë¦¬ ëª…ì‹œ)
âœ… S3 ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° (Line 383-393 ì‚­ì œ)
âœ… ë¡œì»¬ ê²½ë¡œ MLflow ì—…ë¡œë“œ ì œê±° (Line 412-416 ì‚­ì œ)

ê²€ì¦ ê²°ê³¼:
âœ… Dry-run í…ŒìŠ¤íŠ¸ í†µê³¼
âœ… ì‹¤ì œ í›ˆë ¨ 10 step ì •ìƒ ì™„ë£Œ
âœ… ë¡œì»¬ checkpoint ì •ìƒ ì €ì¥ (checkpoint_step_1.pt ì¡´ì¬)
âœ… MLflow artifacts/checkpoints ì—†ìŒ (ì¤‘ë³µ ì œê±° í™•ì¸)

ì˜ˆìƒ íš¨ê³¼ ë‹¬ì„±:
âœ… ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ 0íšŒ (ê¸°ì¡´ 30íšŒ)
âœ… ì €ì¥ ì‹œê°„ ë‹¨ì¶• (MLflow ì—…ë¡œë“œ ì œê±°)

ë²ˆì™¸ ë°œê²¬ì‚¬í•­: ì—†ìŒ
```

---

## ğŸ“ Phase 2: base_wmtp_trainer.py ìµœì¢… ëª¨ë¸ MLflow ë“±ë¡

**ëª©í‘œ**: _save_final_checkpointì—ì„œ MLflow ëª…ì‹œì  ì²˜ë¦¬

### ì›ì¹™ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì›ì¹™ 1**: _save_final_checkpoint ë©”ì„œë“œ ì „ì²´ ì½ê¸° (Line 151-218)
- [ ] **ì›ì¹™ 2**: ê¸°ì¡´ ì €ì¥ ë¡œì§ ìœ ì§€, MLflow ì²˜ë¦¬ë§Œ ê°•í™”
- [ ] **ì›ì¹™ 3**: ìŠ¹ì¸ëœ ìˆ˜ì • (ìµœì¢… ëª¨ë¸ë§Œ MLflow)
- [ ] **ì›ì¹™ 4-1**: ë³€ìˆ˜ëª… í†µì¼ (final_path), ì£¼ì„ ì¼ê´€ì„±
- [ ] **ì›ì¹™ 4-2**: log_model, log_artifact ì§ì ‘ í˜¸ì¶œ (wrapper ì—†ìŒ)
- [ ] **ì›ì¹™ 4-3**: "Phase 3" ì œê±°, ì—­í•  ì„¤ëª…ë§Œ
- [ ] **ì›ì¹™ 5**: ë³€ê²½ í›„ ê³„íš ëŒ€ë¹„ ê²€ì¦
- [ ] **ì›ì¹™ 6**: uv runìœ¼ë¡œ í…ŒìŠ¤íŠ¸

### 2.1. ì½”ë“œ ë³€ê²½

**íŒŒì¼**: `src/components/trainer/base_wmtp_trainer.py`

#### ë³€ê²½: _save_final_checkpoint ìˆ˜ì • (Line 151-218)

**Before** (Line 151-218):
```python
def _save_final_checkpoint(self, epoch: int, step: int, metrics: dict) -> str:
    """
    ìµœì¢… ëª¨ë¸ ì €ì¥ (Phase 3: S3/ë¡œì»¬ ìë™ íŒë‹¨)

    Args:
        epoch: ìµœì¢… ì—í­
        step: ìµœì¢… ìŠ¤í…
        metrics: ìµœì¢… ë©”íŠ¸ë¦­

    Returns:
        ì €ì¥ëœ ìµœì¢… ëª¨ë¸ ê²½ë¡œ (ë¬¸ìì—´)
    """
    # S3/ë¡œì»¬ ìë™ íŒë‹¨í•˜ì—¬ ìµœì¢… ëª¨ë¸ ê²½ë¡œ ìƒì„±
    if self.is_s3_checkpoint:
        # S3 ê²½ë¡œ: ë¬¸ìì—´ ê²°í•©
        final_path = f"{self.checkpoint_dir}/final_model.pt"
    else:
        # ë¡œì»¬ ê²½ë¡œ: Path ê°ì²´ ì‚¬ìš©
        final_path = str(self.checkpoint_dir / "final_model.pt")

    # ìµœì¢… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (MLflow í†µí•©)
    self.dist_manager.save_checkpoint(
        model=self.model,
        optimizer=self.optimizer,
        checkpoint_path=final_path,
        epoch=epoch,
        step=step,
        mlflow_manager=self.mlflow,  # MLflow ë§¤ë‹ˆì € ì „ë‹¬
        metrics=metrics,
        algorithm=getattr(self, "algorithm", "wmtp"),
        final_model=True,
        mlflow_run_id=self.mlflow.get_run_id() if self.mlflow else None,
    )

    # MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ë° ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
    if self.mlflow is not None:
        try:
            # ëª¨ë¸ ì´ë¦„ ìƒì„± (recipeì—ì„œ ì•Œê³ ë¦¬ì¦˜ ì •ë³´ ì‚¬ìš©)
            model_name = f"wmtp-{self.algorithm}"

            # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡
            self.mlflow.log_model(
                model=self.model,
                name="final_model",
                registered_model_name=model_name,
            )

            # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—…ë¡œë“œ (ë¡œì»¬ ê²½ë¡œë§Œ ì§€ì›)
            if not self.is_s3_checkpoint:
                self.mlflow.log_artifact(
                    local_path=final_path, artifact_path="final_checkpoint"
                )
            else:
                console.print(
                    "[blue]S3 ì²´í¬í¬ì¸íŠ¸ëŠ” MLflow artifact ì—…ë¡œë“œ ìƒëµ[/blue]"
                )

            console.print(f"[green]MLflow ëª¨ë¸ ë“±ë¡ ì™„ë£Œ: {model_name}[/green]")
        except Exception as e:
            console.print(
                f"[yellow]MLflow model registration warning: {e}[/yellow]"
            )

    storage_type = "S3" if self.is_s3_checkpoint else "ë¡œì»¬"
    console.print(
        f"[green]{storage_type} ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_path}[/green]"
    )
    return final_path
```

**After**:
```python
def _save_final_checkpoint(self, epoch: int, step: int, metrics: dict) -> str:
    """
    ìµœì¢… ëª¨ë¸ ì €ì¥ ë° MLflow ë“±ë¡

    ì—­í• :
    - paths.checkpointsì— final_model.pt ì €ì¥ (í›ˆë ¨ ì¬ê°œìš©)
    - MLflowì— ëª¨ë¸ ë“±ë¡ ë° artifact ì—…ë¡œë“œ (ì‹¤í—˜ ì¶”ì ìš©)

    Args:
        epoch: ìµœì¢… ì—í­
        step: ìµœì¢… ìŠ¤í…
        metrics: ìµœì¢… ë©”íŠ¸ë¦­

    Returns:
        ì €ì¥ëœ ìµœì¢… ëª¨ë¸ ê²½ë¡œ
    """
    # 1. paths.checkpointsì— ì €ì¥
    if self.is_s3_checkpoint:
        final_path = f"{self.checkpoint_dir}/final_model.pt"
    else:
        final_path = str(self.checkpoint_dir / "final_model.pt")

    # Early stopping ìƒíƒœ ìˆ˜ì§‘
    es_state = self.early_stopping.get_state() if self.early_stopping else None

    # ì €ì¥ (MLflow ì „ë‹¬í•˜ì§€ ì•ŠìŒ - ì•„ë˜ì—ì„œ ë³„ë„ ì²˜ë¦¬)
    self.dist_manager.save_checkpoint(
        model=self.model,
        optimizer=self.optimizer,
        checkpoint_path=final_path,
        epoch=epoch,
        step=step,
        mlflow_manager=None,  # ì¤‘ë³µ ë°©ì§€
        metrics=metrics,
        algorithm=self.algorithm,
        mlflow_run_id=self.mlflow.get_run_id() if self.mlflow else None,
        early_stopping_state=es_state,
    )

    storage_type = "S3" if self.is_s3_checkpoint else "ë¡œì»¬"
    console.print(
        f"[green]{storage_type} ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_path}[/green]"
    )

    # 2. MLflowì— ëª¨ë¸ ë“±ë¡ ë° artifact ì—…ë¡œë“œ
    if self.mlflow:
        try:
            # 2-1. PyTorch ëª¨ë¸ ë“±ë¡ (Model Registry)
            model_name = f"wmtp_{self.algorithm}"
            self.mlflow.log_model(
                model=self.model,
                name="final_model",
                registered_model_name=model_name,
            )
            console.print(
                f"[cyan]MLflow ëª¨ë¸ ë“±ë¡ ì™„ë£Œ: {model_name}[/cyan]"
            )

            # 2-2. Checkpoint artifact ì—…ë¡œë“œ (ë¡œì»¬ì¸ ê²½ìš°ë§Œ)
            if not self.is_s3_checkpoint:
                self.mlflow.log_artifact(
                    local_path=final_path,
                    artifact_path="checkpoints",
                )
                console.print(
                    "[cyan]MLflow artifact ì—…ë¡œë“œ: checkpoints/final_model.pt[/cyan]"
                )
            else:
                # S3 ê²½ë¡œëŠ” ì°¸ì¡°ë§Œ ê¸°ë¡
                self.mlflow.log_param("final_checkpoint_s3_path", final_path)
                console.print(
                    f"[cyan]MLflowì— S3 ê²½ë¡œ ê¸°ë¡: {final_path}[/cyan]"
                )

            # 2-3. ìµœì¢… ë©”íŠ¸ë¦­ ê¸°ë¡
            self.mlflow.log_metrics(
                {
                    "final/epoch": epoch,
                    "final/step": step,
                    **{f"final/{k}": v for k, v in metrics.items()},
                }
            )
        except Exception as e:
            console.print(
                f"[yellow]MLflow ë“±ë¡ ì‹¤íŒ¨ (ì²´í¬í¬ì¸íŠ¸ëŠ” ì €ì¥ë¨): {e}[/yellow]"
            )

    return final_path
```

**ë³€ê²½ ìš”ì•½**:
1. **Docstring ê°„ì†Œí™”**: "Phase 3" ì œê±°, ì—­í•  ëª…ì‹œ
2. **mlflow_manager=None ì „ë‹¬**: distribute_managerì—ì„œ ì¤‘ë³µ ì—…ë¡œë“œ ë°©ì§€
3. **ëª…ì‹œì  MLflow ì²˜ë¦¬**: log_model, log_artifact, log_metrics ì§ì ‘ í˜¸ì¶œ
4. **S3 ê²½ë¡œ ì²˜ë¦¬**: log_paramìœ¼ë¡œ ê²½ë¡œë§Œ ê¸°ë¡ (ì¤‘ë³µ ë°©ì§€)
5. **Early stopping ìƒíƒœ**: ëˆ„ë½ë˜ì—ˆë˜ es_state ì¶”ê°€
6. **ì£¼ì„ ì •ë¦¬**: ë‹¨ê³„ë³„ ì„¤ëª… (1. ì €ì¥, 2. MLflow)
7. **ì—ëŸ¬ í•¸ë“¤ë§**: MLflow ì‹¤íŒ¨í•´ë„ checkpoint ì €ì¥ ë³´ì¥

### 2.2. ê²€ì¦ ë°©ë²•

#### 2.2.1. ì½”ë“œ ë¦¬ë·°
```bash
# ë³€ê²½ ì‚¬í•­ í™•ì¸
git diff src/components/trainer/base_wmtp_trainer.py

# ê¸°ëŒ€:
# - Docstring ê°„ì†Œí™”
# - mlflow_manager=None ì „ë‹¬
# - ëª…ì‹œì  MLflow ì²˜ë¦¬ ì¶”ê°€
# - early_stopping_state ì¶”ê°€
```

#### 2.2.2. ì „ì²´ í›ˆë ¨ (ìµœì¢… ëª¨ë¸ê¹Œì§€)
```bash
# ì „ì²´ í›ˆë ¨ ì‹¤í–‰ (30 step, save_final=true)
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config tests/configs/config.local_test.yaml \
    --recipe tests/configs/recipe.mtp_baseline.yaml \
    --run-name test_phase2_final \
    --tags test,phase2 \
    --verbose 2>&1 | tee /tmp/phase2_final.log
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… í›ˆë ¨ ì •ìƒ ì™„ë£Œ
- âœ… ë¡œì»¬ checkpoint í™•ì¸:
  ```bash
  ls -lh ./test_checkpoints/*/
  # checkpoint_step_1.pt (ì¤‘ê°„)
  # final_model.pt (ìµœì¢…)
  ```
- âœ… MLflow ëª¨ë¸ ë“±ë¡ í™•ì¸:
  ```bash
  mlflow ui --backend-store-uri file:///tmp/mlflow_m3
  # Models íƒ­ì— "wmtp_baseline-mtp" ì¡´ì¬
  ```
- âœ… MLflow artifacts í™•ì¸:
  ```bash
  ls -lh /tmp/mlflow_m3/{run_id}/artifacts/checkpoints/
  # final_model.ptë§Œ ì¡´ì¬ (checkpoint_step_*.pt ì—†ìŒ)
  ```

### 2.3. ì™„ë£Œ ê¸°ì¤€

- [ ] Docstring ì—…ë°ì´íŠ¸ ì™„ë£Œ ("Phase 3" ì œê±°)
- [ ] mlflow_manager=None ì „ë‹¬ (ì¤‘ë³µ ë°©ì§€)
- [ ] ëª…ì‹œì  MLflow ì²˜ë¦¬ êµ¬í˜„ (log_model, log_artifact, log_metrics)
- [ ] Early stopping ìƒíƒœ ì €ì¥ ì¶”ê°€
- [ ] ì „ì²´ í›ˆë ¨ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] MLflow Model Registryì— ëª¨ë¸ ë“±ë¡ í™•ì¸
- [ ] MLflow artifactsì— final_model.ptë§Œ ì¡´ì¬ í™•ì¸
- [ ] ì¤‘ê°„ checkpointëŠ” MLflowì— ì—†ìŒ í™•ì¸

### 2.4. ì›ì¹™ 5: ê³„íš ëŒ€ë¹„ ê²€ì¦ ë° ë³´ê³ 

**ê³„íš ëª©í‘œ**:
```
âœ… _save_final_checkpoint ìˆ˜ì •
âœ… mlflow_manager=None ì „ë‹¬
âœ… ìµœì¢… ëª¨ë¸ë§Œ MLflow ë“±ë¡
```

**ì‹¤ì œ ë‹¬ì„± (ë³´ê³  í˜•ì‹)**:
```
[Phase 2 ì™„ë£Œ ë³´ê³ ]

ë³€ê²½ íŒŒì¼: src/components/trainer/base_wmtp_trainer.py
ë³€ê²½ ë¼ì¸: _save_final_checkpoint ë©”ì„œë“œ ì „ì²´ (Line 151-218)

ê³„íš ëŒ€ë¹„:
âœ… Docstring ê°„ì†Œí™” (ì—­í•  ëª…ì‹œ, Phase ë²ˆí˜¸ ì œê±°)
âœ… mlflow_manager=None ì „ë‹¬ (ì¤‘ë³µ ë°©ì§€)
âœ… ëª…ì‹œì  MLflow ì²˜ë¦¬ (log_model, log_artifact, log_metrics)
âœ… S3 ê²½ë¡œ ì²˜ë¦¬ (log_paramìœ¼ë¡œ ì°¸ì¡° ê¸°ë¡)

ê²€ì¦ ê²°ê³¼:
âœ… ì „ì²´ í›ˆë ¨ (30 step) ì •ìƒ ì™„ë£Œ
âœ… ë¡œì»¬ checkpoint ì •ìƒ ì €ì¥ (checkpoint_step_*.pt, final_model.pt)
âœ… MLflow Model Registry ë“±ë¡ í™•ì¸ (wmtp_baseline-mtp)
âœ… MLflow artifactsì— final_model.ptë§Œ ì¡´ì¬
âœ… ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ 0íšŒ

ì˜ˆìƒ íš¨ê³¼ ë‹¬ì„±:
âœ… ìµœì¢… ëª¨ë¸ë§Œ MLflow ë“±ë¡ (1íšŒ)
âœ… ì¤‘ë³µ ì €ì¥ ì™„ì „ ì œê±° (86% ì ˆê°)

ë²ˆì™¸ ë°œê²¬ì‚¬í•­:
âš ï¸ Early stopping ìƒíƒœê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ â†’ ì¶”ê°€ ì™„ë£Œ
```

---

## ğŸ“ Phase 3: ë¬¸ì„œí™” ë° ì£¼ì„ ì •ë¦¬

**ëª©í‘œ**: ì—­í•  ë¶„ë¦¬ ë¬¸ì„œí™” ë° ë¶ˆí•„ìš”í•œ ì£¼ì„ ì œê±° (ì›ì¹™ 4-3)

### ì›ì¹™ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì›ì¹™ 4-3**: Phase ë²ˆí˜¸ ì£¼ì„ ì™„ì „ ì œê±°
- [ ] **ì›ì¹™ 4-3**: ì½”ë“œ ë™ì‘ í•µì‹¬ ì„¤ëª…ë§Œ ìœ ì§€
- [ ] **ì›ì¹™ 5**: ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦

### 3.1. ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸

**íŒŒì¼**: `docs/WMTP_ì‹œìŠ¤í…œ_ì•„í‚¤í…ì²˜.md`

**ì¶”ê°€ ì„¹ì…˜**:
```markdown
### Checkpoint ê´€ë¦¬ ì‹œìŠ¤í…œ

WMTPëŠ” ì—­í•  ê¸°ë°˜ ì´ì¤‘ ì €ì¥ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

#### 1. Training Checkpoints (paths.checkpoints)
**ëª©ì **: í›ˆë ¨ ì¬ê°œ (Resume Training)

- ì €ì¥ ëŒ€ìƒ: ì£¼ê¸°ì  checkpoint (save_intervalë§ˆë‹¤)
- ê´€ë¦¬ ì •ì±…: keep_last (ì˜¤ë˜ëœ ìë™ ì‚­ì œ)
- ì €ì¥ ìœ„ì¹˜: Config ì„¤ì • (S3 ë˜ëŠ” ë¡œì»¬)
- ì ‘ê·¼ ë°©ë²•: íŒŒì¼ ì‹œìŠ¤í…œ ì§ì ‘
- ìƒëª…ì£¼ê¸°: Ephemeral (í›ˆë ¨ ì™„ë£Œ í›„ ì‚­ì œ ê°€ëŠ¥)

#### 2. MLflow Artifacts
**ëª©ì **: ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ë°°í¬

- ì €ì¥ ëŒ€ìƒ: ìµœì¢… ëª¨ë¸ë§Œ (save_final=true)
- ê´€ë¦¬ ì •ì±…: ì˜êµ¬ ë³´ì¡´ (ë²„ì „ ê´€ë¦¬)
- ì €ì¥ ìœ„ì¹˜: MLflow tracking_uri/artifacts
- ì ‘ê·¼ ë°©ë²•: MLflow API/UI
- ìƒëª…ì£¼ê¸°: Persistent (ì˜êµ¬ ë³´ì¡´)

#### ì„¤ê³„ ì² í•™
- Separation of Concerns: í›ˆë ¨ ì¬ê°œ vs ì‹¤í—˜ ì¶”ì  ì—­í•  ë¶„ë¦¬
- Cost Optimization: ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ ì œê±° (86% ì ˆê°)
- Flexibility: ê° ì‹œìŠ¤í…œ ë…ë¦½ì  ì„¤ì • ê°€ëŠ¥
```

### 3.2. Config ì£¼ì„ ê°œì„ 

**íŒŒì¼**: `tests/configs/config.local_test.yaml`

**Before**:
```yaml
paths:
  checkpoints:
    base_path: "file://./test_checkpoints"
    save_interval: 100
    keep_last: 1
    save_final: true

mlflow:
  experiment: "wmtp/m3_test_critic"
  tracking_uri: "file:///tmp/mlflow_m3"
  registry_uri: "file:///tmp/mlflow_m3"
```

**After**:
```yaml
paths:
  checkpoints:
    base_path: "file://./test_checkpoints"
    save_interval: 100    # í…ŒìŠ¤íŠ¸: ìì£¼ ì €ì¥í•˜ì—¬ ì¬ê°œ ë¡œì§ ê²€ì¦
    keep_last: 1          # í…ŒìŠ¤íŠ¸: ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½
    save_final: true      # ìµœì¢… ëª¨ë¸ì€ MLflowì—ë„ ë“±ë¡

mlflow:
  experiment: "wmtp/m3_test_critic"
  tracking_uri: "file:///tmp/mlflow_m3"
  registry_uri: "file:///tmp/mlflow_m3"
  # Note: ì¤‘ê°„ checkpointëŠ” MLflowì— ì—…ë¡œë“œë˜ì§€ ì•ŠìŒ (final_modelë§Œ)
```

### 3.3. ì™„ë£Œ ê¸°ì¤€

- [ ] ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] Config ì£¼ì„ ê°œì„  ì™„ë£Œ
- [ ] ë¬¸ì„œ ë§í¬ í™•ì¸ (checkpoint, mlflow ê²€ìƒ‰)
- [ ] ì£¼ì„ ì¼ê´€ì„± í™•ì¸ (configs/*.yaml, tests/configs/*.yaml)

---

## ğŸ“ Phase 4: ìµœì¢… ê²€ì¦ ë° ì„±ê³¼ ë³´ê³ 

**ëª©í‘œ**: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê³„íš ëŒ€ë¹„ 100% ë‹¬ì„± ê²€ì¦ (ì›ì¹™ 5)

### ì›ì¹™ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì›ì¹™ 5**: ê³„íšì„œ ëŒ€ë¹„ ì „ì²´ ê²€ì¦
- [ ] **ì›ì¹™ 5**: ì„±ê³¼ ê°ê´€ì  ê¸°ìˆ 
- [ ] **ì›ì¹™ 5-1**: ë²ˆì™¸ ë°œê²¬ì‚¬í•­ ë³´ê³ 
- [ ] **ì›ì¹™ 6**: uv í™˜ê²½ ì‚¬ìš© í™•ì¸

### 4.1. í†µí•© í…ŒìŠ¤íŠ¸

#### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ë¡œì»¬ í›ˆë ¨ ì „ì²´ íë¦„
```bash
# 1. ì „ì²´ í›ˆë ¨ ì‹¤í–‰
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config tests/configs/config.local_test.yaml \
    --recipe tests/configs/recipe.critic_wmtp.yaml \
    --run-name integration_test_final \
    --tags test,integration,final \
    --verbose 2>&1 | tee /tmp/integration_test.log

# 2. ì €ì¥ í™•ì¸
tree ./test_checkpoints/
# ê¸°ëŒ€:
# test_checkpoints/
#   â””â”€â”€ {run_id}/
#       â”œâ”€â”€ checkpoint_step_1.pt
#       â”œâ”€â”€ checkpoint_step_2.pt
#       â””â”€â”€ final_model.pt

tree /tmp/mlflow_m3/{run_id}/artifacts/
# ê¸°ëŒ€:
# artifacts/
#   â””â”€â”€ checkpoints/
#       â””â”€â”€ final_model.pt  (ì´ê²ƒë§Œ!)

# 3. í›ˆë ¨ ì¬ê°œ í…ŒìŠ¤íŠ¸
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config tests/configs/config.local_test.yaml \
    --recipe tests/configs/recipe.critic_wmtp.yaml \
    --resume-checkpoint ./test_checkpoints/{run_id}/checkpoint_step_5.pt \
    --run-name integration_test_resume \
    --verbose
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… ì „ì²´ í›ˆë ¨ ì •ìƒ ì™„ë£Œ
- âœ… ë¡œì»¬ì— ëª¨ë“  checkpoint ì¡´ì¬
- âœ… MLflowì— final_model.ptë§Œ ì¡´ì¬
- âœ… í›ˆë ¨ ì¬ê°œ ì •ìƒ ë™ì‘

#### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: S3 Dry-run
```bash
# S3 ê²½ë¡œ ì„¤ì • ê²€ì¦
export PYTHONPATH=. && uv run python -m src.cli.train \
    --config configs/config.vessl.yaml \
    --recipe configs/recipe.critic_wmtp.yaml \
    --run-name integration_test_s3 \
    --tags test,s3,dryrun \
    --dry-run \
    --verbose
```

**ê¸°ëŒ€ ê²°ê³¼**:
- âœ… Dry-run í†µê³¼
- âœ… S3 ê²½ë¡œ í•´ì„ ì •ìƒ

### 4.2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

**ì €ì¥ ì‹œê°„ ì¸¡ì •**:
```bash
# Before vs After ë¹„êµ
grep "Checkpoint saved" /tmp/integration_test.log

# ê¸°ëŒ€:
# - "Checkpoint saved locally" ì¶œë ¥ë§Œ (MLflow ì—…ë¡œë“œ ë©”ì‹œì§€ ì—†ìŒ)
# - ì €ì¥ ì‹œê°„ ë‹¨ì¶• (MLflow ì—…ë¡œë“œ ì œê±°)
```

**ì €ì¥ëŸ‰ ì¸¡ì •**:
```bash
# ë¡œì»¬ checkpoint í¬ê¸°
du -sh ./test_checkpoints/*/

# MLflow artifacts í¬ê¸°
du -sh /tmp/mlflow_m3/{run_id}/artifacts/checkpoints/

# ê¸°ëŒ€:
# - MLflowëŠ” final_model.ptë§Œ (1ê°œ)
# - ë¡œì»¬ì€ ëª¨ë“  checkpoint (Nê°œ)
```

### 4.3. íšŒê·€ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ê¸°ì¡´ ê¸°ëŠ¥ ë³´ì¡´**
  - [ ] í›ˆë ¨ ì •ìƒ ì™„ë£Œ
  - [ ] Checkpoint ì €ì¥ ì •ìƒ
  - [ ] í›ˆë ¨ ì¬ê°œ ì •ìƒ
  - [ ] Early stopping ë™ì‘
  - [ ] FSDP ë¶„ì‚° í›ˆë ¨ ì •ìƒ

- [ ] **MLflow í†µí•©**
  - [ ] ìµœì¢… ëª¨ë¸ ë“±ë¡ í™•ì¸
  - [ ] Metrics ë¡œê¹… ì •ìƒ
  - [ ] Artifacts ì—…ë¡œë“œ ì •ìƒ (finalë§Œ)
  - [ ] Model Registry ì •ìƒ

- [ ] **ì €ì¥ ìµœì í™”**
  - [ ] ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ ì—†ìŒ
  - [ ] ì €ì¥ ì‹œê°„ ë‹¨ì¶• í™•ì¸
  - [ ] ì €ì¥ëŸ‰ ê°ì†Œ í™•ì¸

### 4.4. Rollback ì „ëµ

**Rollback íŠ¸ë¦¬ê±°**:
- í›ˆë ¨ ì¬ê°œ ì‹¤íŒ¨
- MLflow ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨
- ì„±ëŠ¥ ì €í•˜ (ì €ì¥ ì‹œê°„ ì¦ê°€)

**Rollback ì ˆì°¨**:
```bash
# Git revert
git revert HEAD~2  # Phase 1, 2 ëª¨ë‘ revert

# ë˜ëŠ” ìˆ˜ë™ ë³µì›
# distribute_manager.py Line 412-416 ë³µì›
# base_wmtp_trainer.py mlflow_manager ì „ë‹¬ ë³µì›
```

### 4.5. ì›ì¹™ 5: ìµœì¢… ì„±ê³¼ ë³´ê³ 

**ê³„íš ëª©í‘œ**:
```
âœ… ì¤‘ë³µ ì €ì¥ ì œê±°
âœ… ì €ì¥ ë¹„ìš© 86% ì ˆê°
âœ… ì—­í•  ëª…í™•í™”
âœ… ì„¤ì • ê°„ì†Œí™”
```

**ì‹¤ì œ ë‹¬ì„± (ìµœì¢… ë³´ê³ )**:
```
[ìµœì¢… ì„±ê³¼ ë³´ê³ ]

ë³€ê²½ íŒŒì¼: 2ê°œ
- src/utils/distribute_manager.py (Line 320-417)
- src/components/trainer/base_wmtp_trainer.py (Line 151-218)

ë³€ê²½ ë¼ì¸: ì•½ 30ì¤„
- ì‚­ì œ: 15ì¤„ (MLflow ìë™ ì—…ë¡œë“œ ë¡œì§)
- ì¶”ê°€: 15ì¤„ (ëª…ì‹œì  MLflow ì²˜ë¦¬)

ê³„íš ëŒ€ë¹„ ë‹¬ì„±:
âœ… Phase 0: ì‚¬ì „ ë¶„ì„ ì™„ë£Œ (ì½”ë“œ íë¦„ íŒŒì•…)
âœ… Phase 1: distribute_manager.py ì¤‘ë³µ ì—…ë¡œë“œ ì œê±°
âœ… Phase 2: base_wmtp_trainer.py ìµœì¢… ëª¨ë¸ MLflow ë“±ë¡
âœ… Phase 3: ë¬¸ì„œí™” ë° ì£¼ì„ ì •ë¦¬
âœ… Phase 4: í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼

ê²€ì¦ ê²°ê³¼:
âœ… ë¡œì»¬ í›ˆë ¨ ì „ì²´ íë¦„ ì •ìƒ
âœ… í›ˆë ¨ ì¬ê°œ ì •ìƒ ë™ì‘
âœ… MLflow ëª¨ë¸ ë“±ë¡ ì •ìƒ
âœ… ì¤‘ê°„ checkpoint MLflow ì—…ë¡œë“œ 0íšŒ
âœ… ìµœì¢… ëª¨ë¸ë§Œ MLflow ë“±ë¡ (1íšŒ)

ì •ëŸ‰ì  íš¨ê³¼:
âœ… ì €ì¥ ë¹„ìš© 86% ì ˆê° (420GB â†’ 0GB, MLflow ì¤‘ê°„ checkpoint)
âœ… ì €ì¥ ì‹œê°„ ë‹¨ì¶• (MLflow ì—…ë¡œë“œ ì œê±°)
âœ… ë„¤íŠ¸ì›Œí¬ ë¹„ìš© 50% ì ˆê° (ì—…ë¡œë“œ ëŒ€ì—­í­)

ì •ì„±ì  íš¨ê³¼:
âœ… ì—­í•  ëª…í™•í™” (í›ˆë ¨ ì¬ê°œ vs ì‹¤í—˜ ì¶”ì )
âœ… ì„¤ì • ê°„ì†Œí™” (í…ŒìŠ¤íŠ¸ í™˜ê²½)
âœ… ì½”ë“œ ê°€ë…ì„± í–¥ìƒ (ëª…ì‹œì  ì²˜ë¦¬)

ë²ˆì™¸ ë°œê²¬ì‚¬í•­:
âš ï¸ Early stopping ìƒíƒœê°€ _save_final_checkpointì— ëˆ„ë½
   â†’ Phase 2ì—ì„œ ì¶”ê°€ ì™„ë£Œ (early_stopping_state íŒŒë¼ë¯¸í„°)
âœ… S3 ê²½ë¡œ ì²˜ë¦¬ ê°œì„ 
   â†’ log_paramìœ¼ë¡œ ì°¸ì¡°ë§Œ ê¸°ë¡ (ì¤‘ë³µ ë°©ì§€)
```

**ê°œë°œ ì›ì¹™ ì¤€ìˆ˜ í‰ê°€**:
```
ì›ì¹™ 1 (ì•/ë’¤ íë¦„ í™•ì¸): âœ… Phase 0ì—ì„œ ì „ì²´ íë¦„ ë¶„ì„ ì™„ë£Œ
ì›ì¹™ 2 (ê¸°ì¡´ êµ¬ì¡° ì¡´ì¤‘): âœ… ì €ì¥ ë¡œì§ ìœ ì§€, MLflow ë¶€ë¶„ë§Œ ìˆ˜ì •
ì›ì¹™ 3 (ì‚­ì œ vs ìˆ˜ì • ê²€í† ): âœ… ìŠ¹ì¸ëœ Option 3 ì ìš©
ì›ì¹™ 4 (ê¹¨ë—í•œ ì½”ë“œ): âœ… Phase ë²ˆí˜¸ ì œê±°, í†µì¼ì„± ìœ ì§€
ì›ì¹™ 5 (ê³„íš ëŒ€ë¹„ ê²€ì¦): âœ… ê° Phaseë§ˆë‹¤ ê°ê´€ì  ë³´ê³ 
ì›ì¹™ 6 (íŒ¨í‚¤ì§€ ì˜ì¡´ì„±): âœ… uv run í™œìš©, ì˜ì¡´ì„± ë³€ê²½ ì—†ìŒ
```

---

## âœ… ì™„ë£Œ ê¸°ì¤€

### Phaseë³„ ì™„ë£Œ ì¡°ê±´

- [ ] **Phase 0**: ì‚¬ì „ ë¶„ì„ ì™„ë£Œ âœ…
- [ ] **Phase 1**: distribute_manager.py ìˆ˜ì • ì™„ë£Œ
  - [ ] Docstring ì—…ë°ì´íŠ¸
  - [ ] S3/ë¡œì»¬ MLflow ì—…ë¡œë“œ ì œê±°
  - [ ] Dry-run í…ŒìŠ¤íŠ¸ í†µê³¼
  - [ ] ì‹¤ì œ í›ˆë ¨ í…ŒìŠ¤íŠ¸ í†µê³¼

- [ ] **Phase 2**: base_wmtp_trainer.py ìˆ˜ì • ì™„ë£Œ
  - [ ] _save_final_checkpoint ìˆ˜ì •
  - [ ] mlflow_manager=None ì „ë‹¬
  - [ ] ëª…ì‹œì  MLflow ì²˜ë¦¬ êµ¬í˜„
  - [ ] ì „ì²´ í›ˆë ¨ í…ŒìŠ¤íŠ¸ í†µê³¼
  - [ ] MLflow ëª¨ë¸ ë“±ë¡ í™•ì¸

- [ ] **Phase 3**: ë¬¸ì„œí™” ì™„ë£Œ
  - [ ] ì•„í‚¤í…ì²˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸
  - [ ] Config ì£¼ì„ ê°œì„ 
  - [ ] ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦

- [ ] **Phase 4**: ìµœì¢… ê²€ì¦ ì™„ë£Œ
  - [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
  - [ ] íšŒê·€ í…ŒìŠ¤íŠ¸ í†µê³¼
  - [ ] ì„±ê³¼ ë³´ê³  ì‘ì„±

### ì „ì²´ ì™„ë£Œ ì¡°ê±´

1. âœ… ëª¨ë“  Phase ì™„ë£Œ
2. âœ… ì¤‘ë³µ ì €ì¥ ì™„ì „ ì œê±°
3. âœ… ì—­í•  ë¶„ë¦¬ ëª…í™•í™”
4. âœ… íšŒê·€ í…ŒìŠ¤íŠ¸ í†µê³¼
5. âœ… ê³„íšì„œ ëŒ€ë¹„ 100% ë‹¬ì„±

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë‚´ë¶€ ë¬¸ì„œ
- `docs/WMTP_ì‹œìŠ¤í…œ_ì•„í‚¤í…ì²˜.md` - ì „ì²´ ì•„í‚¤í…ì²˜
- `docs/checkpoint_mlflow_integration_analysis.md` - ìƒì„¸ ë¶„ì„ (ì°¸ê³ ìš©)

### ì½”ë“œ ìœ„ì¹˜
- `src/components/trainer/base_wmtp_trainer.py` (Line 151-218, 559-602)
- `src/utils/distribute_manager.py` (Line 310-417)
- `src/utils/mlflow.py` (Line 234-287)

---

**ì‘ì„±ì**: Claude Code (ê°œë°œ ì›ì¹™ ê¸°ë°˜)
**ìŠ¹ì¸ ëŒ€ê¸°**: Phase 1-4 êµ¬í˜„ ì „ ì‚¬ìš©ì ìµœì¢… ìŠ¹ì¸ í•„ìš”
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-10-02
