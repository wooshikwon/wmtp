# MTP Baseline 실험 - 10분 내 완료용
# 균등한 토큰 가중치를 사용하는 기본 MTP (비교 기준)

run:
  name: "baseline_quick_exp"
  tags:
    - "baseline"
    - "quick"
    - "mtp"
    - "comparison"

# Facebook MTP 모델 사용
model:
  base_id: "facebook/multi-token-prediction"
  ref_id: "codellama/CodeLlama-7b-Python-hf"  # 스키마 요구사항
  tokenizer_pad_side: "right"
  mtp:
    n_heads: 4    # 4개 토큰 동시 예측
    horizon: 4

# 기본선 훈련 설정 - 토큰 가중치 없음
train:
  algo: "mtp-baseline"
  full_finetune: true      # 전체 파인튜닝 (빠른 수렴을 위해)
  lora:
    enabled: false

# 빠른 수렴을 위한 옵티마이저 설정
optim:
  optimizer: "adamw"
  lr: 1.0e-4              # 높은 학습률로 빠른 수렴
  weight_decay: 0.01
  betas: [0.9, 0.999]
  grad_clip: 1.0
  scheduler: "constant"    # 스케줄링 없이 일정한 학습률
  warmup_ratio: 0.0

# 작은 데이터셋으로 빠른 실험
data:
  train:
    sources: ["mbpp"]      # MBPP만 사용 (빠른 로딩)
    max_length: 512        # 짧은 시퀀스
    batch_size: 2          # 작은 배치
    pack_sequences: false  # 패킹 비활성화 (단순화)
  eval:
    sources: ["mbpp"]
    max_length: 512
    batch_size: 4
    pack_sequences: false

# 작은 배치 설정
batching:
  global_batch_tokens: 50000    # 50K 토큰만 (매우 작음)
  micro_batch_size: 1
  grad_accum_steps: 4           # 적은 accumulation

# 기본선 손실 - 균등 가중치
loss:
  weight_norm: "none"           # 정규화 없음
  lambda: 0.01                  # 최소 가중치 (스키마 요구사항)
  temperature: 1.0              # 온도 스케일링 없음
  epsilon: 1e-8
  max_weight: 1.01              # 최소 증폭 (거의 균등)

# 평가 설정 - 간단하게
eval:
  protocol: "meta-mtp"
  sampling:
    temperature: 0.1
    top_p: 0.9
    n: 1                        # 1개 샘플만 생성
  metrics:
    - "mbpp_exact"              # MBPP 정확도만 측정
