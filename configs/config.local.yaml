# Environment Configuration for WMTP Fine-Tuning Framework
# This file contains environment-specific settings

# Project metadata
project: "mtp_ft"
seed: 42

# Storage configuration
storage:
  mode: "local"  # Options: local, s3

# Path configurations
paths:
  models:
    base: "models/7b_1t_4"
    rm: "models/Llama_3_8B_RM"
    ref: "models/codellama_7b_python"
  datasets:
    mbpp: "dataset/mbpp"
    contest: "dataset/contest"

# MLflow configuration
mlflow:
  experiment: "mtp/wmtp"
  tracking_uri: "file:///tmp/mlflow"
  registry_uri: "file:///tmp/mlflow"

# Launcher configuration
launcher:
  target: "local"  # Options: local, vessl
  resources:
    gpus: 4
    gpu_type: "A100"
    cpus: 32
    memory_gb: 256
    disk_gb: 500

# Device and distributed training configuration
devices:
  compute_backend: "auto"  # auto, cuda, mps, cpu
  mixed_precision: "bf16"  # Options: bf16, fp16, fp32
  fsdp:
    enabled: true
    auto_wrap: true
    activation_ckpt: true
    sharding: "full"  # Options: full, shard_grad_op
