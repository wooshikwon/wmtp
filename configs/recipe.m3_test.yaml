# M3 Test Recipe - Minimal configuration for pipeline testing
# Uses small model and dataset for quick verification on MacBook M3

# Run metadata
run:
  name: "m3_test_mtp_baseline"
  tags:
    - "test"
    - "m3"
    - "small_model"

# Model configuration - using test wrapper
model:
  base_id: "test-mtp"  # Special ID for test loader
  ref_id: "distilgpt2"  # Tiny reference model
  tokenizer_type: "hf"
  tokenizer_pad_side: "right"
  mtp:
    n_heads: 4
    horizon: 4

# Training configuration - minimal for testing
train:
  algo: "baseline-mtp"  # Start with simplest algorithm
  full_finetune: true
  max_steps: 10  # Only 10 steps for testing!
  checkpointing:
    save_interval: 5  # Save every 5 steps
    keep_last: 1
    save_final: true

# Optimizer configuration - reduced for M3
optim:
  optimizer: "adamw"
  lr: 5.0e-5  # Slightly higher LR for quick testing
  weight_decay: 0.01
  betas: [0.9, 0.999]
  grad_clip: 1.0
  scheduler: "constant"  # No scheduling for test
  warmup_ratio: 0.0

# Data configuration - tiny batches
data:
  train:
    sources: ["mbpp"]  # Use mbpp dataset
    max_length: 128  # Short sequences for memory
    batch_size: 1  # Minimal batch size
    pack_sequences: false
  eval:
    sources: ["mbpp"]
    max_length: 128
    batch_size: 1
    pack_sequences: false

# Loss configuration - baseline settings
loss:
  weight_norm: "none"
  lambda: 0.001
  temperature: 1.0
  epsilon: 1.0e-8
  max_weight: 1.01

# Evaluation configuration - simplified
eval:
  protocol: "meta-mtp"
  sampling:
    temperature: 0.7
    top_p: 0.9
    n: 1
  metrics:
    - "mbpp_exact"  # Use valid metric for testing