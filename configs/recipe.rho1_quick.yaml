# Rho-1 WMTP 실험 - 10분 내 완료용
# 참조 모델 기반 토큰 가중치를 사용하는 WMTP

run:
  name: "rho1_quick_exp"
  tags:
    - "rho1"
    - "wmtp"
    - "quick"
    - "comparison"

# Facebook MTP + Reference Model 사용
model:
  base_id: "facebook/multi-token-prediction"
  ref_id: "codellama/CodeLlama-7b-Python-hf"    # Rho-1용 참조 모델
  tokenizer_pad_side: "right"
  mtp:
    n_heads: 4
    horizon: 4

# Rho-1 알고리즘 훈련 설정
train:
  algo: "rho1-wmtp"
  full_finetune: true
  lora:
    enabled: false

# 참조 모델 비교를 위한 학습률 설정
optim:
  optimizer: "adamw"
  lr: 3.0e-5              # 약간 낮은 학습률 (안정성)
  weight_decay: 0.1       # 높은 정규화
  betas: [0.9, 0.95]
  grad_clip: 1.0
  scheduler: "constant"
  warmup_ratio: 0.0

# 작은 데이터셋으로 빠른 실험
data:
  train:
    sources: ["mbpp"]
    max_length: 512
    batch_size: 2
    pack_sequences: false
  eval:
    sources: ["mbpp"]
    max_length: 512
    batch_size: 4
    pack_sequences: false

# 작은 배치 설정
batching:
  global_batch_tokens: 50000
  micro_batch_size: 1
  grad_accum_steps: 4

# WMTP 손실 - 참조 모델 기반 가중치
loss:
  weight_norm: "mean1.0_clip"
  lambda: 0.4                   # 높은 가중치 강도
  temperature: 0.8              # 중간 온도
  epsilon: 0.1
  max_weight: 2.5               # 적당한 증폭

# Rho-1 특화 설정 - 참조 모델 기반 가중치
rho1:
  score: "abs_excess_ce"        # 절대 초과 Cross-Entropy
  percentile_top_p: 0.5         # 상위 50% 토큰에 가중치 적용
  refresh_per_epoch: true       # 에포크마다 점수 갱신

# 평가 설정
eval:
  protocol: "meta-mtp"
  sampling:
    temperature: 0.3            # 중간 온도
    top_p: 0.9
    n: 1
  metrics:
    - "mbpp_exact"
