"""
Phase 2 í†µí•© í…ŒìŠ¤íŠ¸
base_wmtp_trainer.pyì˜ MPS ê²½ë¡œ ë¶„ê¸°ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
"""

from pathlib import Path

import torch
import yaml

from src.components.trainer.base_wmtp_trainer import compute_weighted_mtp_loss
from src.utils.mps_optimizer import MPSOptimizer


def test_compute_weighted_mtp_loss_with_config():
    """compute_weighted_mtp_lossê°€ config íŒŒë¼ë¯¸í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 60)
    print("Phase 2 Integration Test: compute_weighted_mtp_loss")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ìš© í…ì„œ ìƒì„±
    B, S, H, V = 2, 10, 4, 100
    device = "cpu"  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ CPU ì‚¬ìš©

    logits = torch.randn(B, S, H, V, device=device)
    target_labels = torch.randint(0, V, (B, S, H), device=device)
    head_weights = torch.ones(B, S, H, device=device)

    # 1. config ì—†ì´ í˜¸ì¶œ (ê¸°ì¡´ ê²½ë¡œ)
    print("\n1ï¸âƒ£ Testing without config (default path):")
    loss1, mask1, ce1 = compute_weighted_mtp_loss(
        logits=logits,
        target_labels=target_labels,
        head_weights=head_weights,
        ignore_index=-100,
        config=None,
    )
    print(f"   Loss: {loss1.item():.4f}")
    print(f"   Valid mask shape: {mask1.shape}")
    print(f"   CE per head shape: {ce1.shape}")

    # 2. MPS configë¡œ í˜¸ì¶œ
    print("\n2ï¸âƒ£ Testing with MPS config:")
    mps_config = {
        "launcher": {"resources": {"gpu_type": "mps"}},
        "devices": {"compute_backend": "mps"},
    }

    # MPSê°€ ì—†ìœ¼ë©´ ê²½ë¡œê°€ í™œì„±í™”ë˜ì§€ ì•ŠìŒ
    if not torch.backends.mps.is_available():
        print("   âš ï¸ MPS not available - will use default path")

    loss2, mask2, ce2 = compute_weighted_mtp_loss(
        logits=logits,
        target_labels=target_labels,
        head_weights=head_weights,
        ignore_index=-100,
        config=mps_config,
    )
    print(f"   Loss: {loss2.item():.4f}")

    # 3. CUDA configë¡œ í˜¸ì¶œ (ê¸°ì¡´ ê²½ë¡œ)
    print("\n3ï¸âƒ£ Testing with CUDA config:")
    cuda_config = {
        "launcher": {"resources": {"gpu_type": "A100"}},
        "devices": {"compute_backend": "cuda"},
    }

    loss3, mask3, ce3 = compute_weighted_mtp_loss(
        logits=logits,
        target_labels=target_labels,
        head_weights=head_weights,
        ignore_index=-100,
        config=cuda_config,
    )
    print(f"   Loss: {loss3.item():.4f}")

    # 4. ê²°ê³¼ ê²€ì¦
    print("\n4ï¸âƒ£ Validation:")

    # ëª¨ë“  ê²½ë¡œì—ì„œ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë‚´ì•¼ í•¨ (ìˆ˜ì¹˜ì  ì˜¤ì°¨ í—ˆìš©)
    if torch.allclose(loss1, loss2, rtol=1e-4) and torch.allclose(
        loss1, loss3, rtol=1e-4
    ):
        print("   âœ… All paths produce consistent results")
    else:
        print("   âš ï¸ Results differ between paths")
        print(f"      Default: {loss1.item():.6f}")
        print(f"      MPS config: {loss2.item():.6f}")
        print(f"      CUDA config: {loss3.item():.6f}")

    return True


def test_config_loading():
    """ì‹¤ì œ config íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 60)
    print("Config Loading Test")
    print("=" * 60)

    config_path = Path("tests/configs/config.local_test.yaml")
    if not config_path.exists():
        print(f"âš ï¸ Config file not found: {config_path}")
        return False

    with open(config_path) as f:
        config = yaml.safe_load(f)

    print(f"ğŸ“„ Loaded config: {config_path}")

    # GPU íƒ€ì… í™•ì¸
    gpu_type = config.get("launcher", {}).get("resources", {}).get("gpu_type", "")
    compute_backend = config.get("devices", {}).get("compute_backend", "")

    print(f"   GPU Type: {gpu_type}")
    print(f"   Compute Backend: {compute_backend}")

    # MPS ê²½ë¡œ íŒë‹¨ í…ŒìŠ¤íŠ¸
    use_mps = MPSOptimizer.should_use_mps_path(config)
    print(f"   Should use MPS path: {use_mps}")

    # configë¥¼ ì‚¬ìš©í•œ compute_weighted_mtp_loss í˜¸ì¶œ
    if use_mps:
        print("\nğŸ Testing with actual MPS config:")
        B, S, H, V = 2, 10, 4, 100
        device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

        logits = torch.randn(B, S, H, V, device=device)
        target_labels = torch.randint(0, V, (B, S, H), device=device)
        head_weights = torch.ones(B, S, H, device=device)

        loss, mask, ce = compute_weighted_mtp_loss(
            logits=logits,
            target_labels=target_labels,
            head_weights=head_weights,
            ignore_index=-100,
            config=config,
        )
        print(f"   Loss computed successfully: {loss.item():.4f}")

    return True


def test_trainer_integration():
    """Trainerì—ì„œ config ì „ë‹¬ì´ ì˜ ë˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 60)
    print("Trainer Integration Test")
    print("=" * 60)

    # BaseWmtpTrainerëŠ” ì¶”ìƒ í´ë˜ìŠ¤ë¼ ì§ì ‘ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ì—†ìŒ
    # ëŒ€ì‹  compute_weighted_mtp_lossê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ë§Œ í™•ì¸

    test_config = {
        "launcher": {"resources": {"gpu_type": "mps"}},
        "devices": {"compute_backend": "mps"},
        "horizon": 4,
        "mixed_precision": "fp32",
        "loss_config": {"lambda": 0.3},
    }

    print("âœ… Config structure is compatible with trainers")
    print(f"   Horizon: {test_config.get('horizon')}")
    print(f"   Mixed precision: {test_config.get('mixed_precision')}")
    print(f"   Lambda: {test_config.get('loss_config', {}).get('lambda')}")

    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\nğŸš€ Starting Phase 2 Integration Tests ğŸš€")

    tests = [
        (
            "compute_weighted_mtp_loss with config",
            test_compute_weighted_mtp_loss_with_config,
        ),
        ("Config loading", test_config_loading),
        ("Trainer integration", test_trainer_integration),
    ]

    results = []
    for name, test_func in tests:
        try:
            print(f"\nğŸ” Running: {name}")
            result = test_func()
            results.append((name, result))
            print(f"   Result: {'âœ… PASS' if result else 'âŒ FAIL'}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
            results.append((name, False))

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status}: {name}")

    print(f"\nTotal: {passed}/{total} tests passed")

    if passed == total:
        print("\nğŸ‰ All Phase 2 tests passed!")
    else:
        print(f"\nâš ï¸ {total - passed} test(s) failed")


if __name__ == "__main__":
    main()
