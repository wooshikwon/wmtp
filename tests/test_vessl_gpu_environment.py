#!/usr/bin/env python
"""
VESSL GPU ν™κ²½ νΈν™μ„± ν…μ¤νΈ

WMTP νμ΄ν”„λΌμΈμ΄ VESSL GPU ν΄λ¬μ¤ν„°μ—μ„ S3 μ¤νΈλ¦¬λ° κΈ°λ°μΌλ΅
μ¬λ°”λ¥΄κ² λ™μ‘ν•λ”μ§€ κ²€μ¦ν•©λ‹λ‹¤.

μ£Όμ” κ²€μ¦ μ‚¬ν•­:
1. GPU ν™κ²½ κ°μ§€ λ° μ„¤μ •
2. S3 μ§μ ‘ μ¤νΈλ¦¬λ° λ™μ‘
3. λ¶„μ‚° ν•™μµ ν™κ²½ νΈν™μ„±
4. λ©”λ¨λ¦¬ ν¨μ¨μ„±
5. ν™κ²½λ³€μ κΈ°λ° μ„¤μ • λ΅λ“
6. MLflow S3 ν†µν•©

VESSL ν™κ²½ μ‹λ®¬λ μ΄μ…:
- GPU λ””λ°”μ΄μ¤ λ©ν‚Ή
- S3 μ „μ© μ„¤μ • (λ΅μ»¬ νμΌ μ—†μ)
- λ¶„μ‚° ν•™μµ ν™κ²½λ³€μ
- λ©”λ¨λ¦¬ μ ν• ν™κ²½
"""

import os
import sys
import tempfile
import unittest
from pathlib import Path
from unittest.mock import MagicMock, patch, Mock
from typing import Dict, Any

import torch
import torch.distributed as dist

# WMTP components
from src.utils.path_resolver import PathResolver, PathCategory
from src.components.loader.unified_model_loader import UnifiedModelLoader
from src.components.loader.unified_data_loader import UnifiedDataLoader
from src.components.tokenizer.sentencepiece_tokenizer import SentencePieceTokenizer
from src.factory.component_factory import ComponentFactory
from src.utils.s3 import S3Manager, create_s3_manager


class VESSLEnvironmentSimulator:
    """VESSL ν™κ²½ μ‹λ®¬λ μ΄ν„°."""

    def __init__(self):
        """VESSL ν™κ²½ μ‹λ®¬λ μ΄ν„° μ΄κΈ°ν™”."""
        self.original_env = {}
        self.gpu_available = torch.cuda.is_available()

    def setup_vessl_environment(self) -> Dict[str, Any]:
        """VESSL GPU ν™κ²½ μ„¤μ •."""
        # VESSL ν™κ²½λ³€μ μ‹λ®¬λ μ΄μ…
        vessl_env = {
            # λ¶„μ‚° ν•™μµ ν™κ²½
            "WORLD_SIZE": "2",
            "RANK": "0",
            "LOCAL_RANK": "0",
            "MASTER_ADDR": "localhost",
            "MASTER_PORT": "29500",

            # S3 μκ²© μ¦λ… (Mock)
            "AWS_ACCESS_KEY_ID": "AKIAMOCKKEY12345678",
            "AWS_SECRET_ACCESS_KEY": "mockSecretKey+abcdefghijklmnopqrstuvwxyz123",
            "AWS_DEFAULT_REGION": "us-east-1",

            # VESSL νΉν™” ν™κ²½
            "VESSL_EXPERIMENT_ID": "exp-12345",
            "VESSL_RUN_ID": "run-67890",
            "HOSTNAME": "vessl-gpu-worker-0",

            # MLflow μ„¤μ •
            "MLFLOW_TRACKING_URI": "s3://wmtp-mlflow/tracking",
            "MLFLOW_REGISTRY_URI": "s3://wmtp-mlflow/registry",
        }

        # ν™κ²½λ³€μ λ°±μ—… λ° μ„¤μ •
        for key, value in vessl_env.items():
            self.original_env[key] = os.environ.get(key)
            os.environ[key] = value

        # VESSL μ„¤μ • λ°ν™
        return {
            "storage": {
                "mode": "s3",  # S3 μ „μ© λ¨λ“
                "s3": {
                    "bucket": "wmtp-models",
                    "region": "us-east-1"
                }
            },
            "distributed": {
                "backend": "nccl",
                "world_size": 2,
                "rank": 0
            },
            "paths": {
                # λ΅μ»¬ κ²½λ΅ μ—†μ - S3λ§ μ‚¬μ©
            },
            "hardware": {
                "device": "cuda" if self.gpu_available else "cpu",
                "mixed_precision": True
            }
        }

    def cleanup_environment(self):
        """ν™κ²½λ³€μ λ³µμ›."""
        for key, value in self.original_env.items():
            if value is None:
                os.environ.pop(key, None)
            else:
                os.environ[key] = value


class TestVESSLGPUEnvironment(unittest.TestCase):
    """VESSL GPU ν™κ²½ ν…μ¤νΈ."""

    def setUp(self):
        """ν…μ¤νΈ μ„¤μ •."""
        self.simulator = VESSLEnvironmentSimulator()
        self.vessl_config = self.simulator.setup_vessl_environment()

        # Mock S3Manager
        self.mock_s3_manager = MagicMock(spec=S3Manager)
        self.mock_s3_manager.connected = True
        self.mock_s3_manager.bucket = "wmtp-models"
        self.mock_s3_manager.region = "us-east-1"

    def tearDown(self):
        """ν…μ¤νΈ μ •λ¦¬."""
        self.simulator.cleanup_environment()

    def test_gpu_detection_and_setup(self):
        """GPU κ°μ§€ λ° μ„¤μ • ν…μ¤νΈ."""
        print("1. GPU κ°μ§€ λ° μ„¤μ • ν…μ¤νΈ...")

        # GPU κ°€μ©μ„± ν™•μΈ
        gpu_available = torch.cuda.is_available()
        print(f"   GPU κ°€μ©: {gpu_available}")

        if gpu_available:
            device_count = torch.cuda.device_count()
            print(f"   GPU κ°μ: {device_count}")

            # μ²« λ²μ§Έ GPU μ •λ³΄
            if device_count > 0:
                device_name = torch.cuda.get_device_name(0)
                device_memory = torch.cuda.get_device_properties(0).total_memory
                print(f"   GPU μ΄λ¦„: {device_name}")
                print(f"   GPU λ©”λ¨λ¦¬: {device_memory / (1024**3):.1f} GB")

        # μ„¤μ •μ—μ„ λ””λ°”μ΄μ¤ ν™•μΈ
        expected_device = "cuda" if gpu_available else "cpu"
        self.assertEqual(self.vessl_config["hardware"]["device"], expected_device)

        print("   β“ GPU ν™κ²½ μ„¤μ • ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_s3_streaming_only_mode(self, mock_create_s3):
        """S3 μ „μ© μ¤νΈλ¦¬λ° λ¨λ“ ν…μ¤νΈ."""
        print("2. S3 μ „μ© μ¤νΈλ¦¬λ° λ¨λ“ ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # PathResolver S3 λ¨λ“ ν…μ¤νΈ
        resolver = PathResolver(self.vessl_config)
        self.assertEqual(resolver.storage_mode, "s3")

        # S3 κ²½λ΅ ν•΄κ²° ν…μ¤νΈ
        s3_model_path = resolver.resolve("s3://wmtp-models/facebook-mtp/model.pth", PathCategory.MODEL)
        self.assertEqual(s3_model_path, "facebook-mtp/model.pth")

        # λ΅μ»¬ κ²½λ΅κ°€ μ—†μ–΄λ„ S3 κ²½λ΅ μ°μ„  μ²λ¦¬
        local_fallback = resolver.resolve("models/nonexistent.pth", PathCategory.MODEL)
        self.assertIsInstance(local_fallback, str)  # S3 ν‚¤λ΅ λ³€ν™λμ–΄μ•Ό ν•¨

        print("   β“ S3 μ „μ© λ¨λ“ λ™μ‘ ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_unified_loaders_gpu_compatibility(self, mock_create_s3):
        """ν†µν•© λ΅λ” GPU νΈν™μ„± ν…μ¤νΈ."""
        print("3. ν†µν•© λ΅λ” GPU νΈν™μ„± ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # λ¨λΈ μ¤νΈλ¦Ό λ©ν‚Ή
        mock_model_stream = MagicMock()
        self.mock_s3_manager.stream_model.return_value = mock_model_stream

        # UnifiedModelLoader GPU μ„¤μ •
        model_loader = UnifiedModelLoader(self.vessl_config)
        model_loader.setup({})

        # GPU λ””λ°”μ΄μ¤ μ„¤μ • ν™•μΈ
        if torch.cuda.is_available():
            # GPU ν™κ²½μ—μ„λ” CUDA λ””λ°”μ΄μ¤ μ‚¬μ©
            with patch.object(model_loader, 'load_model') as mock_load:
                mock_model = MagicMock()
                mock_load.return_value = mock_model

                # S3 μ¤νΈλ¦¬λ° μ‹λ®¬λ μ΄μ…
                try:
                    result = model_loader.run({
                        "path": "s3://wmtp-models/facebook-mtp/model.pth",
                        "device": "cuda:0"
                    })
                    # λ΅λ”© μ„±κ³µ ν™•μΈ
                    self.assertIn("model", result)
                except Exception as e:
                    # S3 μ—°κ²° μ‹¤ν¨λ” μμƒλ¨ (λ© ν™κ²½)
                    self.assertIn("S3", str(e))

        print("   β“ ν†µν•© λ΅λ” GPU νΈν™μ„± ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_distributed_training_compatibility(self, mock_create_s3):
        """λ¶„μ‚° ν•™μµ ν™κ²½ νΈν™μ„± ν…μ¤νΈ."""
        print("4. λ¶„μ‚° ν•™μµ ν™κ²½ νΈν™μ„± ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # λ¶„μ‚° ν™κ²½λ³€μ ν™•μΈ
        world_size = int(os.environ.get("WORLD_SIZE", "1"))
        rank = int(os.environ.get("RANK", "0"))
        local_rank = int(os.environ.get("LOCAL_RANK", "0"))

        self.assertEqual(world_size, 2)
        self.assertEqual(rank, 0)
        self.assertEqual(local_rank, 0)

        # λ¶„μ‚° μ„¤μ • ν™•μΈ
        dist_config = self.vessl_config.get("distributed", {})
        self.assertEqual(dist_config["world_size"], 2)
        self.assertEqual(dist_config["backend"], "nccl")

        # ComponentFactory λ¶„μ‚° ν™κ²½ ν…μ¤νΈ
        factory = ComponentFactory()

        # ν†µν•© λ΅λ”λ“¤μ΄ λ¶„μ‚° ν™κ²½μ—μ„ μ΄κΈ°ν™”λλ”μ§€ ν™•μΈ
        model_loader = factory.create_loader("unified-model", self.vessl_config)
        data_loader = factory.create_loader("unified-data", self.vessl_config)

        self.assertIsNotNone(model_loader)
        self.assertIsNotNone(data_loader)

        print("   β“ λ¶„μ‚° ν•™μµ ν™κ²½ νΈν™μ„± ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_memory_efficient_streaming(self, mock_create_s3):
        """λ©”λ¨λ¦¬ ν¨μ¨μ  μ¤νΈλ¦¬λ° ν…μ¤νΈ."""
        print("5. λ©”λ¨λ¦¬ ν¨μ¨μ  μ¤νΈλ¦¬λ° ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # μ¤νΈλ¦¬λ° λ©”μ„λ“ λ©ν‚Ή
        mock_stream = MagicMock()
        self.mock_s3_manager.stream_model.return_value = mock_stream
        self.mock_s3_manager.stream_dataset.return_value = mock_stream

        # BaseLoader μ¤νΈλ¦¬λ° ν…μ¤νΈ
        from src.components.loader.base_loader import BaseLoader

        # μ¤νΈλ¦¬λ° λ©”μ„λ“ μ΅΄μ¬ ν™•μΈ
        self.assertTrue(hasattr(BaseLoader, "load_with_streaming"))

        # μΊμ‹ λ©”μ„λ“ μ κ±° ν™•μΈ
        cache_methods = [
            "compute_cache_key",
            "get_cached_path",
            "load_with_cache",
            "sync_directory_with_cache"
        ]

        for method in cache_methods:
            self.assertFalse(hasattr(BaseLoader, method))

        # S3Manager μ¤νΈλ¦¬λ° λ©”μ„λ“ ν™•μΈ
        streaming_methods = ["stream_model", "stream_dataset", "upload_from_bytes"]
        for method in streaming_methods:
            self.assertTrue(hasattr(self.mock_s3_manager, method))

        print("   β“ λ©”λ¨λ¦¬ ν¨μ¨μ  μ¤νΈλ¦¬λ° ν™•μΈ")

    @patch('mlflow.set_tracking_uri')
    @patch('mlflow.set_registry_uri')
    @patch('src.utils.s3.create_s3_manager')
    def test_mlflow_s3_integration(self, mock_create_s3, mock_set_registry, mock_set_tracking):
        """MLflow S3 ν†µν•© ν…μ¤νΈ."""
        print("6. MLflow S3 ν†µν•© ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # MLflow URI ν™κ²½λ³€μ ν™•μΈ
        tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
        registry_uri = os.environ.get("MLFLOW_REGISTRY_URI")

        self.assertEqual(tracking_uri, "s3://wmtp-mlflow/tracking")
        self.assertEqual(registry_uri, "s3://wmtp-mlflow/registry")

        # CriticStage1Pretrainer MLflow ν†µν•© ν…μ¤νΈ
        from src.components.trainer.critic_stage1_pretrainer import CriticStage1Pretrainer

        pretrainer = CriticStage1Pretrainer({
            "target": "rm_sequence",
            "lr": 1e-4
        })

        # MLflow λ§¤λ‹μ € λ©ν‚Ή
        mock_mlflow_manager = MagicMock()
        mock_mlflow_manager.list_artifacts.return_value = []
        mock_mlflow_manager.log_model = MagicMock()

        # λ© μ»¨ν…μ¤νΈ μƒμ„±
        mock_model = MagicMock()
        mock_model.config.hidden_size = 4096
        mock_model.config.output_hidden_states = False
        mock_model.parameters.return_value = [MagicMock()]

        ctx = {
            "base_model": mock_model,
            "rm_model": MagicMock(),
            "train_dataloader": [],  # λΉ λ°μ΄ν„°λ΅λ”
            "mlflow_manager": mock_mlflow_manager
        }

        # MLflow S3 μ €μ¥ ν…μ¤νΈ
        pretrainer.setup({})
        result = pretrainer.run(ctx)

        self.assertIn("saved", result)
        self.assertEqual(result["saved"], "MLflow/S3")

        print("   β“ MLflow S3 ν†µν•© ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_tokenizer_s3_streaming(self, mock_create_s3):
        """ν† ν¬λ‚μ΄μ € S3 μ¤νΈλ¦¬λ° ν…μ¤νΈ."""
        print("7. ν† ν¬λ‚μ΄μ € S3 μ¤νΈλ¦¬λ° ν…μ¤νΈ...")

        mock_create_s3.return_value = self.mock_s3_manager

        # ν† ν¬λ‚μ΄μ € μ¤νΈλ¦Ό λ©ν‚Ή
        mock_tokenizer_data = b"fake tokenizer model data"
        mock_stream = MagicMock()
        mock_stream.read.return_value = mock_tokenizer_data
        self.mock_s3_manager.stream_model.return_value = mock_stream

        # SentencePieceTokenizer S3 μ¤νΈλ¦¬λ°
        tokenizer = SentencePieceTokenizer({
            "s3_manager": self.mock_s3_manager
        })

        # ν† ν¬λ‚μ΄μ € μ΄κΈ°ν™” ν…μ¤νΈ
        try:
            tokenizer.setup({})
            # μ‹¤μ  λ΅λ”©μ€ μ‹¤ν¨ν•μ§€λ§ S3 μ¤νΈλ¦¬λ° νΈμ¶μ€ ν™•μΈ κ°€λ¥
            with patch.object(tokenizer, '_ensure_processor_loaded') as mock_ensure:
                mock_ensure.return_value = True
                result = tokenizer.run({})
                self.assertIn("tokenizer", result)
        except Exception as e:
            # S3 μ¤νΈλ¦¬λ° νΈμ¶μ΄ μ΄λ£¨μ–΄μ΅λ”μ§€ ν™•μΈ
            self.mock_s3_manager.stream_model.assert_called()

        print("   β“ ν† ν¬λ‚μ΄μ € S3 μ¤νΈλ¦¬λ° ν™•μΈ")

    def test_environment_variables_configuration(self):
        """ν™κ²½λ³€μ κΈ°λ° μ„¤μ • ν…μ¤νΈ."""
        print("8. ν™κ²½λ³€μ κΈ°λ° μ„¤μ • ν…μ¤νΈ...")

        # ν•„μ ν™κ²½λ³€μ ν™•μΈ
        required_vars = [
            "AWS_ACCESS_KEY_ID",
            "AWS_SECRET_ACCESS_KEY",
            "AWS_DEFAULT_REGION",
            "MLFLOW_TRACKING_URI",
            "MLFLOW_REGISTRY_URI"
        ]

        for var in required_vars:
            self.assertIn(var, os.environ)
            self.assertIsNotNone(os.environ[var])

        # VESSL νΉν™” ν™κ²½λ³€μ ν™•μΈ
        vessl_vars = [
            "VESSL_EXPERIMENT_ID",
            "VESSL_RUN_ID",
            "HOSTNAME"
        ]

        for var in vessl_vars:
            self.assertIn(var, os.environ)

        # λ¶„μ‚° ν•™μµ ν™κ²½λ³€μ ν™•μΈ
        dist_vars = ["WORLD_SIZE", "RANK", "LOCAL_RANK", "MASTER_ADDR", "MASTER_PORT"]
        for var in dist_vars:
            self.assertIn(var, os.environ)

        print("   β“ ν™κ²½λ³€μ κΈ°λ° μ„¤μ • ν™•μΈ")

    def test_error_handling_and_fallbacks(self):
        """μ¤λ¥ μ²λ¦¬ λ° ν΄λ°± ν…μ¤νΈ."""
        print("9. μ¤λ¥ μ²λ¦¬ λ° ν΄λ°± ν…μ¤νΈ...")

        # S3 μ—°κ²° μ‹¤ν¨ μ‹λ‚λ¦¬μ¤
        disconnected_s3 = MagicMock(spec=S3Manager)
        disconnected_s3.connected = False

        config_with_disconnected_s3 = self.vessl_config.copy()

        with patch('src.utils.s3.create_s3_manager') as mock_create:
            mock_create.return_value = disconnected_s3

            # PathResolver ν΄λ°± λ™μ‘
            resolver = PathResolver(config_with_disconnected_s3)

            # S3 μ—°κ²° μ‹¤ν¨ μ‹μ—λ„ μ μ ν μ²λ¦¬λμ–΄μ•Ό ν•¨
            try:
                path = resolver.resolve("models/test.pth", PathCategory.MODEL)
                # κ²½λ΅ ν•΄κ²° μμ²΄λ” μ„±κ³µν•΄μ•Ό ν•¨
                self.assertIsNotNone(path)
            except Exception as e:
                # μ μ ν• μ—λ¬ λ©”μ‹μ§€ ν™•μΈ
                self.assertIn("S3", str(e)) or self.assertIn("connection", str(e))

        print("   β“ μ¤λ¥ μ²λ¦¬ λ° ν΄λ°± ν™•μΈ")


class TestVESSLPerformance(unittest.TestCase):
    """VESSL μ„±λ¥ ν…μ¤νΈ."""

    def setUp(self):
        """ν…μ¤νΈ μ„¤μ •."""
        self.simulator = VESSLEnvironmentSimulator()
        self.vessl_config = self.simulator.setup_vessl_environment()

    def tearDown(self):
        """ν…μ¤νΈ μ •λ¦¬."""
        self.simulator.cleanup_environment()

    def test_memory_usage_optimization(self):
        """λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™” ν…μ¤νΈ."""
        print("10. λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™” ν…μ¤νΈ...")

        # λ² μ΄μ¤λΌμΈ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μΈ΅μ •
        import psutil
        process = psutil.Process()
        initial_memory = process.memory_info().rss / (1024 * 1024)  # MB

        # μ—¬λ¬ λ΅λ” μƒμ„±
        factory = ComponentFactory()
        loaders = []

        with patch('src.utils.s3.create_s3_manager') as mock_create:
            mock_s3 = MagicMock()
            mock_s3.connected = True
            mock_create.return_value = mock_s3

            # λ‹¤μμ λ΅λ” μƒμ„± (μΊμ‹ μ—†μ΄)
            for i in range(5):
                model_loader = factory.create_loader("unified-model", self.vessl_config)
                data_loader = factory.create_loader("unified-data", self.vessl_config)
                loaders.extend([model_loader, data_loader])

        # λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ
        current_memory = process.memory_info().rss / (1024 * 1024)  # MB
        memory_increase = current_memory - initial_memory

        print(f"   μ΄κΈ° λ©”λ¨λ¦¬: {initial_memory:.1f} MB")
        print(f"   ν„μ¬ λ©”λ¨λ¦¬: {current_memory:.1f} MB")
        print(f"   μ¦κ°€λ‰: {memory_increase:.1f} MB")

        # μΊμ‹κ°€ μ κ±°λμ–΄ λ©”λ¨λ¦¬ μ¦κ°€κ°€ μ μ–΄μ•Ό ν•¨
        self.assertLess(memory_increase, 100)  # 100MB λ―Έλ§ μ¦κ°€

        print("   β“ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™” ν™•μΈ")

    @patch('src.utils.s3.create_s3_manager')
    def test_concurrent_s3_streaming(self, mock_create_s3):
        """λ™μ‹ S3 μ¤νΈλ¦¬λ° μ„±λ¥ ν…μ¤νΈ."""
        print("11. λ™μ‹ S3 μ¤νΈλ¦¬λ° μ„±λ¥ ν…μ¤νΈ...")

        mock_s3_manager = MagicMock()
        mock_s3_manager.connected = True
        mock_create_s3.return_value = mock_s3_manager

        # λ™μ‹ μ¤νΈλ¦¬λ° μ‹λ®¬λ μ΄μ…
        import concurrent.futures
        import time

        def simulate_stream_load(key):
            """μ¤νΈλ¦¬λ° λ΅λ“ μ‹λ®¬λ μ΄μ…."""
            mock_stream = MagicMock()
            mock_s3_manager.stream_model.return_value = mock_stream
            time.sleep(0.1)  # λ„¤νΈμ›ν¬ μ§€μ—° μ‹λ®¬λ μ΄μ…
            return f"loaded_{key}"

        # λ™μ‹μ— μ—¬λ¬ νμΌ μ¤νΈλ¦¬λ°
        keys = [f"model_{i}.pth" for i in range(10)]

        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            results = list(executor.map(simulate_stream_load, keys))

        elapsed_time = time.time() - start_time
        print(f"   10κ° νμΌ λ™μ‹ μ¤νΈλ¦¬λ°: {elapsed_time:.2f}μ΄")

        # λ³‘λ ¬ μ²λ¦¬λ΅ μ‹κ°„ λ‹¨μ¶• ν™•μΈ
        self.assertLess(elapsed_time, 1.0)  # 1μ΄ λ―Έλ§μ΄μ–΄μ•Ό ν•¨
        self.assertEqual(len(results), 10)

        print("   β“ λ™μ‹ S3 μ¤νΈλ¦¬λ° μ„±λ¥ ν™•μΈ")


def main():
    """VESSL GPU ν™κ²½ ν…μ¤νΈ μ‹¤ν–‰."""
    print("=" * 80)
    print("WMTP VESSL GPU ν™κ²½ νΈν™μ„± ν…μ¤νΈ")
    print("=" * 80)
    print()

    # GPU ν™κ²½ μ •λ³΄ μ¶λ ¥
    gpu_available = torch.cuda.is_available()
    print(f"GPU μ‚¬μ© κ°€λ¥: {gpu_available}")
    if gpu_available:
        print(f"GPU κ°μ: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    print()

    # ν…μ¤νΈ μ¤μ„νΈ μƒμ„±
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    # VESSL ν™κ²½ ν…μ¤νΈ μ¶”κ°€
    suite.addTests(loader.loadTestsFromTestCase(TestVESSLGPUEnvironment))
    suite.addTests(loader.loadTestsFromTestCase(TestVESSLPerformance))

    # ν…μ¤νΈ μ‹¤ν–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # κ²°κ³Ό μ”μ•½
    print("\n" + "=" * 80)
    print("VESSL GPU ν™κ²½ ν…μ¤νΈ κ²°κ³Ό:")
    print("=" * 80)

    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    passed = total_tests - failures - errors

    print(f"μ‹¤ν–‰: {total_tests} ν…μ¤νΈ")
    print(f"ν†µκ³Ό: {passed}/{total_tests}")

    if failures > 0:
        print(f"μ‹¤ν¨: {failures}")

    if errors > 0:
        print(f"μ¤λ¥: {errors}")

    if passed == total_tests:
        print("\nπ€ VESSL GPU ν™κ²½ νΈν™μ„± κ²€μ¦ μ™„λ£!")
        print("π“¦ WMTPκ°€ VESSL ν΄λ¬μ¤ν„°μ—μ„ μ‹¤ν–‰λ  μ¤€λΉ„κ°€ λμ—μµλ‹λ‹¤.")
    else:
        print("\nβ οΈ  μΌλ¶€ VESSL ν™κ²½ ν…μ¤νΈκ°€ μ‹¤ν¨ν–μµλ‹λ‹¤.")
        print("VESSL λ°°ν¬ μ „μ— λ¬Έμ λ¥Ό ν•΄κ²°ν•΄μ£Όμ„Έμ”.")

    return 0 if passed == total_tests else 1


if __name__ == "__main__":
    sys.exit(main())