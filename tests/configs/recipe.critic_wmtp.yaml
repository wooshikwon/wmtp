# M3 Test Recipe - Critic WMTP Algorithm
# Value function based dynamic weighting for Multi-Token Prediction

# Run metadata
run:
  name: "m3_test_critic_wmtp"
  tags:
    - "test"
    - "m3"
    - "critic"
    - "wmtp"

# Model configuration
model:
  base_id: "test-mtp"  # Special ID for test loader
  rm_id: "tiny-reward-model"  # Lightweight RM for testing
  tokenizer_type: "hf"
  tokenizer_pad_side: "right"
  mtp:
    n_heads: 4
    horizon: 4

# Training configuration
train:
  algo: "critic-wmtp"  # Value-based dynamic weighting
  full_finetune: true
  max_steps: 10
  checkpointing:
    save_interval: 5
    keep_last: 1
    save_final: true

# Optimizer configuration
optim:
  optimizer: "adamw"
  lr: 5.0e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]
  grad_clip: 1.0
  scheduler: "constant"
  warmup_ratio: 0.0

# Data configuration
data:
  train:
    sources: ["mbpp"]
    max_length: 128
    batch_size: 1
    pack_sequences: false
  eval:
    sources: ["mbpp"]
    max_length: 128
    batch_size: 1
    pack_sequences: false

# Loss configuration - critic settings
loss:
  weight_norm: "mean1.0_clip"
  lambda: 0.3
  temperature: 0.7
  epsilon: 0.05
  max_weight: 3.0

# Critic-specific configuration
critic:
  # Stage 2 Value Loss settings (for continuous value head training)
  value_coef: 0.1
  value_lr: 5e-5
  use_pseudo_rewards: true

  # GAE parameters
  gamma: 0.99
  gae_lambda: 0.95

  # Existing settings
  target: "rm_sequence"
  token_spread: "gae"
  delta_mode: "td"
  normalize: "zscore"

# Evaluation configuration
eval:
  protocol: "meta-mtp"
  sampling:
    temperature: 0.7
    top_p: 0.9
    n: 1
  metrics:
    - "mbpp_exact"