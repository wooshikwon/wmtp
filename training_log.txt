β•­β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€ π§ Test Mode β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•®
β”‚ WMTP Pipeline Test on MacBook M3     β”‚
β”‚ Testing with small model and dataset β”‚
β•°β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•―

Checking environment...
β“ PyTorch version: 2.4.1
β“ MPS (Metal Performance Shaders) is available
  MPS device: True
β“ Total memory: 36.0 GB
  Available memory: 15.5 GB
β“ Transformers version: 4.56.2

Loading configurations...
β“ Loaded config: configs/config.m3_test.yaml
β“ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
β“ Test model loaders registered
β“ Test data loader registered
Random seed set to 42
β“ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
β“ Training pipeline imported successfully
π€ νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ‹μ‘
π” νμ΄ν”„λΌμΈ λ‹¨κ³„ μ¶”μ  μ‹μ‘...
Random seed set to 42
π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ™„λ£: epoch=0, step=0
π” MLflow Run ID: None
Started MLflow run: 7e991f9c17d344bbb21843b7198d4f17
π” MLflow μ‹¤ν— μ¶”μ  μ΄κΈ°ν™” μ™„λ£: run_name=m3_test_mtp_baseline
/Users/wesley/Desktop/wooshikwon/wmtp/src/components/loader/test_mtp_loader.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(cache_path, map_location=self.device)
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Loading cached model from /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Successfully loaded cached model
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
π” Base λ¨λΈ λ΅λ”© μ™„λ£: distilgpt2
π” ν† ν¬λ‚μ΄μ € μƒμ„± μ™„λ£: distilgpt2
π” μ•κ³ λ¦¬μ¦λ³„ μ¶”κ°€ λ¨λΈ λ΅λ”© μ™„λ£: mtp-baseline
π” μµν‹°λ§μ΄μ € μ„¤μ • μ™„λ£: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 1916.43 examples/s]
π” λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§• μ™„λ£: mtp-baseline
HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•:   0%|          | 0/10 [00:00<?, ? examples/s]HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 4338.34 examples/s]
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” PyTorch DataLoader μƒμ„± μ™„λ£: mtp-baseline
π” Stage1 μ‚¬μ „ν›λ ¨ μ™„λ£: mtp-baseline
π” λ©”μΈ Trainer μƒμ„± λ° μ΄κΈ°ν™” μ™„λ£: mtp-baseline
π” μ‹¤ν–‰ λ¨λ“ λ¶„κΈ° μ™„λ£: mtp-baseline
μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν™μ„±ν™”: λ§¤ 5μ¤ν…λ§λ‹¤ μ €μ¥
μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: checkpoints/m3_test_mtp_baseline

Pipeline test failed: Placeholder storage has not been allocated on MPS device!

This is expected for initial testing.
Common issues:
  1. Model loading issues - check paths
  2. Memory issues - use --tiny flag
  3. MPS issues - may need to use CPU

Full traceback:
Traceback (most recent call last):
  File "/Users/wesley/Desktop/wooshikwon/wmtp/test_m3_pipeline.py", line 236, in main
    outputs = run_training_pipeline(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/pipelines/training_pipeline.py", line 266, in run_training_pipeline
    metrics = trainer.run({
              ^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 706, in run
    out = self.train_step(batch)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 347, in train_step
    outputs: dict[str, Any] | torch.Tensor = self.model(**batch)
                                             ^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/model/mtp_wrapper.py", line 123, in forward
    base_outputs = self.base_model(
                   ^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1070, in forward
    transformer_outputs = self.transformer(
                          ^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 857, in forward
    inputs_embeds = self.wte(input_ids)
                    ^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py", line 164, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/nn/functional.py", line 2267, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Placeholder storage has not been allocated on MPS device!
