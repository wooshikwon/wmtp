β•­β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€ π§ Test Mode β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•®
β”‚ WMTP Pipeline Test on MacBook M3     β”‚
β”‚ Testing with small model and dataset β”‚
β•°β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•―

Checking environment...
β“ PyTorch version: 2.4.1
β“ MPS (Metal Performance Shaders) is available
  MPS device: True
β“ Total memory: 36.0 GB
  Available memory: 16.0 GB
β“ Transformers version: 4.56.2

Loading configurations...
β“ Loaded config: configs/config.m3_test.yaml
β“ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
β“ Test model loaders registered
β“ Test data loader registered
Random seed set to 42
β“ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
β“ Training pipeline imported successfully
π€ νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ‹μ‘
π” νμ΄ν”„λΌμΈ λ‹¨κ³„ μ¶”μ  μ‹μ‘...
Random seed set to 42
π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ™„λ£: epoch=0, step=0
π” MLflow Run ID: None
Started MLflow run: e83b27567a8846cbb38eb92c76274f45
π” MLflow μ‹¤ν— μ¶”μ  μ΄κΈ°ν™” μ™„λ£: run_name=m3_test_mtp_baseline
`torch_dtype` is deprecated! Use `dtype` instead!
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Creating new MTP wrapper for distilgpt2
[MTPWrapper] Using device: mps
[MTPWrapper] Loading base model: distilgpt2
[MTPWrapper] Created 3 extra MTP heads
[TestMTPLoader] Saving model to cache: /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Model cached successfully
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
π” Base λ¨λΈ λ΅λ”© μ™„λ£: distilgpt2
π” ν† ν¬λ‚μ΄μ € μƒμ„± μ™„λ£: distilgpt2
π” μ•κ³ λ¦¬μ¦λ³„ μ¶”κ°€ λ¨λΈ λ΅λ”© μ™„λ£: mtp-baseline
π” μµν‹°λ§μ΄μ € μ„¤μ • μ™„λ£: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 1966.02 examples/s]
π” λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§• μ™„λ£: mtp-baseline
HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•:   0%|          | 0/10 [00:00<?, ? examples/s]HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 3804.01 examples/s]
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” PyTorch DataLoader μƒμ„± μ™„λ£: mtp-baseline
π” Stage1 μ‚¬μ „ν›λ ¨ μ™„λ£: mtp-baseline
π” λ©”μΈ Trainer μƒμ„± λ° μ΄κΈ°ν™” μ™„λ£: mtp-baseline
π” μ‹¤ν–‰ λ¨λ“ λ¶„κΈ° μ™„λ£: mtp-baseline
μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν™μ„±ν™”: λ§¤ 5μ¤ν…λ§λ‹¤ μ €μ¥
μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: checkpoints/m3_test_mtp_baseline

Pipeline test failed: 'MTPWeightedCETrainer' object has no attribute 'device'

This is expected for initial testing.
Common issues:
  1. Model loading issues - check paths
  2. Memory issues - use --tiny flag
  3. MPS issues - may need to use CPU

Full traceback:
Traceback (most recent call last):
  File "/Users/wesley/Desktop/wooshikwon/wmtp/test_m3_pipeline.py", line 236, in main
    outputs = run_training_pipeline(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/pipelines/training_pipeline.py", line 266, in run_training_pipeline
    metrics = trainer.run({
              ^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 718, in run
    out = self.train_step(batch)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 341, in train_step
    batch = {k: v.to(self.device) if torch.is_tensor(v) else v
                     ^^^^^^^^^^^
AttributeError: 'MTPWeightedCETrainer' object has no attribute 'device'
β•­β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€ π§ Test Mode β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•®
β”‚ WMTP Pipeline Test on MacBook M3     β”‚
β”‚ Testing with small model and dataset β”‚
β•°β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•―

Checking environment...
β“ PyTorch version: 2.4.1
β“ MPS (Metal Performance Shaders) is available
  MPS device: True
β“ Total memory: 36.0 GB
  Available memory: 15.6 GB
β“ Transformers version: 4.56.2

Loading configurations...
β“ Loaded config: configs/config.m3_test.yaml
β“ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
β“ Test model loaders registered
β“ Test data loader registered
Random seed set to 42
β“ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
β“ Training pipeline imported successfully
π€ νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ‹μ‘
π” νμ΄ν”„λΌμΈ λ‹¨κ³„ μ¶”μ  μ‹μ‘...
Random seed set to 42
π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ™„λ£: epoch=0, step=0
π” MLflow Run ID: None
Started MLflow run: 2ef448edee5342af91cd389f62f12d79
π” MLflow μ‹¤ν— μ¶”μ  μ΄κΈ°ν™” μ™„λ£: run_name=m3_test_mtp_baseline
/Users/wesley/Desktop/wooshikwon/wmtp/src/components/loader/test_mtp_loader.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(cache_path, map_location=self.device)
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Loading cached model from /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Successfully loaded cached model
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
π” Base λ¨λΈ λ΅λ”© μ™„λ£: distilgpt2
π” ν† ν¬λ‚μ΄μ € μƒμ„± μ™„λ£: distilgpt2
π” μ•κ³ λ¦¬μ¦λ³„ μ¶”κ°€ λ¨λΈ λ΅λ”© μ™„λ£: mtp-baseline
π” μµν‹°λ§μ΄μ € μ„¤μ • μ™„λ£: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 2708.62 examples/s]
π” λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§• μ™„λ£: mtp-baseline
HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•:   0%|          | 0/10 [00:00<?, ? examples/s]HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 4427.17 examples/s]
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” PyTorch DataLoader μƒμ„± μ™„λ£: mtp-baseline
π” Stage1 μ‚¬μ „ν›λ ¨ μ™„λ£: mtp-baseline
π” λ©”μΈ Trainer μƒμ„± λ° μ΄κΈ°ν™” μ™„λ£: mtp-baseline
π” μ‹¤ν–‰ λ¨λ“ λ¶„κΈ° μ™„λ£: mtp-baseline
μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν™μ„±ν™”: λ§¤ 5μ¤ν…λ§λ‹¤ μ €μ¥
μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: checkpoints/m3_test_mtp_baseline
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.

Pipeline test failed: name 'ce_per_token' is not defined

This is expected for initial testing.
Common issues:
  1. Model loading issues - check paths
  2. Memory issues - use --tiny flag
  3. MPS issues - may need to use CPU

Full traceback:
Traceback (most recent call last):
  File "/Users/wesley/Desktop/wooshikwon/wmtp/test_m3_pipeline.py", line 236, in main
    outputs = run_training_pipeline(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/pipelines/training_pipeline.py", line 266, in run_training_pipeline
    metrics = trainer.run({
              ^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 730, in run
    out = self.train_step(batch)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 676, in train_step
    or not torch.isfinite(ce_per_token).all()
                          ^^^^^^^^^^^^
NameError: name 'ce_per_token' is not defined
β•­β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€ π§ Test Mode β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•®
β”‚ WMTP Pipeline Test on MacBook M3     β”‚
β”‚ Testing with small model and dataset β”‚
β•°β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β•―

Checking environment...
β“ PyTorch version: 2.4.1
β“ MPS (Metal Performance Shaders) is available
  MPS device: True
β“ Total memory: 36.0 GB
  Available memory: 16.6 GB
β“ Transformers version: 4.56.2

Loading configurations...
β“ Loaded config: configs/config.m3_test.yaml
β“ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
β“ Test model loaders registered
β“ Test data loader registered
Random seed set to 42
β“ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
β“ Training pipeline imported successfully
π€ νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ‹μ‘
π” νμ΄ν”„λΌμΈ λ‹¨κ³„ μ¶”μ  μ‹μ‘...
Random seed set to 42
π” μ²΄ν¬ν¬μΈνΈ λ΅λ”© μ™„λ£: epoch=0, step=0
π” MLflow Run ID: None
Started MLflow run: 4a136f73dee24a8687275ab4da982621
π” MLflow μ‹¤ν— μ¶”μ  μ΄κΈ°ν™” μ™„λ£: run_name=m3_test_mtp_baseline
/Users/wesley/Desktop/wooshikwon/wmtp/src/components/loader/test_mtp_loader.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(cache_path, map_location=self.device)
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Loading cached model from /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Successfully loaded cached model
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
π” Base λ¨λΈ λ΅λ”© μ™„λ£: distilgpt2
π” ν† ν¬λ‚μ΄μ € μƒμ„± μ™„λ£: distilgpt2
π” μ•κ³ λ¦¬μ¦λ³„ μ¶”κ°€ λ¨λΈ λ΅λ”© μ™„λ£: mtp-baseline
π” μµν‹°λ§μ΄μ € μ„¤μ • μ™„λ£: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 1922.41 examples/s]
π” λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§• μ™„λ£: mtp-baseline
HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•:   0%|          | 0/10 [00:00<?, ? examples/s]HFνΈν™ ν† ν¬λ‚μ΄μ €λ΅ λ°μ΄ν„°μ…‹ ν† ν¬λ‚μ΄μ§•: 100%|β–β–β–β–β–β–β–β–β–β–| 10/10 [00:00<00:00, 3785.13 examples/s]
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” λ¶„μ‚° ν›λ ¨μ© λ°μ΄ν„° μƒν”λ¬ μ„¤μ • μ™„λ£: mtp-baseline
π” PyTorch DataLoader μƒμ„± μ™„λ£: mtp-baseline
π” Stage1 μ‚¬μ „ν›λ ¨ μ™„λ£: mtp-baseline
π” λ©”μΈ Trainer μƒμ„± λ° μ΄κΈ°ν™” μ™„λ£: mtp-baseline
π” μ‹¤ν–‰ λ¨λ“ λ¶„κΈ° μ™„λ£: mtp-baseline
μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν™μ„±ν™”: λ§¤ 5μ¤ν…λ§λ‹¤ μ €μ¥
μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: checkpoints/m3_test_mtp_baseline
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨ (μ¤ν… 5): 'AdamWBF16FusedOptimizer' object has no attribute
'state_dict'
μµμΆ… λ¨λΈ μ €μ¥ μ‹¤ν¨: 'AdamWBF16FusedOptimizer' object has no attribute 
'state_dict'
π” λ©”μΈ WMTP ν›λ ¨ μ‹¤ν–‰ μ™„λ£: mtp-baseline
Ended MLflow run with status: FINISHED
π νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ™„λ£
π” νμ΄ν”„λΌμΈ μ‹¤ν–‰ κ²°κ³Ό: {'loss': 0.010550212115049362, 'lr': 5e-05}

β“ Pipeline test completed successfully!

Training Metrics:
  loss: 0.0106
  lr: 0.0001

Test complete! The WMTP pipeline is working.
