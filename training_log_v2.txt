╭──────────── 🧪 Test Mode ────────────╮
│ WMTP Pipeline Test on MacBook M3     │
│ Testing with small model and dataset │
╰──────────────────────────────────────╯

Checking environment...
✓ PyTorch version: 2.4.1
✓ MPS (Metal Performance Shaders) is available
  MPS device: True
✓ Total memory: 36.0 GB
  Available memory: 16.0 GB
✓ Transformers version: 4.56.2

Loading configurations...
✓ Loaded config: configs/config.m3_test.yaml
✓ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
✓ Test model loaders registered
✓ Test data loader registered
Random seed set to 42
✓ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
✓ Training pipeline imported successfully
🚀 파이프라인 실행 시작
🔍 파이프라인 단계 추적 시작...
Random seed set to 42
🔍 체크포인트 로딩 완료: epoch=0, step=0
🔍 MLflow Run ID: None
Started MLflow run: e83b27567a8846cbb38eb92c76274f45
🔍 MLflow 실험 추적 초기화 완료: run_name=m3_test_mtp_baseline
`torch_dtype` is deprecated! Use `dtype` instead!
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Creating new MTP wrapper for distilgpt2
[MTPWrapper] Using device: mps
[MTPWrapper] Loading base model: distilgpt2
[MTPWrapper] Created 3 extra MTP heads
[TestMTPLoader] Saving model to cache: /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Model cached successfully
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
🔍 Base 모델 로딩 완료: distilgpt2
🔍 토크나이저 생성 완료: distilgpt2
🔍 알고리즘별 추가 모델 로딩 완료: mtp-baseline
🔍 옵티마이저 설정 완료: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 1966.02 examples/s]
🔍 데이터셋 토크나이징 완료: mtp-baseline
HF호환 토크나이저로 데이터셋 토크나이징:   0%|          | 0/10 [00:00<?, ? examples/s]HF호환 토크나이저로 데이터셋 토크나이징: 100%|██████████| 10/10 [00:00<00:00, 3804.01 examples/s]
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 PyTorch DataLoader 생성 완료: mtp-baseline
🔍 Stage1 사전훈련 완료: mtp-baseline
🔍 메인 Trainer 생성 및 초기화 완료: mtp-baseline
🔍 실행 모드 분기 완료: mtp-baseline
체크포인트 저장 활성화: 매 5스텝마다 저장
체크포인트 디렉토리: checkpoints/m3_test_mtp_baseline

Pipeline test failed: 'MTPWeightedCETrainer' object has no attribute 'device'

This is expected for initial testing.
Common issues:
  1. Model loading issues - check paths
  2. Memory issues - use --tiny flag
  3. MPS issues - may need to use CPU

Full traceback:
Traceback (most recent call last):
  File "/Users/wesley/Desktop/wooshikwon/wmtp/test_m3_pipeline.py", line 236, in main
    outputs = run_training_pipeline(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/pipelines/training_pipeline.py", line 266, in run_training_pipeline
    metrics = trainer.run({
              ^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 718, in run
    out = self.train_step(batch)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 341, in train_step
    batch = {k: v.to(self.device) if torch.is_tensor(v) else v
                     ^^^^^^^^^^^
AttributeError: 'MTPWeightedCETrainer' object has no attribute 'device'
╭──────────── 🧪 Test Mode ────────────╮
│ WMTP Pipeline Test on MacBook M3     │
│ Testing with small model and dataset │
╰──────────────────────────────────────╯

Checking environment...
✓ PyTorch version: 2.4.1
✓ MPS (Metal Performance Shaders) is available
  MPS device: True
✓ Total memory: 36.0 GB
  Available memory: 15.6 GB
✓ Transformers version: 4.56.2

Loading configurations...
✓ Loaded config: configs/config.m3_test.yaml
✓ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
✓ Test model loaders registered
✓ Test data loader registered
Random seed set to 42
✓ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
✓ Training pipeline imported successfully
🚀 파이프라인 실행 시작
🔍 파이프라인 단계 추적 시작...
Random seed set to 42
🔍 체크포인트 로딩 완료: epoch=0, step=0
🔍 MLflow Run ID: None
Started MLflow run: 2ef448edee5342af91cd389f62f12d79
🔍 MLflow 실험 추적 초기화 완료: run_name=m3_test_mtp_baseline
/Users/wesley/Desktop/wooshikwon/wmtp/src/components/loader/test_mtp_loader.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(cache_path, map_location=self.device)
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Loading cached model from /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Successfully loaded cached model
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
🔍 Base 모델 로딩 완료: distilgpt2
🔍 토크나이저 생성 완료: distilgpt2
🔍 알고리즘별 추가 모델 로딩 완료: mtp-baseline
🔍 옵티마이저 설정 완료: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 2708.62 examples/s]
🔍 데이터셋 토크나이징 완료: mtp-baseline
HF호환 토크나이저로 데이터셋 토크나이징:   0%|          | 0/10 [00:00<?, ? examples/s]HF호환 토크나이저로 데이터셋 토크나이징: 100%|██████████| 10/10 [00:00<00:00, 4427.17 examples/s]
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 PyTorch DataLoader 생성 완료: mtp-baseline
🔍 Stage1 사전훈련 완료: mtp-baseline
🔍 메인 Trainer 생성 및 초기화 완료: mtp-baseline
🔍 실행 모드 분기 완료: mtp-baseline
체크포인트 저장 활성화: 매 5스텝마다 저장
체크포인트 디렉토리: checkpoints/m3_test_mtp_baseline
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.

Pipeline test failed: name 'ce_per_token' is not defined

This is expected for initial testing.
Common issues:
  1. Model loading issues - check paths
  2. Memory issues - use --tiny flag
  3. MPS issues - may need to use CPU

Full traceback:
Traceback (most recent call last):
  File "/Users/wesley/Desktop/wooshikwon/wmtp/test_m3_pipeline.py", line 236, in main
    outputs = run_training_pipeline(
              ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/pipelines/training_pipeline.py", line 266, in run_training_pipeline
    metrics = trainer.run({
              ^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 730, in run
    out = self.train_step(batch)
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/wesley/Desktop/wooshikwon/wmtp/src/components/trainer/mtp_weighted_ce_trainer.py", line 676, in train_step
    or not torch.isfinite(ce_per_token).all()
                          ^^^^^^^^^^^^
NameError: name 'ce_per_token' is not defined
╭──────────── 🧪 Test Mode ────────────╮
│ WMTP Pipeline Test on MacBook M3     │
│ Testing with small model and dataset │
╰──────────────────────────────────────╯

Checking environment...
✓ PyTorch version: 2.4.1
✓ MPS (Metal Performance Shaders) is available
  MPS device: True
✓ Total memory: 36.0 GB
  Available memory: 16.6 GB
✓ Transformers version: 4.56.2

Loading configurations...
✓ Loaded config: configs/config.m3_test.yaml
✓ Loaded recipe: configs/recipe.m3_test.yaml

Using tiny model (distilgpt2) for ultra-light testing
  Model: distilgpt2 (82M parameters)
  Max sequence length: 64
  Training steps: 5

Configuring test model loader...
✓ Test model loaders registered
✓ Test data loader registered
Random seed set to 42
✓ Random seed set to 42

Pipeline Configuration:
  Algorithm: mtp-baseline
  Model: distilgpt2
  Device: mps
  Batch size: 1
  Max steps: 5
  Dry run: False

Starting actual training (auto-confirmed for testing)...

Starting WMTP pipeline test...
✓ Training pipeline imported successfully
🚀 파이프라인 실행 시작
🔍 파이프라인 단계 추적 시작...
Random seed set to 42
🔍 체크포인트 로딩 완료: epoch=0, step=0
🔍 MLflow Run ID: None
Started MLflow run: 4a136f73dee24a8687275ab4da982621
🔍 MLflow 실험 추적 초기화 완료: run_name=m3_test_mtp_baseline
/Users/wesley/Desktop/wooshikwon/wmtp/src/components/loader/test_mtp_loader.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(cache_path, map_location=self.device)
[TestMTPLoader] Setup complete. Device: mps
[TestMTPLoader] Loading cached model from /Users/wesley/.cache/wmtp/test_models/mtp_wrapper_distilgpt2.pt
[TestMTPLoader] Successfully loaded cached model
[TestMTPLoader] Model loaded successfully
[TestMTPLoader] Total params: 197,704,704
[TestMTPLoader] Trainable params: 197,704,704
[TestMTPLoader] Estimated memory: 0.74 GB
🔍 Base 모델 로딩 완료: distilgpt2
🔍 토크나이저 생성 완료: distilgpt2
🔍 알고리즘별 추가 모델 로딩 완료: mtp-baseline
🔍 옵티마이저 설정 완료: mtp-baseline
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 1922.41 examples/s]
🔍 데이터셋 토크나이징 완료: mtp-baseline
HF호환 토크나이저로 데이터셋 토크나이징:   0%|          | 0/10 [00:00<?, ? examples/s]HF호환 토크나이저로 데이터셋 토크나이징: 100%|██████████| 10/10 [00:00<00:00, 3785.13 examples/s]
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 분산 훈련용 데이터 샘플러 설정 완료: mtp-baseline
🔍 PyTorch DataLoader 생성 완료: mtp-baseline
🔍 Stage1 사전훈련 완료: mtp-baseline
🔍 메인 Trainer 생성 및 초기화 완료: mtp-baseline
🔍 실행 모드 분기 완료: mtp-baseline
체크포인트 저장 활성화: 매 5스텝마다 저장
체크포인트 디렉토리: checkpoints/m3_test_mtp_baseline
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
/Users/wesley/Desktop/wooshikwon/wmtp/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
체크포인트 저장 실패 (스텝 5): 'AdamWBF16FusedOptimizer' object has no attribute
'state_dict'
최종 모델 저장 실패: 'AdamWBF16FusedOptimizer' object has no attribute 
'state_dict'
🔍 메인 WMTP 훈련 실행 완료: mtp-baseline
Ended MLflow run with status: FINISHED
🏁 파이프라인 실행 완료
🔍 파이프라인 실행 결과: {'loss': 0.010550212115049362, 'lr': 5e-05}

✓ Pipeline test completed successfully!

Training Metrics:
  loss: 0.0106
  lr: 0.0001

Test complete! The WMTP pipeline is working.
