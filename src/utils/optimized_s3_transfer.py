"""
ëŒ€ìš©ëŸ‰ ëª¨ë¸ì„ ìœ„í•œ S3 ìµœì í™” ì „ì†¡ ìœ í‹¸ë¦¬í‹°

WMTPì˜ 10GB+ ëª¨ë¸ íŒŒì¼ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•œ ìµœì í™”:
- boto3 TransferConfigë¡œ ë©€í‹°íŒŒíŠ¸ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ
- ëŒ€ìš©ëŸ‰/ì†Œìš©ëŸ‰ íŒŒì¼ ì§€ëŠ¥ì  ì²˜ë¦¬
- ì§„í–‰ë¥  í‘œì‹œ ë° ë„¤íŠ¸ì›Œí¬ ìž¬ì‹œë„ ë¡œì§
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
"""

from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

from boto3.s3.transfer import TransferConfig
from rich.console import Console
from rich.progress import (
    BarColumn,
    DownloadColumn,
    Progress,
    TaskID,
    TextColumn,
    TimeRemainingColumn,
    TransferSpeedColumn,
)

console = Console()


class OptimizedS3Transfer:
    """S3 ëŒ€ìš©ëŸ‰ ëª¨ë¸ ìµœì í™” ì „ì†¡ í´ëž˜ìŠ¤"""

    def __init__(self, s3_client, bucket: str):
        """
        Args:
            s3_client: boto3 S3 client
            bucket: S3 ë²„í‚· ì´ë¦„
        """
        self.s3_client = s3_client
        self.bucket = bucket

        # WMTP ëŒ€ìš©ëŸ‰ ëª¨ë¸ìš© ìµœì í™” ì„¤ì •
        self.transfer_config = TransferConfig(
            multipart_threshold=1024 * 25,  # 25MB ì´ìƒë¶€í„° ë©€í‹°íŒŒíŠ¸
            max_concurrency=10,  # ìµœëŒ€ 10ê°œ ë³‘ë ¬ ì—°ê²°
            multipart_chunksize=1024 * 25,  # 25MB ì²­í¬ í¬ê¸°
            use_threads=True,  # ìŠ¤ë ˆë“œ í’€ í™œì„±í™”
            num_download_attempts=3,  # ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ì‹œ 3íšŒ ìž¬ì‹œë„
            max_io_queue=100,  # I/O í í¬ê¸° (ë™ì‹œ ìš”ì²­ ìˆ˜)
            io_chunksize=1024 * 256,  # 256KB I/O ì²­í¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        )

        # ëŒ€ìš©ëŸ‰/ì†Œìš©ëŸ‰ íŒŒì¼ êµ¬ë¶„ ìž„ê³„ê°’ (100MB)
        self.large_file_threshold = 100 * 1024 * 1024

    def get_file_info(self, key_prefix: str) -> list[tuple[str, int]]:
        """S3ì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ (í‚¤, í¬ê¸°)"""
        files = []
        paginator = self.s3_client.get_paginator("list_objects_v2")

        for page in paginator.paginate(Bucket=self.bucket, Prefix=key_prefix):
            if "Contents" not in page:
                continue

            for obj in page["Contents"]:
                key = obj["Key"]
                size = obj["Size"]

                # ë””ë ‰í† ë¦¬ëŠ” ì œì™¸
                if not key.endswith("/"):
                    files.append((key, size))

        return files

    def download_file_optimized(
        self,
        s3_key: str,
        local_path: Path,
        file_size: int,
        progress: Progress | None = None,
        task_id: TaskID | None = None,
    ) -> tuple[bool, str | None]:
        """ìµœì í™”ëœ ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ

        Args:
            s3_key: S3 ê°ì²´ í‚¤
            local_path: ë¡œì»¬ ì €ìž¥ ê²½ë¡œ
            file_size: íŒŒì¼ í¬ê¸° (ì§„í–‰ë¥ ìš©)
            progress: Rich Progress ì¸ìŠ¤í„´ìŠ¤
            task_id: Progress íƒœìŠ¤í¬ ID

        Returns:
            (ì„±ê³µ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€)
        """
        try:
            local_path.parent.mkdir(parents=True, exist_ok=True)

            # ì§„í–‰ë¥  ì½œë°± í•¨ìˆ˜
            def progress_callback(bytes_transferred):
                if progress and task_id:
                    progress.update(task_id, advance=bytes_transferred)

            # boto3ì˜ ìµœì í™”ëœ ë‹¤ìš´ë¡œë“œ (ìžë™ ë©€í‹°íŒŒíŠ¸ ì ìš©)
            self.s3_client.download_file(
                self.bucket,
                s3_key,
                str(local_path),
                Config=self.transfer_config,
                Callback=progress_callback,
            )

            return True, None

        except Exception as e:
            error_msg = f"Download failed for {s3_key}: {e}"
            console.print(f"[red]âŒ {error_msg}[/red]")
            return False, error_msg

    def download_model_directory(
        self, s3_key_prefix: str, temp_dir: Path, show_progress: bool = True
    ) -> tuple[bool, list[str]]:
        """ëª¨ë¸ ë””ë ‰í† ë¦¬ ì „ì²´ë¥¼ ìµœì í™”ëœ ë°©ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ

        Args:
            s3_key_prefix: S3 í‚¤ í”„ë¦¬í”½ìŠ¤ (ì˜ˆ: "models/llama-7b/")
            temp_dir: ìž„ì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€

        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡)
        """
        # 1. íŒŒì¼ ì •ë³´ ì¡°íšŒ
        files = self.get_file_info(s3_key_prefix)
        if not files:
            console.print(f"[yellow]âš ï¸ No files found at {s3_key_prefix}[/yellow]")
            return False, []

        # 2. ëŒ€ìš©ëŸ‰/ì†Œìš©ëŸ‰ íŒŒì¼ ë¶„ë¥˜
        large_files = [
            (key, size) for key, size in files if size > self.large_file_threshold
        ]
        small_files = [
            (key, size) for key, size in files if size <= self.large_file_threshold
        ]

        total_size = sum(size for _, size in files)
        console.print(
            f"[cyan]ðŸ“¦ Downloading {len(files)} files ({total_size / (1024**3):.2f}GB)[/cyan]"
        )
        console.print(f"  Large files (>100MB): {len(large_files)}")
        console.print(f"  Small files (â‰¤100MB): {len(small_files)}")

        downloaded_files = []
        success_count = 0

        if show_progress:
            # 3. ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ
            with Progress(
                TextColumn("[bold blue]{task.description}"),
                BarColumn(),
                "[progress.percentage]{task.percentage:>3.1f}%",
                DownloadColumn(),
                TransferSpeedColumn(),
                TimeRemainingColumn(),
                console=console,
                refresh_per_second=2,
            ) as progress:
                # ëŒ€ìš©ëŸ‰ íŒŒì¼ ìˆœì°¨ ì²˜ë¦¬ (ë©€í‹°íŒŒíŠ¸ ìžë™ ì ìš©)
                for s3_key, file_size in large_files:
                    file_name = s3_key.split("/")[-1]
                    local_path = temp_dir / file_name

                    task_id = progress.add_task(f"ðŸ“¥ {file_name}", total=file_size)

                    success, error = self.download_file_optimized(
                        s3_key, local_path, file_size, progress, task_id
                    )

                    if success:
                        success_count += 1
                        downloaded_files.append(str(local_path))
                        progress.update(task_id, completed=file_size)

                # ì†Œìš©ëŸ‰ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 5ê°œ ë™ì‹œ)
                if small_files:
                    with ThreadPoolExecutor(max_workers=5) as executor:
                        future_to_task = {}

                        for s3_key, file_size in small_files:
                            file_name = s3_key.split("/")[-1]
                            local_path = temp_dir / file_name

                            task_id = progress.add_task(
                                f"ðŸ“¥ {file_name}", total=file_size
                            )

                            future = executor.submit(
                                self.download_file_optimized,
                                s3_key,
                                local_path,
                                file_size,
                                progress,
                                task_id,
                            )
                            future_to_task[future] = (
                                s3_key,
                                local_path,
                                task_id,
                                file_size,
                            )

                        for future in as_completed(future_to_task):
                            s3_key, local_path, task_id, file_size = future_to_task[
                                future
                            ]
                            try:
                                success, error = future.result()
                                if success:
                                    success_count += 1
                                    downloaded_files.append(str(local_path))
                                    progress.update(task_id, completed=file_size)
                            except Exception as e:
                                console.print(
                                    f"[red]âŒ Exception for {s3_key}: {e}[/red]"
                                )

        else:
            # ì§„í–‰ë¥  ì—†ì´ ë‹¤ìš´ë¡œë“œ (ì¡°ìš©í•œ ëª¨ë“œ)
            for s3_key, file_size in files:
                file_name = s3_key.split("/")[-1]
                local_path = temp_dir / file_name

                success, error = self.download_file_optimized(
                    s3_key, local_path, file_size
                )
                if success:
                    success_count += 1
                    downloaded_files.append(str(local_path))

        # ê²°ê³¼ ìš”ì•½
        total_files = len(files)
        if success_count == total_files:
            console.print(
                f"[bold green]âœ… Download complete: {success_count}/{total_files} files[/bold green]"
            )
            return True, downloaded_files
        else:
            console.print(
                f"[yellow]âš ï¸ Partial success: {success_count}/{total_files} files[/yellow]"
            )
            return success_count > 0, downloaded_files

    def download_specific_files(
        self,
        s3_key_prefix: str,
        required_files: list[str],
        temp_dir: Path,
        show_progress: bool = True,
    ) -> tuple[bool, list[str]]:
        """íŠ¹ì • íŒŒì¼ë“¤ë§Œ ì„ íƒì  ë‹¤ìš´ë¡œë“œ (HuggingFace ëª¨ë¸ ì „ìš©)

        Args:
            s3_key_prefix: S3 í‚¤ í”„ë¦¬í”½ìŠ¤
            required_files: ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ëª… ëª©ë¡
            temp_dir: ìž„ì‹œ ë””ë ‰í† ë¦¬
            show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€

        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡)
        """
        downloaded_files = []
        success_count = 0

        if show_progress:
            with Progress(console=console) as progress:
                for filename in required_files:
                    s3_key = f"{s3_key_prefix.rstrip('/')}/{filename}"
                    local_path = temp_dir / filename

                    # íŒŒì¼ í¬ê¸° ì¡°íšŒ
                    try:
                        response = self.s3_client.head_object(
                            Bucket=self.bucket, Key=s3_key
                        )
                        file_size = response["ContentLength"]

                        task_id = progress.add_task(f"ðŸ“¥ {filename}", total=file_size)

                        success, error = self.download_file_optimized(
                            s3_key, local_path, file_size, progress, task_id
                        )

                        if success:
                            success_count += 1
                            downloaded_files.append(str(local_path))
                            progress.update(task_id, completed=file_size)

                    except Exception as e:
                        console.print(f"[yellow]âš ï¸ Skipping {filename}: {e}[/yellow]")
                        continue
        else:
            # ì¡°ìš©í•œ ëª¨ë“œ
            for filename in required_files:
                s3_key = f"{s3_key_prefix.rstrip('/')}/{filename}"
                local_path = temp_dir / filename

                try:
                    response = self.s3_client.head_object(
                        Bucket=self.bucket, Key=s3_key
                    )
                    file_size = response["ContentLength"]

                    success, error = self.download_file_optimized(
                        s3_key, local_path, file_size
                    )
                    if success:
                        success_count += 1
                        downloaded_files.append(str(local_path))

                except Exception:
                    continue

        console.print(
            f"[green]ðŸ“ Downloaded {success_count}/{len(required_files)} files[/green]"
        )
        return success_count > 0, downloaded_files
