# WMTP μ‹μ¤ν… κ°μ„  κ³„νμ„
## 2025λ…„ 1μ›” - Phaseλ³„ μƒμ„Έ μ‹¤ν–‰ κ³„ν

---

## π“‹ Executive Summary

### λ°κ²¬λ ν•µμ‹¬ μ΄μ
1. **[Critical]** μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨ - KeyError(None)
2. **[High]** MPS/FSDP νΈν™μ„± λ¬Έμ 
3. **[Medium]** API deprecation κ²½κ³ 
4. **[Low]** λ¦¬μ†μ¤ λ„μ (μ„Έλ§ν¬μ–΄ 15κ°)

### κ°μ„  λ©ν‘
- **μ¦‰μ‹ λ©ν‘**: ν•µμ‹¬ κΈ°λ¥ λ³µκµ¬ (μ²΄ν¬ν¬μΈνΈ μ €μ¥)
- **λ‹¨κΈ° λ©ν‘**: MPS ν™κ²½ μµμ ν™” λ° κ²½κ³  μ κ±°
- **μ¤‘κΈ° λ©ν‘**: κΈ°μ  λ¶€μ±„ ν•΄κ²° λ° ν„λ€μ  API λ„μ…

---

## π” ν„ν™© λ¶„μ„

### 1. μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨ λ¶„μ„

#### μ½”λ“ νλ¦„
```
BaseWmtpTrainer._save_checkpoint()
    β†“
DistributedManager.save_checkpoint(model, ...)
    β†“
FSDP.state_dict_type(model, ...)  # β† μ—¬κΈ°μ„ μ‹¤ν¨
```

#### κ·Όλ³Έ μ›μΈ
- `save_checkpoint()` λ©”μ„λ“κ°€ FSDP λν•‘λ λ¨λΈλ§ μ²λ¦¬ κ°€λ¥
- ν…μ¤νΈ ν™κ²½: `fsdp.enabled: false` β†’ λ¨λΈμ΄ μΌλ° `nn.Module`
- `isinstance(model, FSDP)` μ²΄ν¬ μ—†μ΄ λ¬΄μ΅°κ±΄ FSDP λ΅μ§ μ‹¤ν–‰
- κ²°κ³Ό: `KeyError(None)` λ°μƒ

#### μν–¥ λ²”μ„
- λ¨λ“  non-FSDP ν™κ²½μ—μ„ μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ¶κ°€
- ν•™μµ μ¤‘λ‹¨ μ‹ λ³µκµ¬ λ¶κ°€λ¥
- MLflow μ•„ν‹°ν©νΈ μ—…λ΅λ“ μ‹¤ν¨

### 2. MPS νΈν™μ„± λ¬Έμ  λ¶„μ„

#### λ°μƒ κ²½κ³ λ“¤
```python
# 1. CPU autocast κ²½κ³ 
"In CPU autocast, but the target dtype is not supported"

# 2. FSDP API deprecation
"FSDP.state_dict_type() is being deprecated"

# 3. λ¦¬μ†μ¤ λ„μ
"resource_tracker: 15 leaked semaphore objects"
```

#### μ›μΈ λ¶„μ„
1. **Autocast λ¬Έμ **: MPSλ” fp32λ§ μ§€μ›, bf16/fp16 λ―Έμ§€μ›
2. **FSDP API**: κµ¬λ²„μ „ API μ‚¬μ© μ¤‘
3. **λ¦¬μ†μ¤ λ„μ**: DataLoader `num_workers=4`κ°€ MPSμ—μ„ λ¬Έμ  μ λ°

---

## π“ Phaseλ³„ κ°μ„  κ³„ν

## Phase 1: Critical Fix - μ²΄ν¬ν¬μΈνΈ μ €μ¥ μμ •
**λ©ν‘**: FSDP/non-FSDP λ¨λΈ λ¨λ‘μ—μ„ μ²΄ν¬ν¬μΈνΈ μ €μ¥ κ°€λ¥
**μΌμ •**: μ¦‰μ‹ μ‹¤ν–‰
**μ„ν—λ„**: λ‚®μ (μ΅°κ±΄ λ¶„κΈ°λ§ μ¶”κ°€)

### 1.1 κµ¬ν„ λ‚΄μ©

#### src/utils/dist.py μμ •
```python
def save_checkpoint(
    self,
    model: Union[FSDP, nn.Module],  # νƒ€μ… ννΈ μμ •
    optimizer: torch.optim.Optimizer,
    checkpoint_path: str,
    epoch: int,
    step: int,
    mlflow_manager=None,
    **kwargs,
) -> None:
    """μ²΄ν¬ν¬μΈνΈ μ €μ¥ (FSDP/non-FSDP λ¨λΈ λ¨λ‘ μ§€μ›)"""

    if self.is_main_process():
        # λ¨λΈ νƒ€μ…μ— λ”°λ¥Έ λ¶„κΈ° μ²λ¦¬
        if isinstance(model, FSDP):
            # κΈ°μ΅΄ FSDP λ΅μ§ μ μ§€
            save_policy = FullStateDictConfig(
                offload_to_cpu=True,
                rank0_only=True,
            )
            with FSDP.state_dict_type(
                model, StateDictType.FULL_STATE_DICT, save_policy
            ):
                state_dict = model.state_dict()
        else:
            # μΌλ° λ¨λΈ μ²λ¦¬ (μ‹ κ· μ¶”κ°€)
            state_dict = model.state_dict()
            # CPUλ΅ μ΄λ™ (λ©”λ¨λ¦¬ ν¨μ¨μ„±)
            if hasattr(model, 'device') and model.device.type != 'cpu':
                state_dict = {k: v.cpu() for k, v in state_dict.items()}

        # κ³µν†µ μ²΄ν¬ν¬μΈνΈ κµ¬μ„± (κΈ°μ΅΄ λ΅μ§ μ μ§€)
        checkpoint = {
            "model": state_dict,
            "optimizer": optimizer.state_dict(),
            "epoch": epoch,
            "step": step,
            **kwargs,
        }

        # μ €μ¥ λ΅μ§ (κΈ°μ΅΄ μ μ§€)
        self._save_checkpoint_to_storage(checkpoint, checkpoint_path, mlflow_manager)
```

### 1.2 ν…μ¤νΈ κ³„ν
- [ ] FSDP enabled ν™κ²½ ν…μ¤νΈ
- [ ] FSDP disabled ν™κ²½ ν…μ¤νΈ
- [ ] MPS ν™κ²½ ν…μ¤νΈ
- [ ] μ²΄ν¬ν¬μΈνΈ λ΅λ“ κ²€μ¦
- [ ] MLflow μ—…λ΅λ“ κ²€μ¦

### 1.3 λ΅¤λ°± κ³„ν
- Git μ»¤λ°‹ λ‹¨μ„ κ΄€λ¦¬
- μ‹¤ν¨ μ‹ μ΄μ „ μ»¤λ°‹μΌλ΅ μ¦‰μ‹ λ΅¤λ°±

---

## Phase 2: MPS Optimization - Apple Silicon μµμ ν™”
**λ©ν‘**: MPS ν™κ²½ μµμ ν™” λ° λ¨λ“  κ²½κ³  μ κ±°
**μΌμ •**: Phase 1 μ™„λ£ ν›„ 1μ£ΌμΌ λ‚΄
**μ„ν—λ„**: μ¤‘κ°„ (μ„¤μ • λ³€κ²½ μν–¥)

### 2.1 κµ¬ν„ λ‚΄μ©

#### 2.1.1 Autocast μ΅°κ±΄λ¶€ μ²λ¦¬
```python
# src/components/trainer/base_wmtp_trainer.py
def train(self, ...):
    # MPS κ°μ§€
    device_type = str(self.model.device.type) if hasattr(self.model, 'device') else 'cpu'
    use_autocast = device_type in ['cuda'] and self.mixed_precision != 'fp32'

    # μ΅°κ±΄λ¶€ autocast
    if use_autocast:
        with torch.autocast(device_type=device_type, dtype=self.get_autocast_dtype()):
            loss = self._compute_loss(batch)
    else:
        loss = self._compute_loss(batch)  # MPSλ” autocast μ¤ν‚µ
```

#### 2.1.2 DataLoader μλ™ μµμ ν™”
```python
# src/factory/component_factory.py
def create_data_loader(self, ...):
    # MPS ν™κ²½ κ°μ§€
    is_mps = (
        hasattr(torch.backends, 'mps') and
        torch.backends.mps.is_available() and
        self.config.devices.compute_backend == 'mps'
    )

    # num_workers μλ™ μ΅°μ •
    if is_mps and num_workers > 0:
        console.print(
            f"[yellow]MPS ν™κ²½ κ°μ§€: num_workersλ¥Ό {num_workers} β†’ 0μΌλ΅ μλ™ μ΅°μ •[/yellow]"
        )
        num_workers = 0

    # DataLoader μƒμ„± (κΈ°μ΅΄ λ΅μ§ μ μ§€)
    return DataLoader(..., num_workers=num_workers)
```

#### 2.1.3 MPS ν”„λ΅νμΌ μƒμ„±
```yaml
# configs/profiles/mps_optimized.yaml
devices:
  compute_backend: "mps"
  mixed_precision: "fp32"  # MPSλ” fp32λ§ μ§€μ›
  fsdp:
    enabled: false  # MPSμ—μ„ FSDP λΉ„ν™μ„±ν™”

data:
  train:
    num_workers: 0  # λ©€ν‹°ν”„λ΅μ„Έμ‹± λΉ„ν™μ„±ν™”
  eval:
    num_workers: 0

optim:
  grad_accumulation_steps: 4  # λ©”λ¨λ¦¬ ν¨μ¨μ„±

# MPS μ „μ© μµμ ν™” ν”λκ·Έ
mps_optimizations:
  use_graph_mode: false  # μ•μ •μ„± μ°μ„ 
  fallback_to_cpu: true  # μ§€μ› μ•λλ” μ—°μ‚°μ€ CPUλ΅
```

### 2.2 ν…μ¤νΈ κ³„ν
- [ ] MPS autocast μ¤ν‚µ κ²€μ¦
- [ ] DataLoader μ„Έλ§ν¬μ–΄ λ„μ ν•΄κ²° ν™•μΈ
- [ ] μ„±λ¥ λ²¤μΉλ§ν¬ (vs CPU)
- [ ] λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λ¨λ‹ν„°λ§

---

## Phase 3: API Modernization - κΈ°μ  λ¶€μ±„ ν•΄κ²°
**λ©ν‘**: Deprecated API μ κ±° λ° ν„λ€μ  ν¨ν„΄ λ„μ…
**μΌμ •**: Phase 2 μ™„λ£ ν›„ 2μ£Ό λ‚΄
**μ„ν—λ„**: λ†’μ (API λ§μ΄κ·Έλ μ΄μ…)

### 3.1 κµ¬ν„ λ‚΄μ©

#### 3.1.1 FSDP API ν„λ€ν™”
```python
# src/utils/dist.py - μƒλ΅μ΄ API λ„μ…
def save_checkpoint_v2(self, model, optimizer, ...):
    """μƒλ΅μ΄ FSDP API μ‚¬μ©"""
    from torch.distributed.checkpoint import (
        get_state_dict,
        StateDictOptions,
    )

    if isinstance(model, FSDP):
        # μƒλ΅μ΄ API μ‚¬μ©
        options = StateDictOptions(
            full_state_dict=True,
            cpu_offload=True,
        )
        state_dict = get_state_dict(model, options)
    else:
        state_dict = model.state_dict()

    # ... μ €μ¥ λ΅μ§
```

#### 3.1.2 MLflow ν‚¤ κ΄€λ¦¬ κ°•ν™”
```python
# src/utils/mlflow.py
class MLflowManager:
    def get_run_id(self) -> Optional[str]:
        """μ•μ „ν• run ID λ°ν™"""
        if self.run is None:
            return None
        try:
            return self.run.info.run_id
        except AttributeError:
            console.print("[yellow]MLflow run ID μ΅°ν μ‹¤ν¨[/yellow]")
            return None

    def log_metrics_safe(self, metrics: dict, step: int):
        """μ‹¤ν¨ μ‹ graceful degradation"""
        try:
            if self.run is not None:
                mlflow.log_metrics(metrics, step)
        except Exception as e:
            console.print(f"[yellow]MLflow λ©”νΈλ¦­ λ΅κΉ… μ‹¤ν¨ (κ³„μ† μ§„ν–‰): {e}[/yellow]")
```

#### 3.1.3 λ¦¬μ†μ¤ κ΄€λ¦¬ κ°•ν™”
```python
# src/components/trainer/base_wmtp_trainer.py
class BaseWmtpTrainer:
    def __enter__(self):
        """μ»¨ν…μ¤νΈ λ§¤λ‹μ € μ§„μ…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """λ¦¬μ†μ¤ μ •λ¦¬"""
        # DataLoader μ •λ¦¬
        if hasattr(self, 'train_loader'):
            if hasattr(self.train_loader, '_iterator'):
                del self.train_loader._iterator

        # μ„Έλ§ν¬μ–΄ λ…μ‹μ  ν•΄μ 
        import multiprocessing
        multiprocessing.resource_tracker.ensure_running()

        # GPU μΊμ‹ μ •λ¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif hasattr(torch.backends, 'mps'):
            # MPS μΊμ‹ μ •λ¦¬ (μμ„ κ²½μ°)
            pass

# μ‚¬μ© μμ‹
with BaseWmtpTrainer(...) as trainer:
    trainer.train()
```

### 3.2 λ§μ΄κ·Έλ μ΄μ… μ „λµ
1. **Phase 3.1**: μƒ APIμ™€ κµ¬ API λ³‘ν–‰ μ§€μ›
2. **Phase 3.2**: Deprecation κ²½κ³  μ¶”κ°€
3. **Phase 4**: κµ¬ API μ™„μ „ μ κ±° (3κ°μ›” ν›„)

### 3.3 ν…μ¤νΈ κ³„ν
- [ ] μƒ FSDP API λ™μ‘ κ²€μ¦
- [ ] MLflow μ‹¤ν¨ μ‹ ν•™μµ κ³„μ† μ§„ν–‰ ν™•μΈ
- [ ] λ¦¬μ†μ¤ λ„μ μ™„μ „ ν•΄κ²° κ²€μ¦
- [ ] μ„±λ¥ regression ν…μ¤νΈ

---

## π― μ„±κ³µ μ§€ν‘

### μ •λ‰μ  μ§€ν‘
- β… μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ„±κ³µλ¥ : 100%
- β… MPS κ²½κ³  μ: 0
- β… λ¦¬μ†μ¤ λ„μ: 0
- β… ν…μ¤νΈ ν†µκ³Όμ¨: 100%

### μ •μ„±μ  μ§€ν‘
- μ½”λ“ κ°€λ…μ„± ν–¥μƒ
- μ μ§€λ³΄μμ„± κ°μ„ 
- κ°λ°μ κ²½ν— ν–¥μƒ

---

## β οΈ μ„ν— κ΄€λ¦¬

### Phase 1 μ„ν—
- **μ„ν—**: μµμ† (μ΅°κ±΄ λ¶„κΈ°λ§ μ¶”κ°€)
- **μ™„ν™”**: μ¶©λ¶„ν• ν…μ¤νΈ μ»¤λ²„λ¦¬μ§€

### Phase 2 μ„ν—
- **μ„ν—**: μ„¤μ • λ³€κ²½μΌλ΅ μΈν• μ„±λ¥ μν–¥
- **μ™„ν™”**: ν”„λ΅νμΌ κΈ°λ° μ μ§„μ  μ μ©

### Phase 3 μ„ν—
- **μ„ν—**: API λ§μ΄κ·Έλ μ΄μ… μ¤‘ νΈν™μ„± λ¬Έμ 
- **μ™„ν™”**: λ³‘ν–‰ μ§€μ› κΈ°κ°„ μ κ³µ

---

## π“… νƒ€μ„λΌμΈ

| Phase | μ‘μ—… λ‚΄μ© | μμƒ κΈ°κ°„ | μ°μ„ μμ„ |
|-------|-----------|-----------|----------|
| **Phase 1** | μ²΄ν¬ν¬μΈνΈ μ €μ¥ μμ • | 1μΌ | **Critical** |
| **Phase 2** | MPS μµμ ν™” | 1μ£ΌμΌ | **High** |
| **Phase 3** | API ν„λ€ν™” | 2μ£ΌμΌ | **Medium** |
| **Phase 4** | κµ¬ API μ κ±° | 3κ°μ›” ν›„ | **Low** |

---

## π”„ κ°λ° μ›μΉ™ μ¤€μ μ²΄ν¬λ¦¬μ¤νΈ

- [x] **[ν•„μ1]** ν„μ¬ κµ¬μ΅° μ™„μ „ λ¶„μ„ μ™„λ£
- [x] **[ν•„μ2]** κΈ°μ΅΄ κµ¬μ΅° μµλ€ν• μ μ§€, μ¤‘λ³µ μ κ±°
- [x] **[ν•„μ3]** κΈ°μ΅΄ μ½”λ“ μ μ§€κ°€ μ μ  (μ΅°κ±΄ λ¶„κΈ°λ§ μ¶”κ°€)
- [x] **[ν•„μ4]** Phase 4μ—μ„ κµ¬λ²„μ „ μ™„μ „ μ κ±° κ³„ν
- [x] **[ν•„μ5]** κ³„νμ„ μ‘μ„± μ™„λ£, κ°κ΄€μ  κΈ°μ 
- [x] **[ν•„μ6]** uv κΈ°λ° ν¨ν‚¤μ§€ μμ΅΄μ„± ν™μ©

---

## π“ λ‹¤μ λ‹¨κ³„

1. **μ¦‰μ‹**: Phase 1 κµ¬ν„ μ‹μ‘ (μ²΄ν¬ν¬μΈνΈ μ €μ¥ μμ •)
2. **Phase 1 μ™„λ£ ν›„**: ν…μ¤νΈ λ° κ²€μ¦
3. **κ²€μ¦ μ™„λ£ ν›„**: Phase 2 μ§„ν–‰ κ²°μ •

**μ‘μ„±μΌ**: 2025-01-27
**μ‘μ„±μ**: WMTP κ°λ°ν€
**λ²„μ „**: 1.0