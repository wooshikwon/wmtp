# WMTP MTP Data Collator í†µí•© ìˆ˜ì • ê³„íšì„œ
## Factory íŒ¨í„´ ê¸°ë°˜ ì™„ì „ ì•„í‚¤í…ì²˜ í†µí•©

---

## ğŸ“‹ **í˜„ì¬ êµ¬ì¡° ì‹¬ì¸µ ë¶„ì„**

### **ğŸ—ï¸ ComponentFactory ì•„í‚¤í…ì²˜ í˜„í™©**

**Factory ë©”ì„œë“œ íŒ¨í„´**:
```python
# í˜„ì¬ ComponentFactory ë©”ì„œë“œë“¤
ComponentFactory.create_trainer(recipe, config)      # âœ… ì¡´ì¬
ComponentFactory.create_model_loader(config, recipe, type)  # âœ… ì¡´ì¬
ComponentFactory.create_data_loader(recipe, config)  # âœ… ì¡´ì¬
ComponentFactory.create_tokenizer(recipe, config)    # âœ… ì¡´ì¬
ComponentFactory.create_optimizer(recipe, config)    # âœ… ì¡´ì¬
ComponentFactory.create_pretrainer(recipe)           # âœ… ì¡´ì¬

# ëˆ„ë½ëœ ë©”ì„œë“œ
ComponentFactory.create_collator(???, ???)           # âŒ ë¶€ì¬
```

**Registry íŒ¨í„´ í˜„í™©**:
```python
# ê¸°ì¡´ Registryë“¤
loader_registry = _CompatibilityAdapter("loader")     # âœ…
trainer_registry = _CompatibilityAdapter("trainer")   # âœ…
tokenizer_registry = _CompatibilityAdapter("tokenizer") # âœ…
optimizer_registry = _CompatibilityAdapter("optimizer") # âœ…
evaluator_registry = _CompatibilityAdapter("evaluator") # âœ…
pretrainer_registry = _CompatibilityAdapter("pretrainer") # âœ…

# í•„ìš”í•œ ì¶”ê°€ Registry
collator_registry = _CompatibilityAdapter("collator") # âŒ ë¶€ì¬
```

### **ğŸ”„ Training Pipeline ë°ì´í„° í”Œë¡œìš°**

**í˜„ì¬ í”Œë¡œìš°**:
```
Step 4: ComponentFactory.create_model_loader() â†’ base ëª¨ë¸
Step 5: ComponentFactory.create_tokenizer() â†’ í† í¬ë‚˜ì´ì €
Step 6: ComponentFactory.create_data_loader() â†’ ë°ì´í„°ì…‹
Step 7: tokenizer.tokenize_dataset() â†’ í† í°í™”
Step 8: ë¶„ì‚° ìƒ˜í”ŒëŸ¬ ì„¤ì •
Step 9: DataLoader(collate_fn=default_data_collator) â† ğŸš¨ ë¬¸ì œ ì§€ì 
```

**Factory íŒ¨í„´ ìœ„ë°˜**:
- ëª¨ë“  ì»´í¬ë„ŒíŠ¸ëŠ” Factoryì—ì„œ ìƒì„±ë˜ëŠ”ë° **collatorë§Œ í•˜ë“œì½”ë”©**
- `pack_sequences` ì„¤ì •ì´ Recipeì— ìˆìœ¼ë‚˜ **ì™„ì „íˆ ë¬´ì‹œë¨**

---

## ğŸš¨ **í™•ì¸ëœ ë¬¸ì œ ì¢…í•©**

### **Critical Issues**

1. **KeyError: 'hidden_states'** (critic_head_pretrainer.py:221)
   - ì›ì¸: unsafeí•œ ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼
   - ì˜í–¥: Critic-WMTP Stage 1 ì™„ì „ ë¸”ë¡

2. **ë°°ì¹˜ ì°¨ì› ë¶ˆì¼ì¹˜** (training_pipeline.py:224)
   - ì›ì¸: `default_data_collator` íŒ¨ë”© ë¶€ì¬
   - ì˜í–¥: ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ DataLoader ìƒì„± ì‹¤íŒ¨

3. **Factory íŒ¨í„´ ë¶ˆì¼ì¹˜** (training_pipeline.py:224)
   - ì›ì¸: collatorë§Œ Factory ë°–ì—ì„œ í•˜ë“œì½”ë”©
   - ì˜í–¥: ì•„í‚¤í…ì²˜ ì¼ê´€ì„± ê¹¨ì§, pack_sequences ë¬´ì‹œ

### **Major Issues**

4. **MTP ë¼ë²¨ ìƒì„± ë¶€ì¬**
   - ë¬¸ì œ: MTPëŠ” `[B, S, H=4]` ë¼ë²¨ í•„ìš”í•˜ë‚˜ `[B, S]`ë§Œ ìƒì„±
   - ì˜í–¥: ëª¨ë“  WMTP ì•Œê³ ë¦¬ì¦˜ì˜ ë¶€ì •í™•í•œ ì†ì‹¤ ê³„ì‚°

---

## ğŸ¯ **ì„¤ê³„ ê²°ì •ì‚¬í•­**

### **Collator ë¶„ë¥˜ ê¸°ì¤€: ëª¨ë¸ íƒ€ì…**
- **MTPDataCollator**: MTP ëª¨ë¸ìš© (metadata: training_algorithm == "mtp")
- **LMDataCollator**: ì¼ë°˜ ì–¸ì–´ëª¨ë¸ìš© (metadata: training_algorithm != "mtp")

### **Factory í†µí•© í•„ìˆ˜ì„±**
- í˜„ì¬ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ Factory íŒ¨í„´ ì‚¬ìš©
- collatorë§Œ ì˜ˆì™¸ì ìœ¼ë¡œ í•˜ë“œì½”ë”©ë˜ì–´ ì•„í‚¤í…ì²˜ ì¼ê´€ì„± ìœ„ë°˜
- **Registry íŒ¨í„´ìœ¼ë¡œ ì™„ì „ í†µí•© í•„ìš”**

---

## ğŸ› ï¸ **ì™„ì „ í†µí•© êµ¬í˜„ ê³„íš**

### **Phase 1: Collator í´ë˜ìŠ¤ êµ¬í˜„ (1ì‹œê°„)**

#### **1.1 Collator ê¸°ë³¸ í´ë˜ìŠ¤ ìƒì„±**
**íŒŒì¼**: `src/components/data/collators.py`

```python
"""WMTP Data Collator êµ¬í˜„ì²´ë“¤"""

from transformers import DataCollatorForLanguageModeling
import torch
from typing import Dict, List, Any, Optional

from src.components.base import Component


class LMDataCollator(Component, DataCollatorForLanguageModeling):
    """ì¼ë°˜ ì–¸ì–´ëª¨ë¸ìš© Data Collator

    í‘œì¤€ ì–¸ì–´ëª¨ë¸ë§ì„ ìœ„í•œ ê¸°ë³¸ íŒ¨ë”© ë° ë¼ë²¨ ìƒì„±
    """

    def __init__(self, config: Dict[str, Any]):
        Component.__init__(self, config)

        # tokenizerëŠ” configì—ì„œ ì „ë‹¬ë°›ìŒ
        tokenizer = config.get("tokenizer")
        if not tokenizer:
            raise ValueError("tokenizer is required in config")

        DataCollatorForLanguageModeling.__init__(
            self,
            tokenizer=tokenizer,
            mlm=False,  # ì¸ê³¼ì  ì–¸ì–´ ëª¨ë¸ë§
            pad_to_multiple_of=config.get("pad_to_multiple_of", 8)
        )

    def setup(self, inputs: Dict[str, Any]) -> None:
        """Component ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„"""
        pass

    def run(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Component ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” __call__ ì‚¬ìš©"""
        return {"collator": self}


class MTPDataCollator(LMDataCollator):
    """MTP(Multi-Token Prediction)ìš© Data Collator

    LMDataCollatorë¥¼ ìƒì†í•˜ì—¬:
    1. ê¸°ë³¸ íŒ¨ë”©/ë§ˆìŠ¤í‚¹ ê¸°ëŠ¥ ìœ ì§€
    2. MTPìš© multi-horizon ë¼ë²¨ ìƒì„± ì¶”ê°€
    """

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.horizon = config.get("horizon", 4)

    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:
        # 1. ê¸°ë³¸ íŒ¨ë”© ì²˜ë¦¬ (ìƒì†ëœ DataCollatorForLanguageModeling)
        batch = super().__call__(features)

        # 2. MTP ë¼ë²¨ ìƒì„±: [B, S] â†’ [B, S, H]
        if "labels" in batch:
            batch["labels"] = self._create_mtp_labels(batch["labels"])

        return batch

    def _create_mtp_labels(self, labels: torch.Tensor) -> torch.Tensor:
        """[B, S] ë¼ë²¨ì„ [B, S, H] MTP ë¼ë²¨ë¡œ ë³€í™˜

        ê° ìœ„ì¹˜ tì—ì„œ t+1, t+2, t+3, t+4 í† í°ì„ ë¼ë²¨ë¡œ ìƒì„±
        """
        B, S = labels.shape
        device = labels.device
        dtype = labels.dtype

        # MTP ë¼ë²¨ í…ì„œ ì´ˆê¸°í™” (-100ì€ ë¬´ì‹œí•  ë¼ë²¨)
        mtp_labels = torch.full((B, S, self.horizon), -100, dtype=dtype, device=device)

        # ê° horizonì— ëŒ€í•´ ë¼ë²¨ ìƒì„±
        for h in range(self.horizon):
            shift = h + 1  # t+1, t+2, t+3, t+4
            if shift < S:
                # ê° ìœ„ì¹˜ì—ì„œ shiftë§Œí¼ ì•ì˜ í† í°ì„ ë¼ë²¨ë¡œ ì‚¬ìš©
                mtp_labels[:, :S-shift, h] = labels[:, shift:]

        return mtp_labels
```

#### **1.2 Registry ë“±ë¡**
**íŒŒì¼**: `src/components/data/__init__.py`

```python
"""Data Collator ì»´í¬ë„ŒíŠ¸ë“¤"""

from src.components.registry import registry
from .collators import LMDataCollator, MTPDataCollator

# Registry ë“±ë¡
registry.register("lm-data-collator", category="collator")(LMDataCollator)
registry.register("mtp-data-collator", category="collator")(MTPDataCollator)

__all__ = ["LMDataCollator", "MTPDataCollator"]
```

#### **1.3 Registry Adapter ì¶”ê°€**
**íŒŒì¼**: `src/components/registry.py` (ìˆ˜ì •)

```python
# ê¸°ì¡´ Registryë“¤ì— ì¶”ê°€
collator_registry = _CompatibilityAdapter("collator")
```

### **Phase 2: ComponentFactory í†µí•© (30ë¶„)**

#### **2.1 Factory ë©”ì„œë“œ ì¶”ê°€**
**íŒŒì¼**: `src/factory/component_factory.py` (ìˆ˜ì •)

```python
from src.components.registry import collator_registry

class ComponentFactory:
    # ... ê¸°ì¡´ ë©”ì„œë“œë“¤ ...

    @staticmethod
    def create_collator(
        recipe: Recipe,
        config: Config,
        tokenizer: Any,
        model_metadata: Optional[Dict[str, Any]] = None
    ) -> Any:
        """Data Collator ìƒì„± - ëª¨ë¸ íƒ€ì… ê¸°ë°˜ ìë™ ì„ íƒ

        ëª¨ë¸ ë©”íƒ€ë°ì´í„°ì˜ training_algorithmì— ë”°ë¼ ì ì ˆí•œ collator ì„ íƒ:
        - training_algorithm == "mtp": MTPDataCollator
        - ê¸°íƒ€: LMDataCollator

        Args:
            recipe: í›ˆë ¨ ë ˆì‹œí”¼ (pack_sequences ë“± ì„¤ì •)
            config: í™˜ê²½ ì„¤ì •
            tokenizer: í† í¬ë‚˜ì´ì € ì¸ìŠ¤í„´ìŠ¤
            model_metadata: ëª¨ë¸ ë©”íƒ€ë°ì´í„° (ì•Œê³ ë¦¬ì¦˜ íŒë‹¨ìš©)

        Returns:
            Collator ì¸ìŠ¤í„´ìŠ¤
        """
        # 1. ëª¨ë¸ íƒ€ì… ê²°ì •
        training_algorithm = "base"  # ê¸°ë³¸ê°’
        if model_metadata:
            training_algorithm = model_metadata.get("training_algorithm", "base")

        # 2. ì•Œê³ ë¦¬ì¦˜ë³„ collator ì„ íƒ
        if training_algorithm == "mtp":
            collator_key = "mtp-data-collator"
            horizon = model_metadata.get("horizon", 4)
        else:
            collator_key = "lm-data-collator"
            horizon = 1

        # 3. Collator ì„¤ì • êµ¬ì„±
        collator_config = {
            "tokenizer": tokenizer,
            "horizon": horizon,
            "pad_to_multiple_of": 8,  # GPU íš¨ìœ¨ì„±
        }

        # 4. pack_sequences ì„¤ì • ë°˜ì˜
        if hasattr(recipe.data.train, 'pack_sequences') and recipe.data.train.pack_sequences:
            # pack_sequencesê°€ Trueì¼ ë•Œë§Œ ê³ ê¸‰ íŒ¨ë”© ì ìš©
            collator_config["pad_to_multiple_of"] = 8
        else:
            collator_config["pad_to_multiple_of"] = None

        # 5. Registryì—ì„œ ìƒì„±
        return collator_registry.create(collator_key, collator_config)
```

### **Phase 3: Training Pipeline í†µí•© (30ë¶„)**

#### **3.1 Pipeline ìˆ˜ì •**
**íŒŒì¼**: `src/pipelines/training_pipeline.py` (ìˆ˜ì •)

**í˜„ì¬ (Step 9)**:
```python
# Step 9: PyTorch DataLoader ìƒì„±
train_dl = DataLoader(
    tokenized,
    batch_size=recipe.data.train.batch_size or 1,
    shuffle=(sampler is None),
    sampler=sampler,
    collate_fn=default_data_collator,  # â† í•˜ë“œì½”ë”©
    num_workers=2,
    pin_memory=torch.cuda.is_available(),
)
```

**ìˆ˜ì • í›„**:
```python
# Step 9-1: Data Collator ìƒì„± (Factory íŒ¨í„´)
# ëª¨ë¸ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ collator ìë™ ì„ íƒ
model_metadata = getattr(base, '_model_metadata', {})
collator = ComponentFactory.create_collator(
    recipe=recipe,
    config=config,
    tokenizer=tokenizer.tokenizer,  # ì‹¤ì œ HF tokenizer ê°ì²´
    model_metadata=model_metadata
)

console.print(f"[dim]ğŸ” Data Collator ìƒì„± ì™„ë£Œ: {type(collator).__name__}[/dim]")

# Step 9-2: PyTorch DataLoader ìƒì„± (Factoryë¡œ ìƒì„±ëœ collator ì‚¬ìš©)
train_dl = DataLoader(
    tokenized,
    batch_size=recipe.data.train.batch_size or 1,
    shuffle=(sampler is None),
    sampler=sampler,
    collate_fn=collator,  # â† Factoryì—ì„œ ìƒì„±ëœ collator
    num_workers=recipe.data.train.num_workers or 2,
    pin_memory=torch.cuda.is_available(),
)
```

#### **3.2 Import ì¶”ê°€**
**íŒŒì¼**: `src/pipelines/training_pipeline.py` (ìˆ˜ì •)

```python
# ê¸°ì¡´ importì— ì¶”ê°€
from src.components.data import LMDataCollator, MTPDataCollator  # íƒ€ì… íŒíŠ¸ìš©

# default_data_collator import ì œê±° (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
# from transformers import default_data_collator  # â† ì œê±°
```

### **Phase 4: Hidden States ì•ˆì „ ì¶”ì¶œ (30ë¶„)**

#### **4.1 ê³µí†µ ìœ í‹¸ë¦¬í‹° ìƒì„±**
**íŒŒì¼**: `src/utils/model_utils.py` (ìƒˆ íŒŒì¼)

```python
"""ëª¨ë¸ ê´€ë ¨ ê³µí†µ ìœ í‹¸ë¦¬í‹°"""

import torch
from typing import Any, Union


def extract_hidden_states(outputs: Any) -> torch.Tensor:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ hidden_statesë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ

    ë‹¤ì–‘í•œ ëª¨ë¸ ì¶œë ¥ í˜•íƒœë¥¼ ì§€ì›:
    - dict: outputs["hidden_states"]
    - object: outputs.hidden_states
    - object: outputs.last_hidden_state

    Args:
        outputs: ëª¨ë¸ ì¶œë ¥ (dict, BaseModelOutput, ë“±)

    Returns:
        torch.Tensor: [B, S, D] í˜•íƒœì˜ hidden states

    Raises:
        ValueError: hidden_states ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    hidden_states = None

    try:
        # Case 1: dict í˜•íƒœì—ì„œ hidden_states í‚¤ ì ‘ê·¼
        if isinstance(outputs, dict) and "hidden_states" in outputs:
            hs = outputs["hidden_states"]
            # list/tupleì¸ ê²½ìš° ë§ˆì§€ë§‰ ë ˆì´ì–´ ì„ íƒ
            hidden_states = hs[-1] if isinstance(hs, (list, tuple)) else hs

        # Case 2: object í˜•íƒœì—ì„œ hidden_states ì†ì„± ì ‘ê·¼
        elif hasattr(outputs, "hidden_states"):
            hs = outputs.hidden_states
            hidden_states = hs[-1] if isinstance(hs, (list, tuple)) else hs

        # Case 3: object í˜•íƒœì—ì„œ last_hidden_state ì†ì„± ì ‘ê·¼
        elif hasattr(outputs, "last_hidden_state"):
            hidden_states = outputs.last_hidden_state

    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
        pass

    # ê²€ì¦: hidden_statesê°€ ì˜¬ë°”ë¥¸ í˜•íƒœì¸ì§€ í™•ì¸
    if hidden_states is None:
        raise ValueError(
            f"Failed to extract hidden_states from model outputs. "
            f"Output type: {type(outputs)}, "
            f"Available keys/attributes: {_get_available_keys(outputs)}"
        )

    if not isinstance(hidden_states, torch.Tensor):
        raise ValueError(
            f"hidden_states must be torch.Tensor, got {type(hidden_states)}"
        )

    if hidden_states.ndim != 3:
        raise ValueError(
            f"Expected hidden_states shape [B, S, D], got {hidden_states.shape}"
        )

    return hidden_states


def _get_available_keys(outputs: Any) -> str:
    """ë””ë²„ê¹…ì„ ìœ„í•œ ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤/ì†ì„± ëª©ë¡ ë°˜í™˜"""
    if isinstance(outputs, dict):
        return f"dict keys: {list(outputs.keys())}"
    else:
        attrs = [attr for attr in dir(outputs) if not attr.startswith('_')]
        return f"object attrs: {attrs[:10]}..."  # ì²˜ìŒ 10ê°œë§Œ
```

#### **4.2 Critic Head Pretrainer ìˆ˜ì •**
**íŒŒì¼**: `src/components/trainer/critic_head_pretrainer.py` (ìˆ˜ì •)

**í˜„ì¬ (218-222ë¼ì¸)**:
```python
hidden_states = (
    outputs.hidden_states[-1]
    if hasattr(outputs, "hidden_states")
    else outputs["hidden_states"][-1]  # â† KeyError ë°œìƒ
)
```

**ìˆ˜ì • í›„**:
```python
from src.utils.model_utils import extract_hidden_states

hidden_states = extract_hidden_states(outputs)
```

#### **4.3 ê¸°ì¡´ ì½”ë“œ ì •ë¦¬**
**íŒŒì¼**: `src/components/trainer/critic_wmtp_trainer.py` (ìˆ˜ì •)

**í˜„ì¬ (447-452ë¼ì¸)**ì˜ ì¤‘ë³µ ë¡œì§ì„ ê³µí†µ ìœ í‹¸ë¦¬í‹°ë¡œ êµì²´:
```python
from src.utils.model_utils import extract_hidden_states

# ê¸°ì¡´ 447-452 ë¼ì¸ ëŒ€ì²´
try:
    hidden_states = extract_hidden_states(outputs)
except ValueError as e:
    raise ValueError(
        f"CriticWmtpTrainer requires valid hidden_states [B,S,D] from model outputs. "
        f"Error: {e}"
    )
```

---

## ğŸ§ª **ê²€ì¦ ê³„íš**

### **ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸**

#### **Phase 1 í…ŒìŠ¤íŠ¸: Collator ë‹¨ë…**
```python
# Unit Test ì˜ˆì‹œ
from src.components.data import MTPDataCollator, LMDataCollator

# MTP Collator í…ŒìŠ¤íŠ¸
config = {"tokenizer": tokenizer, "horizon": 4}
mtp_collator = MTPDataCollator(config)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
features = [
    {"input_ids": [1, 2, 3, 4, 5]},
    {"input_ids": [6, 7, 8]}
]

batch = mtp_collator(features)
assert batch["labels"].shape == (2, 5, 4)  # [B, S, H]
```

#### **Phase 2 í…ŒìŠ¤íŠ¸: Factory í†µí•©**
```python
# Factory í…ŒìŠ¤íŠ¸
collator = ComponentFactory.create_collator(
    recipe=recipe,
    config=config,
    tokenizer=tokenizer,
    model_metadata={"training_algorithm": "mtp", "horizon": 4}
)
assert isinstance(collator, MTPDataCollator)
```

#### **Phase 3 í…ŒìŠ¤íŠ¸: Pipeline End-to-End**
```bash
# 1. Dry-run í…ŒìŠ¤íŠ¸
python -m src.cli.train --config tests/configs/config.local_test.yaml \
                        --recipe tests/configs/recipe.critic_wmtp.yaml \
                        --dry-run

# 2. ì‹¤ì œ í›ˆë ¨ í…ŒìŠ¤íŠ¸ (ê° ì•Œê³ ë¦¬ì¦˜ë³„)
# Baseline (ê°€ì¥ ë‹¨ìˆœ)
python -m src.cli.train --config tests/configs/config.local_test.yaml \
                        --recipe tests/configs/recipe.mtp_baseline.yaml

# Critic (ìˆ˜ì • ëŒ€ìƒ)
python -m src.cli.train --config tests/configs/config.local_test.yaml \
                        --recipe tests/configs/recipe.critic_wmtp.yaml

# Rho1 (ì°¸ì¡° ëª¨ë¸ í¬í•¨)
python -m src.cli.train --config tests/configs/config.local_test.yaml \
                        --recipe tests/configs/recipe.rho1_wmtp_weighted.yaml
```

---

## ğŸ“Š **ì˜ˆìƒ íš¨ê³¼**

### **ì¦‰ì‹œ í•´ê²°ë˜ëŠ” ë¬¸ì œ**
- âœ… **KeyError: 'hidden_states'** â†’ ì•ˆì „í•œ ì¶”ì¶œ ìœ í‹¸ë¦¬í‹°ë¡œ í•´ê²°
- âœ… **ë°°ì¹˜ ì°¨ì› ë¶ˆì¼ì¹˜** â†’ DataCollatorForLanguageModeling ìƒì†ìœ¼ë¡œ í•´ê²°
- âœ… **Factory íŒ¨í„´ ìœ„ë°˜** â†’ ComponentFactory.create_collator() ì¶”ê°€ë¡œ í•´ê²°
- âœ… **pack_sequences ë¬´ì‹œ** â†’ Factoryì—ì„œ ì„¤ì • ë°˜ì˜ìœ¼ë¡œ í•´ê²°
- âœ… **MTP ë¼ë²¨ ë¶€ì¬** â†’ MTPDataCollator._create_mtp_labels()ë¡œ í•´ê²°

### **ì•„í‚¤í…ì²˜ ê°œì„ **
- **ì¼ê´€ì„±**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ Factory íŒ¨í„´ ì‚¬ìš©
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ collator íƒ€ì…ì„ Registryì— ì‰½ê²Œ ì¶”ê°€
- **ì¬ì‚¬ìš©ì„±**: ê³µí†µ ìœ í‹¸ë¦¬í‹°ë¡œ hidden_states ì¶”ì¶œ ë¡œì§ í†µí•©
- **ì„¤ì • ì£¼ë„**: Recipeì˜ pack_sequences ì„¤ì • ì •ìƒ ë™ì‘

### **ì„±ëŠ¥ ìµœì í™”**
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: pad_to_multiple_of=8ë¡œ GPU ìµœì í™”
- **ë°°ì¹˜ ì•ˆì •ì„±**: ëª¨ë“  ì‹œí€€ìŠ¤ê°€ ë™ì¼ ê¸¸ì´ë¡œ íŒ¨ë”©
- **ì²˜ë¦¬ ì†ë„**: DataCollatorForLanguageModelingì˜ ìµœì í™”ëœ êµ¬í˜„ í™œìš©

---

## âš ï¸ **ë¦¬ìŠ¤í¬ ë¶„ì„ ë° ì™„í™”**

### **ì˜ˆìƒ ë¦¬ìŠ¤í¬**

1. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€** (MTP ë¼ë²¨ 4ë°° ì¦ê°€)
   - **ì™„í™”**: í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ batch_size=1ë¡œ ì‹œì‘, ì ì§„ì  í™•ëŒ€
   - **ëª¨ë‹ˆí„°ë§**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 

2. **ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ í˜¸í™˜ì„±**
   - **ì™„í™”**: LMDataCollatorë¡œ ê¸°ì¡´ ë™ì‘ ì™„ì „ ë³´ì¡´
   - **ê²€ì¦**: baseline/rho1 ì•Œê³ ë¦¬ì¦˜ ë¨¼ì € í…ŒìŠ¤íŠ¸

3. **Factory ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½**
   - **ì™„í™”**: ê¸°ì¡´ Factory ë©”ì„œë“œëŠ” ë³€ê²½í•˜ì§€ ì•Šê³  ì¶”ê°€ë§Œ
   - **í•˜ìœ„í˜¸í™˜**: ê¸°ì¡´ ì½”ë“œ ì˜í–¥ ì—†ìŒ

### **ë¡¤ë°± ê³„íš**
```python
# ê¸´ê¸‰ ë¡¤ë°±: training_pipeline.py í•œ ì¤„ë§Œ ìˆ˜ì •
# ìˆ˜ì •ëœ ì½”ë“œ
collate_fn=collator,

# ë¡¤ë°± ì½”ë“œ
collate_fn=default_data_collator,
```

---

## â±ï¸ **êµ¬í˜„ íƒ€ì„ë¼ì¸**

| Phase | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ì£¼ìš” ì‚°ì¶œë¬¼ |
|-------|------|----------|------------|
| 1 | Collator í´ë˜ìŠ¤ + Registry | 1ì‹œê°„ | `collators.py`, `__init__.py` |
| 2 | ComponentFactory í†µí•© | 30ë¶„ | `component_factory.py` ìˆ˜ì • |
| 3 | Training Pipeline ìˆ˜ì • | 30ë¶„ | `training_pipeline.py` ìˆ˜ì • |
| 4 | Hidden States ìœ í‹¸ë¦¬í‹° | 30ë¶„ | `model_utils.py`, pretrainer ìˆ˜ì • |
| 5 | í†µí•© í…ŒìŠ¤íŠ¸ | 1.5ì‹œê°„ | ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦ |

**ì´ ì˜ˆìƒ ì‹œê°„**: **3.5ì‹œê°„**

---

## ğŸ¯ **ì„±ê³µ ê¸°ì¤€**

### **ê¸°ëŠ¥ì  ì„±ê³µ**
1. **ëª¨ë“  ì—ëŸ¬ ì œê±°**: KeyError, ë°°ì¹˜ ì°¨ì› ë¶ˆì¼ì¹˜ ì™„ì „ í•´ê²°
2. **Factory íŒ¨í„´ ì™„ì„±**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ComponentFactory í†µê³¼
3. **MTP ë¼ë²¨ ì •ìƒ ìƒì„±**: `[B, S, H=4]` í˜•íƒœ ê²€ì¦
4. **ì„¤ì • ë°˜ì˜**: pack_sequences ì„¤ì • ì •ìƒ ë™ì‘

### **ì„±ëŠ¥ ê¸°ì¤€**
1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ê¸°ì¡´ ëŒ€ë¹„ ì ì • ìˆ˜ì¤€ (4ë°° ì´ë‚´) ìœ ì§€
2. **ì²˜ë¦¬ ì†ë„**: ê¸°ì¡´ ëŒ€ë¹„ 90% ì´ìƒ ì„±ëŠ¥ ìœ ì§€
3. **ì•ˆì •ì„±**: 10íšŒ ì—°ì† ì‹¤í–‰ ëª¨ë‘ ì„±ê³µ

### **ì•„í‚¤í…ì²˜ í’ˆì§ˆ**
1. **ì¼ê´€ì„±**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ë™ì¼í•œ Factory + Registry íŒ¨í„´
2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ collator íƒ€ì… ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥
3. **ì¬ì‚¬ìš©ì„±**: ê³µí†µ ë¡œì§ì˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜í™”

---

## ğŸ“‹ **ìµœì¢… íŒŒì¼ ë³€ê²½ ìš”ì•½**

### **ìƒˆë¡œ ìƒì„±í•  íŒŒì¼**
```
src/components/data/
â”œâ”€â”€ __init__.py              # Registry ë“±ë¡
â””â”€â”€ collators.py             # LMDataCollator, MTPDataCollator

src/utils/
â””â”€â”€ model_utils.py           # extract_hidden_states ìœ í‹¸ë¦¬í‹°
```

### **ìˆ˜ì •í•  íŒŒì¼**
```
src/components/registry.py                    # collator_registry ì¶”ê°€
src/factory/component_factory.py              # create_collator ë©”ì„œë“œ ì¶”ê°€
src/pipelines/training_pipeline.py            # Factory ê¸°ë°˜ collator ì‚¬ìš©
src/components/trainer/critic_head_pretrainer.py  # ì•ˆì „í•œ hidden_states ì¶”ì¶œ
src/components/trainer/critic_wmtp_trainer.py     # ì¤‘ë³µ ë¡œì§ ì œê±°
```

---

## ğŸš€ **ê²°ë¡ **

ì´ ê³„íšì€ **ì™„ì „í•œ Factory íŒ¨í„´ í†µí•©**ì„ í†µí•´ WMTP ì‹œìŠ¤í…œì˜ ì•„í‚¤í…ì²˜ ì¼ê´€ì„±ì„ í™•ë¦½í•˜ë©´ì„œ ëª¨ë“  Critical/Major ì´ìŠˆë¥¼ ë™ì‹œ í•´ê²°í•©ë‹ˆë‹¤:

### **í•µì‹¬ í˜ì‹ ì **
1. **ComponentFactory.create_collator()** - ëª¨ë¸ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìë™ ì„ íƒ
2. **MTPDataCollator/LMDataCollator** - ì•Œê³ ë¦¬ì¦˜ë³„ ìµœì í™”ëœ ë¼ë²¨ ìƒì„±
3. **Registry íŒ¨í„´ ì™„ì„±** - ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì˜ í†µì¼ëœ ê´€ë¦¬
4. **ì•ˆì „í•œ hidden_states ì¶”ì¶œ** - ê³µí†µ ìœ í‹¸ë¦¬í‹°ë¡œ ì¬ì‚¬ìš©ì„± í™•ë³´

### **ì•„í‚¤í…ì²˜ ì™„ì„±ë„**
- âœ… **Factory íŒ¨í„´**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ComponentFactory ê²½ìœ 
- âœ… **Registry íŒ¨í„´**: collator_registry ì¶”ê°€ë¡œ í†µí•© ê´€ë¦¬
- âœ… **ì„¤ì • ì£¼ë„**: Recipeì˜ pack_sequences ë“± ì„¤ì • ì™„ì „ ë°˜ì˜
- âœ… **ì»´í¬ë„ŒíŠ¸ ë…ë¦½ì„±**: ê° collatorê°€ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸/í™•ì¥ ê°€ëŠ¥

ì´ì œ WMTP ì‹œìŠ¤í…œì´ ì§„ì •í•œ "Research-Grade Production System"ìœ¼ë¡œ ì™„ì„±ë©ë‹ˆë‹¤.